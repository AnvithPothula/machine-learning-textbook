<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A comprehensive intelligent textbook on machine learning algorithms and applications"><meta name=author content="Anvith Pothula"><link href=https://example.com/chapters/02-k-nearest-neighbors/ rel=canonical><link href=../01-intro-to-ml-fundamentals/quiz/ rel=prev><link href=quiz/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Content - Machine Learning - Algorithms and Applications</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#k-nearest-neighbors-algorithm class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-header__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Machine Learning - Algorithms and Applications </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Content </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../course-description/ class=md-tabs__link> Course Description </a> </li> <li class=md-tabs__item> <a href=../../faq/ class=md-tabs__link> FAQ </a> </li> <li class=md-tabs__item> <a href=../../glossary/ class=md-tabs__link> Glossary </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Chapters </a> </li> <li class=md-tabs__item> <a href=../../sims/ class=md-tabs__link> MicroSims </a> </li> <li class=md-tabs__item> <a href=../../learning-graph/ class=md-tabs__link> Learning Graph </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-nav__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Machine Learning - Algorithms and Applications </label> <div class=md-nav__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-nav__item> <a href=../../course-description/ class=md-nav__link> <span class=md-ellipsis> Course Description </span> </a> </li> <li class=md-nav__item> <a href=../../faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> <li class=md-nav__item> <a href=../../glossary/ class=md-nav__link> <span class=md-ellipsis> Glossary </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> Chapters </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Chapters </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_2> <label class=md-nav__link for=__nav_5_2 id=__nav_5_2_label tabindex> <span class=md-ellipsis> 1. ML Fundamentals </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> 1. ML Fundamentals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_3 checked> <label class=md-nav__link for=__nav_5_3 id=__nav_5_3_label tabindex> <span class=md-ellipsis> 2. K-Nearest Neighbors </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_3_label aria-expanded=true> <label class=md-nav__title for=__nav_5_3> <span class="md-nav__icon md-icon"></span> 2. K-Nearest Neighbors </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Content </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Content </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#the-intuition-behind-k-nearest-neighbors class=md-nav__link> <span class=md-ellipsis> The Intuition Behind K-Nearest Neighbors </span> </a> <nav class=md-nav aria-label="The Intuition Behind K-Nearest Neighbors"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#how-knn-works-a-step-by-step-example class=md-nav__link> <span class=md-ellipsis> How KNN Works: A Step-by-Step Example </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#distance-metrics-measuring-similarity class=md-nav__link> <span class=md-ellipsis> Distance Metrics: Measuring Similarity </span> </a> <nav class=md-nav aria-label="Distance Metrics: Measuring Similarity"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#euclidean-distance class=md-nav__link> <span class=md-ellipsis> Euclidean Distance </span> </a> </li> <li class=md-nav__item> <a href=#manhattan-distance class=md-nav__link> <span class=md-ellipsis> Manhattan Distance </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#implementing-knn-for-classification class=md-nav__link> <span class=md-ellipsis> Implementing KNN for Classification </span> </a> </li> <li class=md-nav__item> <a href=#k-selection-choosing-the-right-number-of-neighbors class=md-nav__link> <span class=md-ellipsis> K Selection: Choosing the Right Number of Neighbors </span> </a> <nav class=md-nav aria-label="K Selection: Choosing the Right Number of Neighbors"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#finding-the-optimal-k class=md-nav__link> <span class=md-ellipsis> Finding the Optimal k </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#decision-boundaries-and-voronoi-diagrams class=md-nav__link> <span class=md-ellipsis> Decision Boundaries and Voronoi Diagrams </span> </a> </li> <li class=md-nav__item> <a href=#knn-for-regression class=md-nav__link> <span class=md-ellipsis> KNN for Regression </span> </a> </li> <li class=md-nav__item> <a href=#lazy-learning-no-explicit-training-phase class=md-nav__link> <span class=md-ellipsis> Lazy Learning: No Explicit Training Phase </span> </a> </li> <li class=md-nav__item> <a href=#the-curse-of-dimensionality class=md-nav__link> <span class=md-ellipsis> The Curse of Dimensionality </span> </a> </li> <li class=md-nav__item> <a href=#best-practices-for-using-knn class=md-nav__link> <span class=md-ellipsis> Best Practices for Using KNN </span> </a> </li> <li class=md-nav__item> <a href=#key-takeaways class=md-nav__link> <span class=md-ellipsis> Key Takeaways </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_4> <label class=md-nav__link for=__nav_5_4 id=__nav_5_4_label tabindex> <span class=md-ellipsis> 3. Decision Trees </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_4_label aria-expanded=false> <label class=md-nav__title for=__nav_5_4> <span class="md-nav__icon md-icon"></span> 3. Decision Trees </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../03-decision-trees/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../03-decision-trees/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_5> <label class=md-nav__link for=__nav_5_5 id=__nav_5_5_label tabindex> <span class=md-ellipsis> 4. Logistic Regression </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5_5> <span class="md-nav__icon md-icon"></span> 4. Logistic Regression </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../04-logistic-regression/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../04-logistic-regression/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_6> <label class=md-nav__link for=__nav_5_6 id=__nav_5_6_label tabindex> <span class=md-ellipsis> 5. Regularization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_6_label aria-expanded=false> <label class=md-nav__title for=__nav_5_6> <span class="md-nav__icon md-icon"></span> 5. Regularization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../05-regularization/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../05-regularization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_7> <label class=md-nav__link for=__nav_5_7 id=__nav_5_7_label tabindex> <span class=md-ellipsis> 6. Support Vector Machines </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_7_label aria-expanded=false> <label class=md-nav__title for=__nav_5_7> <span class="md-nav__icon md-icon"></span> 6. Support Vector Machines </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../06-support-vector-machines/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../06-support-vector-machines/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_8> <label class=md-nav__link for=__nav_5_8 id=__nav_5_8_label tabindex> <span class=md-ellipsis> 7. K-Means Clustering </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_8_label aria-expanded=false> <label class=md-nav__title for=__nav_5_8> <span class="md-nav__icon md-icon"></span> 7. K-Means Clustering </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../07-k-means-clustering/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../07-k-means-clustering/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_9> <label class=md-nav__link for=__nav_5_9 id=__nav_5_9_label tabindex> <span class=md-ellipsis> 8. Data Preprocessing </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_9_label aria-expanded=false> <label class=md-nav__title for=__nav_5_9> <span class="md-nav__icon md-icon"></span> 8. Data Preprocessing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../08-data-preprocessing/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../08-data-preprocessing/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_10> <label class=md-nav__link for=__nav_5_10 id=__nav_5_10_label tabindex> <span class=md-ellipsis> 9. Neural Networks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_10_label aria-expanded=false> <label class=md-nav__title for=__nav_5_10> <span class="md-nav__icon md-icon"></span> 9. Neural Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../09-neural-networks/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../09-neural-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_11> <label class=md-nav__link for=__nav_5_11 id=__nav_5_11_label tabindex> <span class=md-ellipsis> 10. Convolutional Networks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_11_label aria-expanded=false> <label class=md-nav__title for=__nav_5_11> <span class="md-nav__icon md-icon"></span> 10. Convolutional Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../10-convolutional-networks/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../10-convolutional-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_12> <label class=md-nav__link for=__nav_5_12 id=__nav_5_12_label tabindex> <span class=md-ellipsis> 11. Transfer Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_12_label aria-expanded=false> <label class=md-nav__title for=__nav_5_12> <span class="md-nav__icon md-icon"></span> 11. Transfer Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../11-transfer-learning/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../11-transfer-learning/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_13> <label class=md-nav__link for=__nav_5_13 id=__nav_5_13_label tabindex> <span class=md-ellipsis> 12. Evaluation & Optimization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_13_label aria-expanded=false> <label class=md-nav__title for=__nav_5_13> <span class="md-nav__icon md-icon"></span> 12. Evaluation & Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../12-evaluation-optimization/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../12-evaluation-optimization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> MicroSims </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> MicroSims </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../sims/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../../sims/activation-functions/ class=md-nav__link> <span class=md-ellipsis> Activation Functions </span> </a> </li> <li class=md-nav__item> <a href=../../sims/categorical-encoding-explorer/ class=md-nav__link> <span class=md-ellipsis> Categorical Encoding Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/cnn-architecture/ class=md-nav__link> <span class=md-ellipsis> CNN Architecture </span> </a> </li> <li class=md-nav__item> <a href=../../sims/confusion-matrix-explorer/ class=md-nav__link> <span class=md-ellipsis> Confusion Matrix Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/convolution-operation/ class=md-nav__link> <span class=md-ellipsis> Convolution Operation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/distance-metrics/ class=md-nav__link> <span class=md-ellipsis> Distance Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../sims/entropy-gini-comparison/ class=md-nav__link> <span class=md-ellipsis> Entropy-Gini Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/feature-scaling-visualizer/ class=md-nav__link> <span class=md-ellipsis> Feature Scaling Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/k-selection-simulator/ class=md-nav__link> <span class=md-ellipsis> K-Selection Simulator </span> </a> </li> <li class=md-nav__item> <a href=../../sims/kfold-cross-validation/ class=md-nav__link> <span class=md-ellipsis> K-Fold Cross Validation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/lasso-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Lasso Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/network-architecture-visualizer/ class=md-nav__link> <span class=md-ellipsis> Network Architecture Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/ridge-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Ridge Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/roc-curve-comparison/ class=md-nav__link> <span class=md-ellipsis> ROC Curve Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/sigmoid-explorer/ class=md-nav__link> <span class=md-ellipsis> Sigmoid Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/svm-margin-maximization/ class=md-nav__link> <span class=md-ellipsis> SVM Margin Maximization </span> </a> </li> <li class=md-nav__item> <a href=../../sims/training-validation-curves/ class=md-nav__link> <span class=md-ellipsis> Training Validation Curves </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex=0> <span class=md-ellipsis> Learning Graph </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Learning Graph </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../learning-graph/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../sims/graph-viewer/ class=md-nav__link> <span class=md-ellipsis> Graph Viewer </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/course-description-assessment/ class=md-nav__link> <span class=md-ellipsis> Course Description Assessment </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-list/ class=md-nav__link> <span class=md-ellipsis> Concept List </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-taxonomy/ class=md-nav__link> <span class=md-ellipsis> Concept Taxonomy </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.csv class=md-nav__link> <span class=md-ellipsis> Learning Graph (CSV) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.json class=md-nav__link> <span class=md-ellipsis> Learning Graph (JSON) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/quality-metrics/ class=md-nav__link> <span class=md-ellipsis> Quality Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/taxonomy-distribution/ class=md-nav__link> <span class=md-ellipsis> Taxonomy Distribution </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/glossary-quality-report/ class=md-nav__link> <span class=md-ellipsis> Glossary Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-quality-report/ class=md-nav__link> <span class=md-ellipsis> FAQ Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-coverage-gaps/ class=md-nav__link> <span class=md-ellipsis> FAQ Coverage Gaps </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/book-metrics/ class=md-nav__link> <span class=md-ellipsis> Book Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/chapter-metrics/ class=md-nav__link> <span class=md-ellipsis> Chapter Metrics </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#the-intuition-behind-k-nearest-neighbors class=md-nav__link> <span class=md-ellipsis> The Intuition Behind K-Nearest Neighbors </span> </a> <nav class=md-nav aria-label="The Intuition Behind K-Nearest Neighbors"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#how-knn-works-a-step-by-step-example class=md-nav__link> <span class=md-ellipsis> How KNN Works: A Step-by-Step Example </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#distance-metrics-measuring-similarity class=md-nav__link> <span class=md-ellipsis> Distance Metrics: Measuring Similarity </span> </a> <nav class=md-nav aria-label="Distance Metrics: Measuring Similarity"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#euclidean-distance class=md-nav__link> <span class=md-ellipsis> Euclidean Distance </span> </a> </li> <li class=md-nav__item> <a href=#manhattan-distance class=md-nav__link> <span class=md-ellipsis> Manhattan Distance </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#implementing-knn-for-classification class=md-nav__link> <span class=md-ellipsis> Implementing KNN for Classification </span> </a> </li> <li class=md-nav__item> <a href=#k-selection-choosing-the-right-number-of-neighbors class=md-nav__link> <span class=md-ellipsis> K Selection: Choosing the Right Number of Neighbors </span> </a> <nav class=md-nav aria-label="K Selection: Choosing the Right Number of Neighbors"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#finding-the-optimal-k class=md-nav__link> <span class=md-ellipsis> Finding the Optimal k </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#decision-boundaries-and-voronoi-diagrams class=md-nav__link> <span class=md-ellipsis> Decision Boundaries and Voronoi Diagrams </span> </a> </li> <li class=md-nav__item> <a href=#knn-for-regression class=md-nav__link> <span class=md-ellipsis> KNN for Regression </span> </a> </li> <li class=md-nav__item> <a href=#lazy-learning-no-explicit-training-phase class=md-nav__link> <span class=md-ellipsis> Lazy Learning: No Explicit Training Phase </span> </a> </li> <li class=md-nav__item> <a href=#the-curse-of-dimensionality class=md-nav__link> <span class=md-ellipsis> The Curse of Dimensionality </span> </a> </li> <li class=md-nav__item> <a href=#best-practices-for-using-knn class=md-nav__link> <span class=md-ellipsis> Best Practices for Using KNN </span> </a> </li> <li class=md-nav__item> <a href=#key-takeaways class=md-nav__link> <span class=md-ellipsis> Key Takeaways </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=k-nearest-neighbors-algorithm>K-Nearest Neighbors Algorithm<a class=headerlink href=#k-nearest-neighbors-algorithm title="Permanent link">&para;</a></h1> <hr> <p>title: K-Nearest Neighbors Algorithm description: Introduction to KNN for classification and regression, distance metrics, k selection, decision boundaries, and the curse of dimensionality generated_by: claude skill chapter-content-generator date: 2025-12-28 version: 0.03</p> <hr> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">&para;</a></h2> <p>This chapter introduces the K-Nearest Neighbors (KNN) algorithm, one of the most intuitive machine learning algorithms that serves as an excellent starting point for understanding classification and regression. Students will explore how KNN makes predictions by finding similar examples in the training data, learn about different distance metrics (Euclidean and Manhattan), and understand the importance of selecting an appropriate value of k. The chapter covers the geometric interpretation of decision boundaries and Voronoi diagrams, addresses the curse of dimensionality, and demonstrates how KNN operates as a lazy learning algorithm that requires no explicit training phase.</p> <h2 id=concepts-covered>Concepts Covered<a class=headerlink href=#concepts-covered title="Permanent link">&para;</a></h2> <p>This chapter covers the following 11 concepts from the learning graph:</p> <ol> <li>K-Nearest Neighbors</li> <li>Distance Metric</li> <li>Euclidean Distance</li> <li>Manhattan Distance</li> <li>K Selection</li> <li>Decision Boundary</li> <li>Voronoi Diagram</li> <li>Curse of Dimensionality</li> <li>KNN for Classification</li> <li>KNN for Regression</li> <li>Lazy Learning</li> </ol> <h2 id=prerequisites>Prerequisites<a class=headerlink href=#prerequisites title="Permanent link">&para;</a></h2> <p>This chapter builds on concepts from:</p> <ul> <li><a href=../01-intro-to-ml-fundamentals/ >Chapter 1: Introduction to Machine Learning Fundamentals</a></li> </ul> <hr> <h2 id=the-intuition-behind-k-nearest-neighbors>The Intuition Behind K-Nearest Neighbors<a class=headerlink href=#the-intuition-behind-k-nearest-neighbors title="Permanent link">&para;</a></h2> <p>Imagine you've just moved to a new city and want to find a good restaurant. You ask your five nearest neighbors for recommendations, and four of them suggest Italian restaurants while one suggests Chinese food. Using the "majority vote" principle, you'd choose an Italian restaurant. This is precisely how the K-Nearest Neighbors algorithm works—it makes predictions based on the most common outcome among the k closest training examples.</p> <p>K-Nearest Neighbors (KNN) is an instance-based learning algorithm that classifies new data points by examining the k training instances that are most similar (nearest) to the query point. Unlike algorithms that build an explicit model during training, KNN simply stores all training examples and defers computation until prediction time. This makes KNN remarkably simple yet surprisingly effective for many real-world problems.</p> <p>The algorithm's elegance lies in its core principle: <strong>similar inputs should produce similar outputs</strong>. If you want to predict whether a flower is an Iris setosa, versicolor, or virginica based on its petal and sepal measurements, KNN finds the k flowers in your training data with the most similar measurements and assigns the most common species among those neighbors.</p> <h3 id=how-knn-works-a-step-by-step-example>How KNN Works: A Step-by-Step Example<a class=headerlink href=#how-knn-works-a-step-by-step-example title="Permanent link">&para;</a></h3> <p>Let's walk through a concrete classification example using the classic Iris dataset, which contains measurements of 150 iris flowers across three species.</p> <p><strong>Training Phase:</strong> 1. Store all training examples (no actual "learning" happens—this is why KNN is called a "lazy" algorithm)</p> <p><strong>Prediction Phase:</strong> 1. Given a new flower to classify, calculate its distance to all training examples 2. Identify the k nearest neighbors based on these distances 3. For classification: Count the class labels among these k neighbors 4. Predict the majority class (for regression, predict the average value)</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_iris</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.neighbors</span><span class=w> </span><span class=kn>import</span> <span class=n>KNeighborsClassifier</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>accuracy_score</span><span class=p>,</span> <span class=n>confusion_matrix</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a><span class=kn>import</span><span class=w> </span><span class=nn>seaborn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>sns</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=c1># Load the Iris dataset</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a><span class=n>iris</span> <span class=o>=</span> <span class=n>load_iris</span><span class=p>()</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a><span class=n>X</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>data</span>  <span class=c1># Features: sepal length, sepal width, petal length, petal width</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a><span class=n>y</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>target</span>  <span class=c1># Labels: 0=setosa, 1=versicolor, 2=virginica</span>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a><span class=c1># Create a DataFrame for easier exploration</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a><span class=n>iris_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>columns</span><span class=o>=</span><span class=n>iris</span><span class=o>.</span><span class=n>feature_names</span><span class=p>)</span>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a><span class=n>iris_df</span><span class=p>[</span><span class=s1>&#39;species&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>Categorical</span><span class=o>.</span><span class=n>from_codes</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>target_names</span><span class=p>)</span>
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Iris Dataset Shape:&quot;</span><span class=p>,</span> <span class=n>iris_df</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>First 5 rows:&quot;</span><span class=p>)</span>
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a><span class=nb>print</span><span class=p>(</span><span class=n>iris_df</span><span class=o>.</span><span class=n>head</span><span class=p>())</span>
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Class distribution:&quot;</span><span class=p>)</span>
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a><span class=nb>print</span><span class=p>(</span><span class=n>iris_df</span><span class=p>[</span><span class=s1>&#39;species&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>value_counts</span><span class=p>())</span>
</span></code></pre></div> <p>This dataset provides an ideal testbed for KNN because the three species form distinct clusters in feature space, as we'll see when we visualize the data.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># Visualize the data with pairplot</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=n>sns</span><span class=o>.</span><span class=n>pairplot</span><span class=p>(</span><span class=n>iris_df</span><span class=p>,</span> <span class=nb>vars</span><span class=o>=</span><span class=n>iris_df</span><span class=o>.</span><span class=n>columns</span><span class=p>[:</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span> <span class=n>hue</span><span class=o>=</span><span class=s2>&quot;species&quot;</span><span class=p>,</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>             <span class=n>markers</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;o&quot;</span><span class=p>,</span> <span class=s2>&quot;s&quot;</span><span class=p>,</span> <span class=s2>&quot;D&quot;</span><span class=p>],</span> <span class=n>palette</span><span class=o>=</span><span class=s2>&quot;Set2&quot;</span><span class=p>)</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=n>plt</span><span class=o>.</span><span class=n>suptitle</span><span class=p>(</span><span class=s2>&quot;Iris Dataset: Feature Relationships by Species&quot;</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=mf>1.02</span><span class=p>)</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <div class="admonition note"> <p class=admonition-title>Interpreting Pairplots</p> <p>Each subplot shows the relationship between two features, with points colored by species. Notice how the three species form separable clusters, particularly when plotting petal length vs petal width. This visual separation suggests KNN will perform well on this dataset.</p> </div> <h2 id=distance-metrics-measuring-similarity>Distance Metrics: Measuring Similarity<a class=headerlink href=#distance-metrics-measuring-similarity title="Permanent link">&para;</a></h2> <p>The foundation of KNN is measuring how "close" or "similar" two data points are. This requires defining a distance metric—a mathematical function that quantifies the dissimilarity between feature vectors. The choice of distance metric profoundly affects KNN's performance, as it determines which neighbors are considered "nearest."</p> <h3 id=euclidean-distance>Euclidean Distance<a class=headerlink href=#euclidean-distance title="Permanent link">&para;</a></h3> <p>The most common distance metric is <strong>Euclidean distance</strong>, which measures the straight-line distance between two points in feature space. For two points <span class=arithmatex>\(\mathbf{x} = (x_1, x_2, ..., x_n)\)</span> and <span class=arithmatex>\(\mathbf{y} = (y_1, y_2, ..., y_n)\)</span>, Euclidean distance is:</p> <div class=arithmatex>\[d_{Euclidean}(\mathbf{x}, \mathbf{y}) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}\]</div> <p>This corresponds to our everyday notion of distance—imagine drawing a straight line between two points and measuring its length. For a 2D example with points (1, 2) and (4, 6):</p> <div class=arithmatex>\[d = \sqrt{(4-1)^2 + (6-2)^2} = \sqrt{9 + 16} = \sqrt{25} = 5\]</div> <p>Euclidean distance works well when all features are on similar scales and continuous. However, it can be dominated by features with large numerical ranges, making feature scaling essential (we'll address this shortly).</p> <h3 id=manhattan-distance>Manhattan Distance<a class=headerlink href=#manhattan-distance title="Permanent link">&para;</a></h3> <p><strong>Manhattan distance</strong> (also called taxicab or L1 distance) measures the distance traveled along axis-aligned paths, like navigating city blocks in Manhattan where you can only move horizontally or vertically. The formula is:</p> <div class=arithmatex>\[d_{Manhattan}(\mathbf{x}, \mathbf{y}) = \sum_{i=1}^{n} |x_i - y_i|\]</div> <p>For the same example points (1, 2) and (4, 6):</p> <div class=arithmatex>\[d = |4-1| + |6-2| = 3 + 4 = 7\]</div> <p>Manhattan distance can be more robust to outliers than Euclidean distance because it doesn't square the differences. It's particularly useful when features represent independent dimensions (like grid coordinates) rather than components of a unified measurement.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># Demonstrate distance calculations</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>point1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>])</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=n>point2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>4</span><span class=p>,</span> <span class=mi>6</span><span class=p>])</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=c1># Euclidean distance</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a><span class=n>euclidean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>((</span><span class=n>point2</span> <span class=o>-</span> <span class=n>point1</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=p>))</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Euclidean distance: </span><span class=si>{</span><span class=n>euclidean</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a><span class=c1># Manhattan distance</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=n>manhattan</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>point2</span> <span class=o>-</span> <span class=n>point1</span><span class=p>))</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Manhattan distance: </span><span class=si>{</span><span class=n>manhattan</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a><span class=c1># Scikit-learn&#39;s KNN allows specifying the distance metric</span>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.neighbors</span><span class=w> </span><span class=kn>import</span> <span class=n>KNeighborsClassifier</span>
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a>
</span><span id=__span-2-16><a id=__codelineno-2-16 name=__codelineno-2-16 href=#__codelineno-2-16></a><span class=c1># KNN with Euclidean distance (default)</span>
</span><span id=__span-2-17><a id=__codelineno-2-17 name=__codelineno-2-17 href=#__codelineno-2-17></a><span class=n>knn_euclidean</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>metric</span><span class=o>=</span><span class=s1>&#39;euclidean&#39;</span><span class=p>)</span>
</span><span id=__span-2-18><a id=__codelineno-2-18 name=__codelineno-2-18 href=#__codelineno-2-18></a>
</span><span id=__span-2-19><a id=__codelineno-2-19 name=__codelineno-2-19 href=#__codelineno-2-19></a><span class=c1># KNN with Manhattan distance</span>
</span><span id=__span-2-20><a id=__codelineno-2-20 name=__codelineno-2-20 href=#__codelineno-2-20></a><span class=n>knn_manhattan</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>metric</span><span class=o>=</span><span class=s1>&#39;manhattan&#39;</span><span class=p>)</span>
</span></code></pre></div> <p>The table below compares these distance metrics:</p> <table> <thead> <tr> <th>Aspect</th> <th>Euclidean Distance</th> <th>Manhattan Distance</th> </tr> </thead> <tbody> <tr> <td><strong>Formula</strong></td> <td><span class=arithmatex>\(\sqrt{\sum (x_i - y_i)^2}\)</span></td> <td><span class=arithmatex>\(\sum \|x_i - y_i\|\)</span></td> </tr> <tr> <td><strong>Geometry</strong></td> <td>Straight-line distance</td> <td>Grid-path distance</td> </tr> <tr> <td><strong>Sensitivity to outliers</strong></td> <td>Higher (squares differences)</td> <td>Lower (absolute differences)</td> </tr> <tr> <td><strong>Best for</strong></td> <td>Continuous features on similar scales</td> <td>Independent dimensions, city-block problems</td> </tr> <tr> <td><strong>Computational cost</strong></td> <td>Moderate (square root)</td> <td>Lower (just absolute values)</td> </tr> </tbody> </table> <h4 id=distance-metrics-visualization>Distance Metrics Visualization<a class=headerlink href=#distance-metrics-visualization title="Permanent link">&para;</a></h4> <iframe src=../../sims/distance-metrics/main.html width=100% height=680px style="border: 1px solid #ccc; border-radius: 4px;"></iframe> <p><a class=md-button href=../../sims/distance-metrics/main.html target=_blank>View Fullscreen</a> | <a href=../../sims/distance-metrics/ >Documentation</a></p> <p>This interactive visualization compares Euclidean distance (green straight line) with Manhattan distance (orange grid path). Drag the blue point to see how both metrics change. Notice that Manhattan distance always equals or exceeds Euclidean distance, with the ratio reaching √2 when points align diagonally.</p> <h2 id=implementing-knn-for-classification>Implementing KNN for Classification<a class=headerlink href=#implementing-knn-for-classification title="Permanent link">&para;</a></h2> <p>Let's build a complete KNN classifier for the Iris dataset, following best practices for machine learning pipelines.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># Split data into training and test sets</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>    <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=p>)</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Training set: </span><span class=si>{</span><span class=n>X_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>}</span><span class=s2> samples&quot;</span><span class=p>)</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test set: </span><span class=si>{</span><span class=n>X_test</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>}</span><span class=s2> samples&quot;</span><span class=p>)</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a><span class=c1># Create and train KNN classifier with k=3</span>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a><span class=n>knn</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a><span class=n>knn</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a><span class=c1># Make predictions on test set</span>
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a><span class=n>y_pred</span> <span class=o>=</span> <span class=n>knn</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-3-15><a id=__codelineno-3-15 name=__codelineno-3-15 href=#__codelineno-3-15></a>
</span><span id=__span-3-16><a id=__codelineno-3-16 name=__codelineno-3-16 href=#__codelineno-3-16></a><span class=c1># Evaluate performance</span>
</span><span id=__span-3-17><a id=__codelineno-3-17 name=__codelineno-3-17 href=#__codelineno-3-17></a><span class=n>accuracy</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span><span id=__span-3-18><a id=__codelineno-3-18 name=__codelineno-3-18 href=#__codelineno-3-18></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Test accuracy with k=3: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-3-19><a id=__codelineno-3-19 name=__codelineno-3-19 href=#__codelineno-3-19></a>
</span><span id=__span-3-20><a id=__codelineno-3-20 name=__codelineno-3-20 href=#__codelineno-3-20></a><span class=c1># Confusion matrix</span>
</span><span id=__span-3-21><a id=__codelineno-3-21 name=__codelineno-3-21 href=#__codelineno-3-21></a><span class=n>cm</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span><span id=__span-3-22><a id=__codelineno-3-22 name=__codelineno-3-22 href=#__codelineno-3-22></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Confusion Matrix:&quot;</span><span class=p>)</span>
</span><span id=__span-3-23><a id=__codelineno-3-23 name=__codelineno-3-23 href=#__codelineno-3-23></a><span class=nb>print</span><span class=p>(</span><span class=n>cm</span><span class=p>)</span>
</span><span id=__span-3-24><a id=__codelineno-3-24 name=__codelineno-3-24 href=#__codelineno-3-24></a>
</span><span id=__span-3-25><a id=__codelineno-3-25 name=__codelineno-3-25 href=#__codelineno-3-25></a><span class=c1># Visualize confusion matrix</span>
</span><span id=__span-3-26><a id=__codelineno-3-26 name=__codelineno-3-26 href=#__codelineno-3-26></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-3-27><a id=__codelineno-3-27 name=__codelineno-3-27 href=#__codelineno-3-27></a><span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>cm</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s1>&#39;d&#39;</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;Blues&#39;</span><span class=p>,</span>
</span><span id=__span-3-28><a id=__codelineno-3-28 name=__codelineno-3-28 href=#__codelineno-3-28></a>            <span class=n>xticklabels</span><span class=o>=</span><span class=n>iris</span><span class=o>.</span><span class=n>target_names</span><span class=p>,</span>
</span><span id=__span-3-29><a id=__codelineno-3-29 name=__codelineno-3-29 href=#__codelineno-3-29></a>            <span class=n>yticklabels</span><span class=o>=</span><span class=n>iris</span><span class=o>.</span><span class=n>target_names</span><span class=p>)</span>
</span><span id=__span-3-30><a id=__codelineno-3-30 name=__codelineno-3-30 href=#__codelineno-3-30></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Confusion Matrix for KNN (k=3)&#39;</span><span class=p>)</span>
</span><span id=__span-3-31><a id=__codelineno-3-31 name=__codelineno-3-31 href=#__codelineno-3-31></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True Label&#39;</span><span class=p>)</span>
</span><span id=__span-3-32><a id=__codelineno-3-32 name=__codelineno-3-32 href=#__codelineno-3-32></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Predicted Label&#39;</span><span class=p>)</span>
</span><span id=__span-3-33><a id=__codelineno-3-33 name=__codelineno-3-33 href=#__codelineno-3-33></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>The confusion matrix reveals which species are most easily confused. Typically, setosa is perfectly separated, while versicolor and virginica have some overlap in feature space.</p> <div class="admonition tip"> <p class=admonition-title>Why Stratified Splitting?</p> <p>When we use <code>stratify=y</code> in <code>train_test_split</code>, we ensure that both training and test sets maintain the same class proportions as the original dataset. For Iris, this means each set contains roughly equal numbers of all three species, preventing biased evaluation.</p> </div> <h2 id=k-selection-choosing-the-right-number-of-neighbors>K Selection: Choosing the Right Number of Neighbors<a class=headerlink href=#k-selection-choosing-the-right-number-of-neighbors title="Permanent link">&para;</a></h2> <p>The value of k—the number of neighbors to consider—is KNN's most important hyperparameter. Choosing k involves a fundamental tradeoff between bias and variance:</p> <ul> <li><strong>Small k (e.g., k=1)</strong>: Low bias, high variance</li> <li>Decision boundary closely fits training data</li> <li>Sensitive to noise and outliers</li> <li> <p>Risk of overfitting</p> </li> <li> <p><strong>Large k</strong>: High bias, low variance</p> </li> <li>Smoother decision boundary</li> <li>More robust to noise</li> <li>Risk of underfitting by averaging over too many neighbors</li> </ul> <h3 id=finding-the-optimal-k>Finding the Optimal k<a class=headerlink href=#finding-the-optimal-k title="Permanent link">&para;</a></h3> <p>We can systematically search for the best k value using cross-validation, which provides more reliable performance estimates than a single train-test split.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>cross_val_score</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=c1># Test different k values</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=n>k_range</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>  <span class=c1># Test k = 1, 3, 5, 7, ..., 49</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=n>cv_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>k_range</span><span class=p>:</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>    <span class=n>knn</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=n>k</span><span class=p>)</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>    <span class=c1># 10-fold cross-validation</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>knn</span><span class=p>,</span> <span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>    <span class=n>cv_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>scores</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a><span class=c1># Find optimal k</span>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a><span class=n>optimal_k</span> <span class=o>=</span> <span class=n>k_range</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>cv_scores</span><span class=p>)]</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Optimal k: </span><span class=si>{</span><span class=n>optimal_k</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-4-16><a id=__codelineno-4-16 name=__codelineno-4-16 href=#__codelineno-4-16></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best cross-validation accuracy: </span><span class=si>{</span><span class=nb>max</span><span class=p>(</span><span class=n>cv_scores</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-4-17><a id=__codelineno-4-17 name=__codelineno-4-17 href=#__codelineno-4-17></a>
</span><span id=__span-4-18><a id=__codelineno-4-18 name=__codelineno-4-18 href=#__codelineno-4-18></a><span class=c1># Plot k vs accuracy</span>
</span><span id=__span-4-19><a id=__codelineno-4-19 name=__codelineno-4-19 href=#__codelineno-4-19></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-4-20><a id=__codelineno-4-20 name=__codelineno-4-20 href=#__codelineno-4-20></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>k_range</span><span class=p>,</span> <span class=n>cv_scores</span><span class=p>,</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;o&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;-&#39;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;blue&#39;</span><span class=p>)</span>
</span><span id=__span-4-21><a id=__codelineno-4-21 name=__codelineno-4-21 href=#__codelineno-4-21></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Neighbors (k)&#39;</span><span class=p>)</span>
</span><span id=__span-4-22><a id=__codelineno-4-22 name=__codelineno-4-22 href=#__codelineno-4-22></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Cross-Validation Accuracy&#39;</span><span class=p>)</span>
</span><span id=__span-4-23><a id=__codelineno-4-23 name=__codelineno-4-23 href=#__codelineno-4-23></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;KNN Performance vs k Value&#39;</span><span class=p>)</span>
</span><span id=__span-4-24><a id=__codelineno-4-24 name=__codelineno-4-24 href=#__codelineno-4-24></a><span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>optimal_k</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span>
</span><span id=__span-4-25><a id=__codelineno-4-25 name=__codelineno-4-25 href=#__codelineno-4-25></a>            <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Optimal k=</span><span class=si>{</span><span class=n>optimal_k</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span><span id=__span-4-26><a id=__codelineno-4-26 name=__codelineno-4-26 href=#__codelineno-4-26></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-4-27><a id=__codelineno-4-27 name=__codelineno-4-27 href=#__codelineno-4-27></a><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span><span id=__span-4-28><a id=__codelineno-4-28 name=__codelineno-4-28 href=#__codelineno-4-28></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>The accuracy typically increases initially as k grows (reducing overfitting to noise), reaches a peak, then declines as k becomes too large (the model becomes too simple). The optimal k often falls between 3 and 15 for many datasets, though this depends on dataset size and complexity.</p> <p>Explore how different k values affect decision boundaries and predictions:</p> <iframe src=../../sims/k-selection-simulator/k-selection-simulator.html width=100% height=850 style="border: 1px solid #ccc; border-radius: 4px;"></iframe> <p><a class=md-button href=../../sims/k-selection-simulator/k-selection-simulator.html target=_blank>View Fullscreen</a> | <a href=../../sims/k-selection-simulator/ >Documentation</a></p> <h2 id=decision-boundaries-and-voronoi-diagrams>Decision Boundaries and Voronoi Diagrams<a class=headerlink href=#decision-boundaries-and-voronoi-diagrams title="Permanent link">&para;</a></h2> <p>A <strong>decision boundary</strong> is the line (or surface in higher dimensions) that separates regions assigned to different classes. Understanding decision boundaries provides geometric intuition for how classification algorithms partition feature space.</p> <p>For KNN, the decision boundary is determined by the distribution of training points and the value of k. When k=1, the decision boundary creates <strong>Voronoi diagrams</strong>—each training point has a cell consisting of all locations closer to it than to any other training point. Points within a Voronoi cell are classified according to that cell's training point.</p> <p>As k increases, decision boundaries become smoother. Instead of sharp Voronoi cells, boundaries become influenced by groups of neighbors, creating more gradual transitions between classes. This smoothing reduces sensitivity to individual training points but may obscure genuine fine-grained patterns in the data.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=c1># Visualize decision boundaries for different k values</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=kn>from</span><span class=w> </span><span class=nn>matplotlib.colors</span><span class=w> </span><span class=kn>import</span> <span class=n>ListedColormap</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=c1># Use only two features for 2D visualization</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a><span class=n>X_2d</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>data</span><span class=p>[:,</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>]]</span>  <span class=c1># Petal length and width</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=n>y_2d</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>target</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=c1># Standardize features</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a><span class=n>X_2d_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_2d</span><span class=p>)</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a><span class=c1># Split data</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a><span class=n>X_train_2d</span><span class=p>,</span> <span class=n>X_test_2d</span><span class=p>,</span> <span class=n>y_train_2d</span><span class=p>,</span> <span class=n>y_test_2d</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a>    <span class=n>X_2d_scaled</span><span class=p>,</span> <span class=n>y_2d</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y_2d</span>
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a><span class=p>)</span>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a><span class=c1># Create mesh for plotting decision boundaries</span>
</span><span id=__span-5-19><a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a><span class=n>h</span> <span class=o>=</span> <span class=mf>0.02</span>  <span class=c1># Step size in mesh</span>
</span><span id=__span-5-20><a id=__codelineno-5-20 name=__codelineno-5-20 href=#__codelineno-5-20></a><span class=n>x_min</span><span class=p>,</span> <span class=n>x_max</span> <span class=o>=</span> <span class=n>X_2d_scaled</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>X_2d_scaled</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>+</span> <span class=mi>1</span>
</span><span id=__span-5-21><a id=__codelineno-5-21 name=__codelineno-5-21 href=#__codelineno-5-21></a><span class=n>y_min</span><span class=p>,</span> <span class=n>y_max</span> <span class=o>=</span> <span class=n>X_2d_scaled</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>X_2d_scaled</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>+</span> <span class=mi>1</span>
</span><span id=__span-5-22><a id=__codelineno-5-22 name=__codelineno-5-22 href=#__codelineno-5-22></a><span class=n>xx</span><span class=p>,</span> <span class=n>yy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>meshgrid</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>x_min</span><span class=p>,</span> <span class=n>x_max</span><span class=p>,</span> <span class=n>h</span><span class=p>),</span>
</span><span id=__span-5-23><a id=__codelineno-5-23 name=__codelineno-5-23 href=#__codelineno-5-23></a>                     <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>y_min</span><span class=p>,</span> <span class=n>y_max</span><span class=p>,</span> <span class=n>h</span><span class=p>))</span>
</span><span id=__span-5-24><a id=__codelineno-5-24 name=__codelineno-5-24 href=#__codelineno-5-24></a>
</span><span id=__span-5-25><a id=__codelineno-5-25 name=__codelineno-5-25 href=#__codelineno-5-25></a><span class=c1># Plot decision boundaries for k=1, 5, 15</span>
</span><span id=__span-5-26><a id=__codelineno-5-26 name=__codelineno-5-26 href=#__codelineno-5-26></a><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</span><span id=__span-5-27><a id=__codelineno-5-27 name=__codelineno-5-27 href=#__codelineno-5-27></a><span class=n>k_values</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>]</span>
</span><span id=__span-5-28><a id=__codelineno-5-28 name=__codelineno-5-28 href=#__codelineno-5-28></a>
</span><span id=__span-5-29><a id=__codelineno-5-29 name=__codelineno-5-29 href=#__codelineno-5-29></a><span class=n>cmap_light</span> <span class=o>=</span> <span class=n>ListedColormap</span><span class=p>([</span><span class=s1>&#39;#FFAAAA&#39;</span><span class=p>,</span> <span class=s1>&#39;#AAFFAA&#39;</span><span class=p>,</span> <span class=s1>&#39;#AAAAFF&#39;</span><span class=p>])</span>
</span><span id=__span-5-30><a id=__codelineno-5-30 name=__codelineno-5-30 href=#__codelineno-5-30></a><span class=n>cmap_bold</span> <span class=o>=</span> <span class=n>ListedColormap</span><span class=p>([</span><span class=s1>&#39;#FF0000&#39;</span><span class=p>,</span> <span class=s1>&#39;#00FF00&#39;</span><span class=p>,</span> <span class=s1>&#39;#0000FF&#39;</span><span class=p>])</span>
</span><span id=__span-5-31><a id=__codelineno-5-31 name=__codelineno-5-31 href=#__codelineno-5-31></a>
</span><span id=__span-5-32><a id=__codelineno-5-32 name=__codelineno-5-32 href=#__codelineno-5-32></a><span class=k>for</span> <span class=n>idx</span><span class=p>,</span> <span class=n>k</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>k_values</span><span class=p>):</span>
</span><span id=__span-5-33><a id=__codelineno-5-33 name=__codelineno-5-33 href=#__codelineno-5-33></a>    <span class=n>knn</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=n>k</span><span class=p>)</span>
</span><span id=__span-5-34><a id=__codelineno-5-34 name=__codelineno-5-34 href=#__codelineno-5-34></a>    <span class=n>knn</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_2d</span><span class=p>,</span> <span class=n>y_train_2d</span><span class=p>)</span>
</span><span id=__span-5-35><a id=__codelineno-5-35 name=__codelineno-5-35 href=#__codelineno-5-35></a>
</span><span id=__span-5-36><a id=__codelineno-5-36 name=__codelineno-5-36 href=#__codelineno-5-36></a>    <span class=c1># Predict for each point in mesh</span>
</span><span id=__span-5-37><a id=__codelineno-5-37 name=__codelineno-5-37 href=#__codelineno-5-37></a>    <span class=n>Z</span> <span class=o>=</span> <span class=n>knn</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>c_</span><span class=p>[</span><span class=n>xx</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span> <span class=n>yy</span><span class=o>.</span><span class=n>ravel</span><span class=p>()])</span>
</span><span id=__span-5-38><a id=__codelineno-5-38 name=__codelineno-5-38 href=#__codelineno-5-38></a>    <span class=n>Z</span> <span class=o>=</span> <span class=n>Z</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>xx</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-5-39><a id=__codelineno-5-39 name=__codelineno-5-39 href=#__codelineno-5-39></a>
</span><span id=__span-5-40><a id=__codelineno-5-40 name=__codelineno-5-40 href=#__codelineno-5-40></a>    <span class=c1># Plot</span>
</span><span id=__span-5-41><a id=__codelineno-5-41 name=__codelineno-5-41 href=#__codelineno-5-41></a>    <span class=n>axes</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>.</span><span class=n>contourf</span><span class=p>(</span><span class=n>xx</span><span class=p>,</span> <span class=n>yy</span><span class=p>,</span> <span class=n>Z</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=n>cmap_light</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.8</span><span class=p>)</span>
</span><span id=__span-5-42><a id=__codelineno-5-42 name=__codelineno-5-42 href=#__codelineno-5-42></a>    <span class=n>axes</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X_train_2d</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>X_train_2d</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>c</span><span class=o>=</span><span class=n>y_train_2d</span><span class=p>,</span>
</span><span id=__span-5-43><a id=__codelineno-5-43 name=__codelineno-5-43 href=#__codelineno-5-43></a>                     <span class=n>cmap</span><span class=o>=</span><span class=n>cmap_bold</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span><span id=__span-5-44><a id=__codelineno-5-44 name=__codelineno-5-44 href=#__codelineno-5-44></a>    <span class=n>axes</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;KNN Decision Boundary (k=</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
</span><span id=__span-5-45><a id=__codelineno-5-45 name=__codelineno-5-45 href=#__codelineno-5-45></a>    <span class=n>axes</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Petal Length (scaled)&#39;</span><span class=p>)</span>
</span><span id=__span-5-46><a id=__codelineno-5-46 name=__codelineno-5-46 href=#__codelineno-5-46></a>    <span class=n>axes</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Petal Width (scaled)&#39;</span><span class=p>)</span>
</span><span id=__span-5-47><a id=__codelineno-5-47 name=__codelineno-5-47 href=#__codelineno-5-47></a>
</span><span id=__span-5-48><a id=__codelineno-5-48 name=__codelineno-5-48 href=#__codelineno-5-48></a><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span><span id=__span-5-49><a id=__codelineno-5-49 name=__codelineno-5-49 href=#__codelineno-5-49></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>Notice how k=1 creates jagged, complex boundaries that tightly wrap training points, while k=15 creates smooth, generalized boundaries. The optimal k typically produces boundaries that capture true patterns while ignoring noise.</p> <h2 id=knn-for-regression>KNN for Regression<a class=headerlink href=#knn-for-regression title="Permanent link">&para;</a></h2> <p>While we've focused on classification, KNN also performs regression by predicting the average (or weighted average) of the k nearest neighbors' target values instead of voting on classes.</p> <p>For a regression problem, given a query point <span class=arithmatex>\(\mathbf{x}\)</span> and its k nearest neighbors <span class=arithmatex>\(\mathcal{N}_k(\mathbf{x})\)</span>, the KNN regression prediction is:</p> <div class=arithmatex>\[\hat{y} = \frac{1}{k} \sum_{i \in \mathcal{N}_k(\mathbf{x})} y_i\]</div> <p>Optionally, we can weight neighbors by inverse distance, giving closer neighbors more influence:</p> <div class=arithmatex>\[\hat{y} = \frac{\sum_{i \in \mathcal{N}_k(\mathbf{x})} w_i y_i}{\sum_{i \in \mathcal{N}_k(\mathbf{x})} w_i}, \quad \text{where} \quad w_i = \frac{1}{d(\mathbf{x}, \mathbf{x}_i)}\]</div> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.neighbors</span><span class=w> </span><span class=kn>import</span> <span class=n>KNeighborsRegressor</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>fetch_california_housing</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=c1># Load California housing dataset (regression task)</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=n>housing</span> <span class=o>=</span> <span class=n>fetch_california_housing</span><span class=p>()</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a><span class=n>X_housing</span> <span class=o>=</span> <span class=n>housing</span><span class=o>.</span><span class=n>data</span><span class=p>[:</span><span class=mi>1000</span><span class=p>]</span>  <span class=c1># Use subset for speed</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a><span class=n>y_housing</span> <span class=o>=</span> <span class=n>housing</span><span class=o>.</span><span class=n>target</span><span class=p>[:</span><span class=mi>1000</span><span class=p>]</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a><span class=c1># Split data</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a><span class=n>X_train_h</span><span class=p>,</span> <span class=n>X_test_h</span><span class=p>,</span> <span class=n>y_train_h</span><span class=p>,</span> <span class=n>y_test_h</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>    <span class=n>X_housing</span><span class=p>,</span> <span class=n>y_housing</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a><span class=p>)</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a><span class=c1># KNN regression with k=5</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a><span class=n>knn_reg</span> <span class=o>=</span> <span class=n>KNeighborsRegressor</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a><span class=n>knn_reg</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_h</span><span class=p>,</span> <span class=n>y_train_h</span><span class=p>)</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a><span class=c1># Evaluate with R² score (proportion of variance explained)</span>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>r2_score</span><span class=p>,</span> <span class=n>mean_squared_error</span>
</span><span id=__span-6-20><a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a>
</span><span id=__span-6-21><a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a><span class=n>y_pred_h</span> <span class=o>=</span> <span class=n>knn_reg</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_h</span><span class=p>)</span>
</span><span id=__span-6-22><a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a><span class=n>r2</span> <span class=o>=</span> <span class=n>r2_score</span><span class=p>(</span><span class=n>y_test_h</span><span class=p>,</span> <span class=n>y_pred_h</span><span class=p>)</span>
</span><span id=__span-6-23><a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a><span class=n>mse</span> <span class=o>=</span> <span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_test_h</span><span class=p>,</span> <span class=n>y_pred_h</span><span class=p>)</span>
</span><span id=__span-6-24><a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a>
</span><span id=__span-6-25><a id=__codelineno-6-25 name=__codelineno-6-25 href=#__codelineno-6-25></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;KNN Regression R² score: </span><span class=si>{</span><span class=n>r2</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-26><a id=__codelineno-6-26 name=__codelineno-6-26 href=#__codelineno-6-26></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Mean Squared Error: </span><span class=si>{</span><span class=n>mse</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-27><a id=__codelineno-6-27 name=__codelineno-6-27 href=#__codelineno-6-27></a>
</span><span id=__span-6-28><a id=__codelineno-6-28 name=__codelineno-6-28 href=#__codelineno-6-28></a><span class=c1># Compare actual vs predicted</span>
</span><span id=__span-6-29><a id=__codelineno-6-29 name=__codelineno-6-29 href=#__codelineno-6-29></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-6-30><a id=__codelineno-6-30 name=__codelineno-6-30 href=#__codelineno-6-30></a><span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>y_test_h</span><span class=p>,</span> <span class=n>y_pred_h</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>)</span>
</span><span id=__span-6-31><a id=__codelineno-6-31 name=__codelineno-6-31 href=#__codelineno-6-31></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>([</span><span class=n>y_test_h</span><span class=o>.</span><span class=n>min</span><span class=p>(),</span> <span class=n>y_test_h</span><span class=o>.</span><span class=n>max</span><span class=p>()],</span>
</span><span id=__span-6-32><a id=__codelineno-6-32 name=__codelineno-6-32 href=#__codelineno-6-32></a>         <span class=p>[</span><span class=n>y_test_h</span><span class=o>.</span><span class=n>min</span><span class=p>(),</span> <span class=n>y_test_h</span><span class=o>.</span><span class=n>max</span><span class=p>()],</span>
</span><span id=__span-6-33><a id=__codelineno-6-33 name=__codelineno-6-33 href=#__codelineno-6-33></a>         <span class=s1>&#39;r--&#39;</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Perfect Prediction&#39;</span><span class=p>)</span>
</span><span id=__span-6-34><a id=__codelineno-6-34 name=__codelineno-6-34 href=#__codelineno-6-34></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Actual House Price&#39;</span><span class=p>)</span>
</span><span id=__span-6-35><a id=__codelineno-6-35 name=__codelineno-6-35 href=#__codelineno-6-35></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Predicted House Price&#39;</span><span class=p>)</span>
</span><span id=__span-6-36><a id=__codelineno-6-36 name=__codelineno-6-36 href=#__codelineno-6-36></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;KNN Regression: Actual vs Predicted&#39;</span><span class=p>)</span>
</span><span id=__span-6-37><a id=__codelineno-6-37 name=__codelineno-6-37 href=#__codelineno-6-37></a><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span><span id=__span-6-38><a id=__codelineno-6-38 name=__codelineno-6-38 href=#__codelineno-6-38></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-6-39><a id=__codelineno-6-39 name=__codelineno-6-39 href=#__codelineno-6-39></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>KNN regression works well when the relationship between features and target is complex and nonlinear, as KNN makes no assumptions about the underlying functional form. However, it performs poorly when data is sparse or high-dimensional (as we'll discuss next).</p> <h2 id=lazy-learning-no-explicit-training-phase>Lazy Learning: No Explicit Training Phase<a class=headerlink href=#lazy-learning-no-explicit-training-phase title="Permanent link">&para;</a></h2> <p>KNN is a <strong>lazy learning</strong> (or instance-based) algorithm, meaning it defers all computation until prediction time rather than building a model during training. This contrasts with eager learning algorithms like decision trees or neural networks that construct explicit models from training data.</p> <p>Characteristics of lazy learning in KNN:</p> <ul> <li><strong>Training phase</strong>: Simply store all training examples (O(1) time complexity)</li> <li><strong>Prediction phase</strong>: Compute distances to all training points and find k nearest neighbors (O(n) time complexity for n training examples)</li> <li><strong>Memory requirements</strong>: Must store entire training dataset</li> <li><strong>Adaptability</strong>: Easy to add new training data without retraining</li> </ul> <p>This lazy approach has important implications:</p> <p><strong>Advantages:</strong> - No training time—can immediately use new data - Naturally handles complex decision boundaries - No assumptions about data distribution - Adapts locally to different regions of feature space</p> <p><strong>Disadvantages:</strong> - Slow predictions (must compute distances to all training points) - High memory requirements (stores all training data) - Requires careful selection of k and distance metric - Doesn't provide interpretable model or feature importance</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>import</span><span class=w> </span><span class=nn>time</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=c1># Measure prediction time for different training set sizes</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=n>sizes</span> <span class=o>=</span> <span class=p>[</span><span class=mi>100</span><span class=p>,</span> <span class=mi>500</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=mi>5000</span><span class=p>,</span> <span class=mi>10000</span><span class=p>]</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=n>prediction_times</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a><span class=k>for</span> <span class=n>size</span> <span class=ow>in</span> <span class=n>sizes</span><span class=p>:</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>    <span class=c1># Create synthetic dataset of specified size</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>    <span class=n>X_synth</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a>    <span class=n>y_synth</span> <span class=o>=</span> <span class=p>(</span><span class=n>X_synth</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>    <span class=c1># Train KNN</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a>    <span class=n>knn</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a>    <span class=n>knn</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_synth</span><span class=p>,</span> <span class=n>y_synth</span><span class=p>)</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a>    <span class=c1># Time prediction for 100 test points</span>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a>    <span class=n>X_test_synth</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span><span id=__span-7-18><a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a>    <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span><span id=__span-7-19><a id=__codelineno-7-19 name=__codelineno-7-19 href=#__codelineno-7-19></a>    <span class=n>knn</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_synth</span><span class=p>)</span>
</span><span id=__span-7-20><a id=__codelineno-7-20 name=__codelineno-7-20 href=#__codelineno-7-20></a>    <span class=n>elapsed</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span>
</span><span id=__span-7-21><a id=__codelineno-7-21 name=__codelineno-7-21 href=#__codelineno-7-21></a>    <span class=n>prediction_times</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>elapsed</span><span class=p>)</span>
</span><span id=__span-7-22><a id=__codelineno-7-22 name=__codelineno-7-22 href=#__codelineno-7-22></a>
</span><span id=__span-7-23><a id=__codelineno-7-23 name=__codelineno-7-23 href=#__codelineno-7-23></a><span class=c1># Plot scaling behavior</span>
</span><span id=__span-7-24><a id=__codelineno-7-24 name=__codelineno-7-24 href=#__codelineno-7-24></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-7-25><a id=__codelineno-7-25 name=__codelineno-7-25 href=#__codelineno-7-25></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>sizes</span><span class=p>,</span> <span class=n>prediction_times</span><span class=p>,</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;o&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-7-26><a id=__codelineno-7-26 name=__codelineno-7-26 href=#__codelineno-7-26></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Training Set Size&#39;</span><span class=p>)</span>
</span><span id=__span-7-27><a id=__codelineno-7-27 name=__codelineno-7-27 href=#__codelineno-7-27></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Prediction Time (seconds)&#39;</span><span class=p>)</span>
</span><span id=__span-7-28><a id=__codelineno-7-28 name=__codelineno-7-28 href=#__codelineno-7-28></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;KNN Prediction Time Scales Linearly with Training Set Size&#39;</span><span class=p>)</span>
</span><span id=__span-7-29><a id=__codelineno-7-29 name=__codelineno-7-29 href=#__codelineno-7-29></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-7-30><a id=__codelineno-7-30 name=__codelineno-7-30 href=#__codelineno-7-30></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span><span id=__span-7-31><a id=__codelineno-7-31 name=__codelineno-7-31 href=#__codelineno-7-31></a>
</span><span id=__span-7-32><a id=__codelineno-7-32 name=__codelineno-7-32 href=#__codelineno-7-32></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Prediction time grows linearly with training data size.&quot;</span><span class=p>)</span>
</span><span id=__span-7-33><a id=__codelineno-7-33 name=__codelineno-7-33 href=#__codelineno-7-33></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;This is a fundamental limitation of lazy learning algorithms.&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>For large datasets, consider using approximate nearest neighbor algorithms (like locality-sensitive hashing or KD-trees) to speed up predictions, though these trade exactness for efficiency.</p> <h2 id=the-curse-of-dimensionality>The Curse of Dimensionality<a class=headerlink href=#the-curse-of-dimensionality title="Permanent link">&para;</a></h2> <p>One of KNN's most significant limitations is the <strong>curse of dimensionality</strong>—as the number of features increases, the distance between all points becomes increasingly similar, making the notion of "nearest neighbors" less meaningful.</p> <p>In high-dimensional spaces:</p> <ol> <li> <p><strong>Volume grows exponentially</strong>: A unit hypercube in d dimensions has volume <span class=arithmatex>\(1^d = 1\)</span>, but most of this volume concentrates near the surface. Points become sparse even with millions of examples.</p> </li> <li> <p><strong>Distances become uniform</strong>: The ratio of the farthest to nearest neighbor approaches 1 as dimensionality increases, making all points roughly equidistant.</p> </li> <li> <p><strong>Concentration phenomenon</strong>: The distance between a random point and its nearest neighbor grows as <span class=arithmatex>\(\sqrt{d}\)</span>, where d is dimensionality.</p> </li> </ol> <p>Mathematically, for uniformly distributed random points in a d-dimensional unit hypercube, the expected distance to the nearest neighbor is approximately:</p> <div class=arithmatex>\[\mathbb{E}[\text{dist}_{nearest}] \approx \left(\frac{1}{n}\right)^{1/d}\]</div> <p>This means we need exponentially more data to maintain the same density as dimensions increase. To keep the same neighbor density going from 2D to 10D requires roughly <span class=arithmatex>\(n^{10/2} = n^5\)</span> times as much data!</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=c1># Demonstrate curse of dimensionality</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics.pairwise</span><span class=w> </span><span class=kn>import</span> <span class=n>euclidean_distances</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=n>dimensions</span> <span class=o>=</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>100</span><span class=p>]</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a><span class=n>avg_nearest_dist</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=n>avg_farthest_dist</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a><span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=n>dimensions</span><span class=p>:</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>    <span class=c1># Generate 1000 random points in d dimensions</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>1000</span><span class=p>,</span> <span class=n>d</span><span class=p>)</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a>    <span class=c1># Compute pairwise distances</span>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a>    <span class=n>distances</span> <span class=o>=</span> <span class=n>euclidean_distances</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a>    <span class=c1># For each point, find nearest and farthest neighbor (excluding itself)</span>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a>    <span class=n>np</span><span class=o>.</span><span class=n>fill_diagonal</span><span class=p>(</span><span class=n>distances</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>inf</span><span class=p>)</span>
</span><span id=__span-8-19><a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a>    <span class=n>nearest</span> <span class=o>=</span> <span class=n>distances</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span><span id=__span-8-20><a id=__codelineno-8-20 name=__codelineno-8-20 href=#__codelineno-8-20></a>    <span class=n>np</span><span class=o>.</span><span class=n>fill_diagonal</span><span class=p>(</span><span class=n>distances</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span><span id=__span-8-21><a id=__codelineno-8-21 name=__codelineno-8-21 href=#__codelineno-8-21></a>    <span class=n>farthest</span> <span class=o>=</span> <span class=n>distances</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span><span id=__span-8-22><a id=__codelineno-8-22 name=__codelineno-8-22 href=#__codelineno-8-22></a>
</span><span id=__span-8-23><a id=__codelineno-8-23 name=__codelineno-8-23 href=#__codelineno-8-23></a>    <span class=n>avg_nearest_dist</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nearest</span><span class=p>)</span>
</span><span id=__span-8-24><a id=__codelineno-8-24 name=__codelineno-8-24 href=#__codelineno-8-24></a>    <span class=n>avg_farthest_dist</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>farthest</span><span class=p>)</span>
</span><span id=__span-8-25><a id=__codelineno-8-25 name=__codelineno-8-25 href=#__codelineno-8-25></a>
</span><span id=__span-8-26><a id=__codelineno-8-26 name=__codelineno-8-26 href=#__codelineno-8-26></a><span class=c1># Plot results</span>
</span><span id=__span-8-27><a id=__codelineno-8-27 name=__codelineno-8-27 href=#__codelineno-8-27></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-8-28><a id=__codelineno-8-28 name=__codelineno-8-28 href=#__codelineno-8-28></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>dimensions</span><span class=p>,</span> <span class=n>avg_nearest_dist</span><span class=p>,</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;o&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Avg Nearest Neighbor Dist&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-8-29><a id=__codelineno-8-29 name=__codelineno-8-29 href=#__codelineno-8-29></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>dimensions</span><span class=p>,</span> <span class=n>avg_farthest_dist</span><span class=p>,</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;s&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Avg Farthest Neighbor Dist&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-8-30><a id=__codelineno-8-30 name=__codelineno-8-30 href=#__codelineno-8-30></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Dimensions&#39;</span><span class=p>)</span>
</span><span id=__span-8-31><a id=__codelineno-8-31 name=__codelineno-8-31 href=#__codelineno-8-31></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Average Distance&#39;</span><span class=p>)</span>
</span><span id=__span-8-32><a id=__codelineno-8-32 name=__codelineno-8-32 href=#__codelineno-8-32></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Curse of Dimensionality: Distances Become Similar in High Dimensions&#39;</span><span class=p>)</span>
</span><span id=__span-8-33><a id=__codelineno-8-33 name=__codelineno-8-33 href=#__codelineno-8-33></a><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span><span id=__span-8-34><a id=__codelineno-8-34 name=__codelineno-8-34 href=#__codelineno-8-34></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-8-35><a id=__codelineno-8-35 name=__codelineno-8-35 href=#__codelineno-8-35></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span><span id=__span-8-36><a id=__codelineno-8-36 name=__codelineno-8-36 href=#__codelineno-8-36></a>
</span><span id=__span-8-37><a id=__codelineno-8-37 name=__codelineno-8-37 href=#__codelineno-8-37></a><span class=c1># Compute ratio of farthest to nearest</span>
</span><span id=__span-8-38><a id=__codelineno-8-38 name=__codelineno-8-38 href=#__codelineno-8-38></a><span class=n>ratio</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>avg_farthest_dist</span><span class=p>)</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>avg_nearest_dist</span><span class=p>)</span>
</span><span id=__span-8-39><a id=__codelineno-8-39 name=__codelineno-8-39 href=#__codelineno-8-39></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Ratio of farthest to nearest neighbor distance:&quot;</span><span class=p>)</span>
</span><span id=__span-8-40><a id=__codelineno-8-40 name=__codelineno-8-40 href=#__codelineno-8-40></a><span class=k>for</span> <span class=n>d</span><span class=p>,</span> <span class=n>r</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>dimensions</span><span class=p>,</span> <span class=n>ratio</span><span class=p>):</span>
</span><span id=__span-8-41><a id=__codelineno-8-41 name=__codelineno-8-41 href=#__codelineno-8-41></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  </span><span class=si>{</span><span class=n>d</span><span class=si>}</span><span class=s2>D: </span><span class=si>{</span><span class=n>r</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>As dimensionality increases, the ratio approaches 1, meaning "nearest" and "farthest" neighbors become indistinguishable. This severely degrades KNN performance in high dimensions.</p> <p><strong>Mitigation strategies:</strong></p> <ul> <li><strong>Feature selection</strong>: Remove irrelevant features</li> <li><strong>Dimensionality reduction</strong>: Use PCA or other techniques (Chapter 8)</li> <li><strong>Distance weighting</strong>: Weight features by importance</li> <li><strong>Local distance metrics</strong>: Use distance metrics that adapt to local data structure</li> </ul> <div class="admonition warning"> <p class=admonition-title>High-Dimensional Data Warning</p> <p>For datasets with &gt;20 features, KNN often performs poorly unless combined with dimensionality reduction. Modern deep learning methods (Chapters 9-11) handle high-dimensional data more effectively by learning feature representations.</p> </div> <h2 id=best-practices-for-using-knn>Best Practices for Using KNN<a class=headerlink href=#best-practices-for-using-knn title="Permanent link">&para;</a></h2> <p>To maximize KNN performance, follow these guidelines:</p> <p><strong>1. Feature Scaling is Essential</strong></p> <p>KNN uses distances, so features with large ranges dominate those with small ranges. Always standardize or normalize features:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=c1># Standardization (mean=0, std=1)</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=n>X_train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a><span class=n>X_test_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a><span class=n>knn</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a><span class=n>knn</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></code></pre></div> <p><strong>2. Choose k Using Cross-Validation</strong></p> <p>Never guess k—systematically search for the optimal value using cross-validation.</p> <p><strong>3. Consider the Distance Metric</strong></p> <p>Euclidean distance is default but not always best. Try Manhattan distance or others (Minkowski, cosine similarity) based on data characteristics.</p> <p><strong>4. Handle Imbalanced Classes</strong></p> <p>For imbalanced datasets, consider weighted KNN that gives more importance to closer neighbors.</p> <p><strong>5. Reduce Dimensionality</strong></p> <p>For high-dimensional data, apply PCA or feature selection before KNN.</p> <p><strong>6. Use Approximate Methods for Large Datasets</strong></p> <p>For very large datasets, use tree-based methods (Ball Tree, KD-Tree) or approximate nearest neighbor algorithms.</p> <h2 id=key-takeaways>Key Takeaways<a class=headerlink href=#key-takeaways title="Permanent link">&para;</a></h2> <p>This chapter explored the K-Nearest Neighbors algorithm, a simple yet powerful instance-based learning approach:</p> <ul> <li> <p><strong>KNN makes predictions</strong> by finding the k training examples most similar to a query point, then voting (classification) or averaging (regression) their labels</p> </li> <li> <p><strong>Distance metrics</strong> like Euclidean and Manhattan distance quantify similarity; the choice of metric affects which neighbors are considered "nearest"</p> </li> <li> <p><strong>K selection</strong> involves a bias-variance tradeoff: small k fits training data closely but is sensitive to noise, while large k creates smoother boundaries but may underfit</p> </li> <li> <p><strong>Decision boundaries</strong> visualize how KNN partitions feature space; when k=1, these form Voronoi diagrams</p> </li> <li> <p><strong>Lazy learning</strong> means KNN stores training data and defers all computation until prediction time, making training fast but predictions slow</p> </li> <li> <p><strong>The curse of dimensionality</strong> causes KNN to fail in high-dimensional spaces where distances become meaningless and all points appear equidistant</p> </li> <li> <p><strong>Best practices</strong> include feature scaling, cross-validation for k selection, and dimensionality reduction for high-dimensional data</p> </li> </ul> <p>KNN provides an excellent introduction to machine learning because it's intuitive, requires no training, and performs well on many real-world problems. However, its limitations—particularly computational cost and sensitivity to dimensionality—motivate the more sophisticated algorithms we'll explore in subsequent chapters, starting with Decision Trees in Chapter 3.</p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 | CC BY-NC-SA 4.0 DEED </div> </div> <div class=md-social> <a href=https://github.com/AnvithPothula target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/anvith-pothula target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>