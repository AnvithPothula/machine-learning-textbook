<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A comprehensive intelligent textbook on machine learning algorithms and applications"><meta name=author content="Anvith Pothula"><link href=https://example.com/chapters/03-decision-trees/ rel=canonical><link href=../02-k-nearest-neighbors/quiz/ rel=prev><link href=quiz/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Content - Machine Learning - Algorithms and Applications</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#decision-trees-and-tree-based-learning class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-header__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Machine Learning - Algorithms and Applications </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Content </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../course-description/ class=md-tabs__link> Course Description </a> </li> <li class=md-tabs__item> <a href=../../faq/ class=md-tabs__link> FAQ </a> </li> <li class=md-tabs__item> <a href=../../glossary/ class=md-tabs__link> Glossary </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Chapters </a> </li> <li class=md-tabs__item> <a href=../../learning-graph/ class=md-tabs__link> Learning Graph </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-nav__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Machine Learning - Algorithms and Applications </label> <div class=md-nav__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-nav__item> <a href=../../course-description/ class=md-nav__link> <span class=md-ellipsis> Course Description </span> </a> </li> <li class=md-nav__item> <a href=../../faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> <li class=md-nav__item> <a href=../../glossary/ class=md-nav__link> <span class=md-ellipsis> Glossary </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> Chapters </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Chapters </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_2> <label class=md-nav__link for=__nav_5_2 id=__nav_5_2_label tabindex> <span class=md-ellipsis> 1. ML Fundamentals </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> 1. ML Fundamentals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_3> <label class=md-nav__link for=__nav_5_3 id=__nav_5_3_label tabindex> <span class=md-ellipsis> 2. K-Nearest Neighbors </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_3_label aria-expanded=false> <label class=md-nav__title for=__nav_5_3> <span class="md-nav__icon md-icon"></span> 2. K-Nearest Neighbors </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../02-k-nearest-neighbors/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../02-k-nearest-neighbors/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_4 checked> <label class=md-nav__link for=__nav_5_4 id=__nav_5_4_label tabindex> <span class=md-ellipsis> 3. Decision Trees </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_4_label aria-expanded=true> <label class=md-nav__title for=__nav_5_4> <span class="md-nav__icon md-icon"></span> 3. Decision Trees </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Content </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Content </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#the-intuition-behind-decision-trees class=md-nav__link> <span class=md-ellipsis> The Intuition Behind Decision Trees </span> </a> <nav class=md-nav aria-label="The Intuition Behind Decision Trees"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#a-simple-example-predicting-tumor-diagnosis class=md-nav__link> <span class=md-ellipsis> A Simple Example: Predicting Tumor Diagnosis </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#tree-structure-nodes-splits-and-leaves class=md-nav__link> <span class=md-ellipsis> Tree Structure: Nodes, Splits, and Leaves </span> </a> <nav class=md-nav aria-label="Tree Structure: Nodes, Splits, and Leaves"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#how-trees-make-predictions class=md-nav__link> <span class=md-ellipsis> How Trees Make Predictions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#building-trees-the-recursive-partitioning-algorithm class=md-nav__link> <span class=md-ellipsis> Building Trees: The Recursive Partitioning Algorithm </span> </a> </li> <li class=md-nav__item> <a href=#splitting-criteria-measuring-impurity class=md-nav__link> <span class=md-ellipsis> Splitting Criteria: Measuring Impurity </span> </a> <nav class=md-nav aria-label="Splitting Criteria: Measuring Impurity"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#entropy-and-information-gain class=md-nav__link> <span class=md-ellipsis> Entropy and Information Gain </span> </a> </li> <li class=md-nav__item> <a href=#gini-impurity class=md-nav__link> <span class=md-ellipsis> Gini Impurity </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#overfitting-and-underfitting-the-bias-variance-tradeoff class=md-nav__link> <span class=md-ellipsis> Overfitting and Underfitting: The Bias-Variance Tradeoff </span> </a> <nav class=md-nav aria-label="Overfitting and Underfitting: The Bias-Variance Tradeoff"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#controlling-tree-complexity class=md-nav__link> <span class=md-ellipsis> Controlling Tree Complexity </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#feature-space-partitioning class=md-nav__link> <span class=md-ellipsis> Feature Space Partitioning </span> </a> </li> <li class=md-nav__item> <a href=#loss-functions-and-cross-entropy-loss class=md-nav__link> <span class=md-ellipsis> Loss Functions and Cross-Entropy Loss </span> </a> </li> <li class=md-nav__item> <a href=#visualizing-decision-trees class=md-nav__link> <span class=md-ellipsis> Visualizing Decision Trees </span> </a> </li> <li class=md-nav__item> <a href=#practical-considerations-and-best-practices class=md-nav__link> <span class=md-ellipsis> Practical Considerations and Best Practices </span> </a> </li> <li class=md-nav__item> <a href=#random-forests-ensemble-of-trees class=md-nav__link> <span class=md-ellipsis> Random Forests: Ensemble of Trees </span> </a> </li> <li class=md-nav__item> <a href=#key-takeaways class=md-nav__link> <span class=md-ellipsis> Key Takeaways </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_5> <label class=md-nav__link for=__nav_5_5 id=__nav_5_5_label tabindex> <span class=md-ellipsis> 4. Logistic Regression </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5_5> <span class="md-nav__icon md-icon"></span> 4. Logistic Regression </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../04-logistic-regression/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../04-logistic-regression/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_6> <label class=md-nav__link for=__nav_5_6 id=__nav_5_6_label tabindex> <span class=md-ellipsis> 5. Regularization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_6_label aria-expanded=false> <label class=md-nav__title for=__nav_5_6> <span class="md-nav__icon md-icon"></span> 5. Regularization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../05-regularization/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../05-regularization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_7> <label class=md-nav__link for=__nav_5_7 id=__nav_5_7_label tabindex> <span class=md-ellipsis> 6. Support Vector Machines </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_7_label aria-expanded=false> <label class=md-nav__title for=__nav_5_7> <span class="md-nav__icon md-icon"></span> 6. Support Vector Machines </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../06-support-vector-machines/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../06-support-vector-machines/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_8> <label class=md-nav__link for=__nav_5_8 id=__nav_5_8_label tabindex> <span class=md-ellipsis> 7. K-Means Clustering </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_8_label aria-expanded=false> <label class=md-nav__title for=__nav_5_8> <span class="md-nav__icon md-icon"></span> 7. K-Means Clustering </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../07-k-means-clustering/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../07-k-means-clustering/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_9> <label class=md-nav__link for=__nav_5_9 id=__nav_5_9_label tabindex> <span class=md-ellipsis> 8. Data Preprocessing </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_9_label aria-expanded=false> <label class=md-nav__title for=__nav_5_9> <span class="md-nav__icon md-icon"></span> 8. Data Preprocessing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../08-data-preprocessing/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../08-data-preprocessing/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_10> <label class=md-nav__link for=__nav_5_10 id=__nav_5_10_label tabindex> <span class=md-ellipsis> 9. Neural Networks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_10_label aria-expanded=false> <label class=md-nav__title for=__nav_5_10> <span class="md-nav__icon md-icon"></span> 9. Neural Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../09-neural-networks/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../09-neural-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_11> <label class=md-nav__link for=__nav_5_11 id=__nav_5_11_label tabindex> <span class=md-ellipsis> 10. Convolutional Networks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_11_label aria-expanded=false> <label class=md-nav__title for=__nav_5_11> <span class="md-nav__icon md-icon"></span> 10. Convolutional Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../10-convolutional-networks/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../10-convolutional-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_12> <label class=md-nav__link for=__nav_5_12 id=__nav_5_12_label tabindex> <span class=md-ellipsis> 11. Transfer Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_12_label aria-expanded=false> <label class=md-nav__title for=__nav_5_12> <span class="md-nav__icon md-icon"></span> 11. Transfer Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../11-transfer-learning/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../11-transfer-learning/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_13> <label class=md-nav__link for=__nav_5_13 id=__nav_5_13_label tabindex> <span class=md-ellipsis> 12. Evaluation & Optimization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_13_label aria-expanded=false> <label class=md-nav__title for=__nav_5_13> <span class="md-nav__icon md-icon"></span> 12. Evaluation & Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../12-evaluation-optimization/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../12-evaluation-optimization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Learning Graph </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Learning Graph </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../learning-graph/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../sims/graph-viewer/ class=md-nav__link> <span class=md-ellipsis> Graph Viewer </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/course-description-assessment/ class=md-nav__link> <span class=md-ellipsis> Course Description Assessment </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-list/ class=md-nav__link> <span class=md-ellipsis> Concept List </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-taxonomy/ class=md-nav__link> <span class=md-ellipsis> Concept Taxonomy </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.csv class=md-nav__link> <span class=md-ellipsis> Learning Graph (CSV) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.json class=md-nav__link> <span class=md-ellipsis> Learning Graph (JSON) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/quality-metrics/ class=md-nav__link> <span class=md-ellipsis> Quality Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/taxonomy-distribution/ class=md-nav__link> <span class=md-ellipsis> Taxonomy Distribution </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/glossary-quality-report/ class=md-nav__link> <span class=md-ellipsis> Glossary Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-quality-report/ class=md-nav__link> <span class=md-ellipsis> FAQ Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-coverage-gaps/ class=md-nav__link> <span class=md-ellipsis> FAQ Coverage Gaps </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#the-intuition-behind-decision-trees class=md-nav__link> <span class=md-ellipsis> The Intuition Behind Decision Trees </span> </a> <nav class=md-nav aria-label="The Intuition Behind Decision Trees"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#a-simple-example-predicting-tumor-diagnosis class=md-nav__link> <span class=md-ellipsis> A Simple Example: Predicting Tumor Diagnosis </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#tree-structure-nodes-splits-and-leaves class=md-nav__link> <span class=md-ellipsis> Tree Structure: Nodes, Splits, and Leaves </span> </a> <nav class=md-nav aria-label="Tree Structure: Nodes, Splits, and Leaves"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#how-trees-make-predictions class=md-nav__link> <span class=md-ellipsis> How Trees Make Predictions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#building-trees-the-recursive-partitioning-algorithm class=md-nav__link> <span class=md-ellipsis> Building Trees: The Recursive Partitioning Algorithm </span> </a> </li> <li class=md-nav__item> <a href=#splitting-criteria-measuring-impurity class=md-nav__link> <span class=md-ellipsis> Splitting Criteria: Measuring Impurity </span> </a> <nav class=md-nav aria-label="Splitting Criteria: Measuring Impurity"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#entropy-and-information-gain class=md-nav__link> <span class=md-ellipsis> Entropy and Information Gain </span> </a> </li> <li class=md-nav__item> <a href=#gini-impurity class=md-nav__link> <span class=md-ellipsis> Gini Impurity </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#overfitting-and-underfitting-the-bias-variance-tradeoff class=md-nav__link> <span class=md-ellipsis> Overfitting and Underfitting: The Bias-Variance Tradeoff </span> </a> <nav class=md-nav aria-label="Overfitting and Underfitting: The Bias-Variance Tradeoff"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#controlling-tree-complexity class=md-nav__link> <span class=md-ellipsis> Controlling Tree Complexity </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#feature-space-partitioning class=md-nav__link> <span class=md-ellipsis> Feature Space Partitioning </span> </a> </li> <li class=md-nav__item> <a href=#loss-functions-and-cross-entropy-loss class=md-nav__link> <span class=md-ellipsis> Loss Functions and Cross-Entropy Loss </span> </a> </li> <li class=md-nav__item> <a href=#visualizing-decision-trees class=md-nav__link> <span class=md-ellipsis> Visualizing Decision Trees </span> </a> </li> <li class=md-nav__item> <a href=#practical-considerations-and-best-practices class=md-nav__link> <span class=md-ellipsis> Practical Considerations and Best Practices </span> </a> </li> <li class=md-nav__item> <a href=#random-forests-ensemble-of-trees class=md-nav__link> <span class=md-ellipsis> Random Forests: Ensemble of Trees </span> </a> </li> <li class=md-nav__item> <a href=#key-takeaways class=md-nav__link> <span class=md-ellipsis> Key Takeaways </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=decision-trees-and-tree-based-learning>Decision Trees and Tree-Based Learning<a class=headerlink href=#decision-trees-and-tree-based-learning title="Permanent link">&para;</a></h1> <hr> <p>title: Decision Trees and Tree-Based Learning description: Recursive partitioning, splitting criteria (entropy, information gain, Gini impurity), overfitting, underfitting, and tree complexity control generated_by: claude skill chapter-content-generator date: 2025-12-28 version: 0.03</p> <hr> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">&para;</a></h2> <p>This chapter explores decision trees, one of the most interpretable and widely-used machine learning algorithms. Students will learn how decision trees recursively partition the feature space to make predictions, understand the mathematical foundations of splitting criteria including entropy, information gain, and Gini impurity, and discover how to control tree complexity through pruning and depth limits. The chapter introduces the critical concepts of overfitting and underfitting that apply across all machine learning algorithms, and demonstrates how decision trees handle both categorical and continuous features while creating clear decision boundaries.</p> <h2 id=concepts-covered>Concepts Covered<a class=headerlink href=#concepts-covered title="Permanent link">&para;</a></h2> <p>This chapter covers the following 14 concepts from the learning graph:</p> <ol> <li>Decision Tree</li> <li>Tree Node</li> <li>Leaf Node</li> <li>Splitting Criterion</li> <li>Entropy</li> <li>Information Gain</li> <li>Gini Impurity</li> <li>Pruning</li> <li>Overfitting</li> <li>Underfitting</li> <li>Tree Depth</li> <li>Feature Space Partitioning</li> <li>Loss Function</li> <li>Cross-Entropy Loss</li> </ol> <h2 id=prerequisites>Prerequisites<a class=headerlink href=#prerequisites title="Permanent link">&para;</a></h2> <p>This chapter builds on concepts from:</p> <ul> <li><a href=../01-intro-to-ml-fundamentals/ >Chapter 1: Introduction to Machine Learning Fundamentals</a></li> </ul> <hr> <h2 id=the-intuition-behind-decision-trees>The Intuition Behind Decision Trees<a class=headerlink href=#the-intuition-behind-decision-trees title="Permanent link">&para;</a></h2> <p>Imagine you're a doctor diagnosing whether a patient has a disease. You might ask a series of questions: "Is the patient's temperature above 100°F?" If yes, "Does the patient have a cough?" If yes, "Has the cough lasted more than a week?" Based on the answers to these sequential yes/no questions, you arrive at a diagnosis. This is precisely how decision trees work—they make predictions by asking a series of questions about features, following a tree-like structure from root to leaf.</p> <p>Decision trees are supervised learning algorithms that recursively partition the feature space into regions, each associated with a predicted class (classification) or value (regression). Unlike KNN, which stores all training data, decision trees learn explicit rules during training, creating an interpretable model that humans can understand and validate.</p> <p>The algorithm's power lies in its simplicity and interpretability. A trained decision tree can be visualized as a flowchart where internal nodes represent feature tests, branches represent outcomes of those tests, and leaf nodes represent final predictions. This transparency makes decision trees particularly valuable in domains requiring explainable AI, such as healthcare, finance, and legal applications.</p> <h3 id=a-simple-example-predicting-tumor-diagnosis>A Simple Example: Predicting Tumor Diagnosis<a class=headerlink href=#a-simple-example-predicting-tumor-diagnosis title="Permanent link">&para;</a></h3> <p>Let's build intuition with a medical example using the Breast Cancer Wisconsin dataset, which contains measurements of cell nuclei from breast masses. The task: predict whether a tumor is malignant (cancerous) or benign (non-cancerous) based on features like radius, texture, and smoothness.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_breast_cancer</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.tree</span><span class=w> </span><span class=kn>import</span> <span class=n>DecisionTreeClassifier</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>accuracy_score</span><span class=p>,</span> <span class=n>confusion_matrix</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a><span class=kn>import</span><span class=w> </span><span class=nn>seaborn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>sns</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=c1># Load breast cancer dataset</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a><span class=n>cancer</span> <span class=o>=</span> <span class=n>load_breast_cancer</span><span class=p>()</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a><span class=n>X</span> <span class=o>=</span> <span class=n>cancer</span><span class=o>.</span><span class=n>data</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a><span class=n>y</span> <span class=o>=</span> <span class=n>cancer</span><span class=o>.</span><span class=n>target</span>  <span class=c1># 0 = malignant, 1 = benign</span>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a><span class=c1># Create DataFrame for exploration</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a><span class=n>cancer_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>columns</span><span class=o>=</span><span class=n>cancer</span><span class=o>.</span><span class=n>feature_names</span><span class=p>)</span>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a><span class=n>cancer_df</span><span class=p>[</span><span class=s1>&#39;diagnosis&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>Categorical</span><span class=o>.</span><span class=n>from_codes</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=p>[</span><span class=s1>&#39;malignant&#39;</span><span class=p>,</span> <span class=s1>&#39;benign&#39;</span><span class=p>])</span>
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Dataset shape:&quot;</span><span class=p>,</span> <span class=n>cancer_df</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Class distribution:&quot;</span><span class=p>)</span>
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a><span class=nb>print</span><span class=p>(</span><span class=n>cancer_df</span><span class=p>[</span><span class=s1>&#39;diagnosis&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>value_counts</span><span class=p>())</span>
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>First 5 feature columns:&quot;</span><span class=p>)</span>
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a><span class=nb>print</span><span class=p>(</span><span class=n>cancer_df</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span> <span class=p>:</span><span class=mi>5</span><span class=p>]</span><span class=o>.</span><span class=n>head</span><span class=p>())</span>
</span></code></pre></div> <p>This dataset contains 569 tumor samples with 30 features each. A decision tree will learn which features best distinguish malignant from benign tumors.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># Visualize feature relationships</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=n>selected_features</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;mean radius&#39;</span><span class=p>,</span> <span class=s1>&#39;mean texture&#39;</span><span class=p>,</span> <span class=s1>&#39;mean perimeter&#39;</span><span class=p>,</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>                     <span class=s1>&#39;mean area&#39;</span><span class=p>,</span> <span class=s1>&#39;mean smoothness&#39;</span><span class=p>]</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=n>sns</span><span class=o>.</span><span class=n>pairplot</span><span class=p>(</span><span class=n>cancer_df</span><span class=p>,</span> <span class=nb>vars</span><span class=o>=</span><span class=n>selected_features</span><span class=p>,</span> <span class=n>hue</span><span class=o>=</span><span class=s1>&#39;diagnosis&#39;</span><span class=p>,</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a>             <span class=n>markers</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;o&quot;</span><span class=p>,</span> <span class=s2>&quot;s&quot;</span><span class=p>],</span> <span class=n>palette</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;malignant&#39;</span><span class=p>:</span> <span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=s1>&#39;benign&#39;</span><span class=p>:</span> <span class=s1>&#39;blue&#39;</span><span class=p>})</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a><span class=n>plt</span><span class=o>.</span><span class=n>suptitle</span><span class=p>(</span><span class=s2>&quot;Breast Cancer Features by Diagnosis&quot;</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=mf>1.02</span><span class=p>)</span>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>Notice how malignant and benign tumors occupy different regions in feature space. Decision trees identify these boundaries by asking questions like "Is mean radius &gt; 15?" to separate classes.</p> <div class="admonition note"> <p class=admonition-title>Interpretability Advantage</p> <p>Unlike neural networks (black boxes), decision trees produce human-readable rules like: "If radius &gt; 15 AND texture &gt; 20, predict malignant." This transparency is crucial when decisions affect human lives.</p> </div> <h2 id=tree-structure-nodes-splits-and-leaves>Tree Structure: Nodes, Splits, and Leaves<a class=headerlink href=#tree-structure-nodes-splits-and-leaves title="Permanent link">&para;</a></h2> <p>A decision tree consists of three types of components organized in a hierarchical structure:</p> <p><strong>Tree Node (Internal Node)</strong>: A decision point that tests a feature - Contains a splitting criterion (e.g., "radius_mean ≤ 15.0") - Has two or more child nodes (binary trees use two) - Represents a partition of the data based on feature values</p> <p><strong>Leaf Node (Terminal Node)</strong>: An endpoint that makes predictions - Contains no children - Stores the final prediction (class label or numerical value) - Represents a region of feature space with homogeneous outcomes</p> <p><strong>Tree Depth</strong>: The longest path from root to any leaf - Depth 0: Only root node (no splits) - Deeper trees can capture more complex patterns - Excessive depth leads to overfitting</p> <h4 id=decision-tree-structure>Decision Tree Structure<a class=headerlink href=#decision-tree-structure title="Permanent link">&para;</a></h4> <pre class=mermaid><code>graph TD
    Root(("Root Node&lt;br/&gt;radius_mean ≤ 15.0&lt;br/&gt;samples=460"))
    Left(("Internal Node&lt;br/&gt;texture_mean ≤ 20.0&lt;br/&gt;samples=250"))
    Right(("Internal Node&lt;br/&gt;smoothness_mean ≤ 0.1&lt;br/&gt;samples=210"))
    Leaf1["Leaf: Benign&lt;br/&gt;n=150&lt;br/&gt;probability=0.95"]
    Leaf2["Leaf: Malignant&lt;br/&gt;n=100&lt;br/&gt;probability=0.30"]
    Leaf3["Leaf: Benign&lt;br/&gt;n=170&lt;br/&gt;probability=0.90"]
    Leaf4["Leaf: Malignant&lt;br/&gt;n=40&lt;br/&gt;probability=0.85"]

    Root --&gt;|True ≤ 15.0| Left
    Root --&gt;|False &gt; 15.0| Right
    Left --&gt;|True ≤ 20.0| Leaf1
    Left --&gt;|False &gt; 20.0| Leaf2
    Right --&gt;|True ≤ 0.1| Leaf3
    Right --&gt;|False &gt; 0.1| Leaf4

    classDef decisionNode fill:#90CAF9,stroke:#1976D2,stroke-width:3px,color:#000,font-size:14px
    classDef benignLeaf fill:#81C784,stroke:#388E3C,stroke-width:2px,color:#000,font-size:14px
    classDef malignantLeaf fill:#E57373,stroke:#D32F2F,stroke-width:2px,color:#000,font-size:14px

    class Root,Left,Right decisionNode
    class Leaf1,Leaf3 benignLeaf
    class Leaf2,Leaf4 malignantLeaf

    linkStyle default stroke:#666,stroke-width:2px,font-size:12px</code></pre> <p><strong>Tree Depth</strong>: 2 levels | <strong>Recursive Partitioning</strong>: Each internal node tests a feature and splits data based on a threshold value | <strong>Final Predictions</strong>: Leaf nodes contain class predictions with sample counts</p> <h3 id=how-trees-make-predictions>How Trees Make Predictions<a class=headerlink href=#how-trees-make-predictions title="Permanent link">&para;</a></h3> <p>Given a new sample, the tree makes a prediction by:</p> <ol> <li>Start at the root node</li> <li>Evaluate the feature test (e.g., "Is radius_mean ≤ 15.0?")</li> <li>Follow the branch corresponding to the test result (True → left, False → right)</li> <li>Repeat steps 2-3 at each internal node until reaching a leaf</li> <li>Return the leaf's prediction (majority class for classification)</li> </ol> <p>This process is deterministic—the same input always produces the same prediction by following the same path through the tree.</p> <h2 id=building-trees-the-recursive-partitioning-algorithm>Building Trees: The Recursive Partitioning Algorithm<a class=headerlink href=#building-trees-the-recursive-partitioning-algorithm title="Permanent link">&para;</a></h2> <p>Decision trees are constructed using a greedy, top-down recursive algorithm:</p> <p><strong>Algorithm: Decision Tree Learning</strong></p> <ol> <li>Start with all training data at the root</li> <li>Find the best feature and threshold to split data (maximize information gain or minimize impurity)</li> <li>Create two child nodes and partition data accordingly</li> <li>Recursively repeat steps 2-3 for each child node</li> <li>Stop when:</li> <li>All samples in a node belong to the same class (pure node)</li> <li>Maximum depth is reached</li> <li>Minimum samples threshold is met</li> <li>No split improves the criterion</li> </ol> <p>The key challenge: How do we determine the "best" split? This requires quantifying how well a split separates classes.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># Train a decision tree classifier</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a>    <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.25</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=p>)</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a><span class=c1># Create decision tree with default settings</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a><span class=n>dt_classifier</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a><span class=n>dt_classifier</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Decision tree trained successfully&quot;</span><span class=p>)</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Tree depth: </span><span class=si>{</span><span class=n>dt_classifier</span><span class=o>.</span><span class=n>get_depth</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Number of leaves: </span><span class=si>{</span><span class=n>dt_classifier</span><span class=o>.</span><span class=n>get_n_leaves</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Number of features used: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>dt_classifier</span><span class=o>.</span><span class=n>feature_importances_</span><span class=w> </span><span class=o>&gt;</span><span class=w> </span><span class=mi>0</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a>
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a><span class=c1># Make predictions</span>
</span><span id=__span-2-16><a id=__codelineno-2-16 name=__codelineno-2-16 href=#__codelineno-2-16></a><span class=n>y_pred</span> <span class=o>=</span> <span class=n>dt_classifier</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-2-17><a id=__codelineno-2-17 name=__codelineno-2-17 href=#__codelineno-2-17></a><span class=n>test_accuracy</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span><span id=__span-2-18><a id=__codelineno-2-18 name=__codelineno-2-18 href=#__codelineno-2-18></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Test accuracy: </span><span class=si>{</span><span class=n>test_accuracy</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-19><a id=__codelineno-2-19 name=__codelineno-2-19 href=#__codelineno-2-19></a>
</span><span id=__span-2-20><a id=__codelineno-2-20 name=__codelineno-2-20 href=#__codelineno-2-20></a><span class=c1># Confusion matrix</span>
</span><span id=__span-2-21><a id=__codelineno-2-21 name=__codelineno-2-21 href=#__codelineno-2-21></a><span class=n>cm</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span><span id=__span-2-22><a id=__codelineno-2-22 name=__codelineno-2-22 href=#__codelineno-2-22></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-2-23><a id=__codelineno-2-23 name=__codelineno-2-23 href=#__codelineno-2-23></a><span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>cm</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s1>&#39;d&#39;</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;Blues&#39;</span><span class=p>,</span>
</span><span id=__span-2-24><a id=__codelineno-2-24 name=__codelineno-2-24 href=#__codelineno-2-24></a>            <span class=n>xticklabels</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;Malignant&#39;</span><span class=p>,</span> <span class=s1>&#39;Benign&#39;</span><span class=p>],</span>
</span><span id=__span-2-25><a id=__codelineno-2-25 name=__codelineno-2-25 href=#__codelineno-2-25></a>            <span class=n>yticklabels</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;Malignant&#39;</span><span class=p>,</span> <span class=s1>&#39;Benign&#39;</span><span class=p>])</span>
</span><span id=__span-2-26><a id=__codelineno-2-26 name=__codelineno-2-26 href=#__codelineno-2-26></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Decision Tree Confusion Matrix&#39;</span><span class=p>)</span>
</span><span id=__span-2-27><a id=__codelineno-2-27 name=__codelineno-2-27 href=#__codelineno-2-27></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True Label&#39;</span><span class=p>)</span>
</span><span id=__span-2-28><a id=__codelineno-2-28 name=__codelineno-2-28 href=#__codelineno-2-28></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Predicted Label&#39;</span><span class=p>)</span>
</span><span id=__span-2-29><a id=__codelineno-2-29 name=__codelineno-2-29 href=#__codelineno-2-29></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>Even with default settings, decision trees often achieve high accuracy. But what criteria does the algorithm use to choose splits?</p> <h2 id=splitting-criteria-measuring-impurity>Splitting Criteria: Measuring Impurity<a class=headerlink href=#splitting-criteria-measuring-impurity title="Permanent link">&para;</a></h2> <p>A <strong>splitting criterion</strong> is a mathematical function that quantifies how "pure" or "mixed" a node's class distribution is. The algorithm searches for splits that reduce impurity, creating more homogeneous child nodes.</p> <h3 id=entropy-and-information-gain>Entropy and Information Gain<a class=headerlink href=#entropy-and-information-gain title="Permanent link">&para;</a></h3> <p><strong>Entropy</strong> measures the randomness or disorder in a set of class labels. For a node with class distribution <span class=arithmatex>\(p_1, p_2, ..., p_k\)</span>, entropy is:</p> <div class=arithmatex>\[H(S) = -\sum_{i=1}^{k} p_i \log_2(p_i)\]</div> <p>where <span class=arithmatex>\(p_i\)</span> is the proportion of samples in class <span class=arithmatex>\(i\)</span>.</p> <p>Properties of entropy: - Minimum entropy = 0 (all samples in one class—perfectly pure) - Maximum entropy = <span class=arithmatex>\(\log_2(k)\)</span> (uniform distribution—maximally mixed) - For binary classification: max entropy = 1 when <span class=arithmatex>\(p_1 = p_2 = 0.5\)</span></p> <p><strong>Information Gain</strong> measures the reduction in entropy achieved by a split:</p> <div class=arithmatex>\[IG(S, A) = H(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} H(S_v)\]</div> <p>where: - <span class=arithmatex>\(S\)</span> = parent node samples - <span class=arithmatex>\(A\)</span> = feature being tested - <span class=arithmatex>\(S_v\)</span> = subset of samples where feature <span class=arithmatex>\(A\)</span> has value <span class=arithmatex>\(v\)</span> - <span class=arithmatex>\(\frac{|S_v|}{|S|}\)</span> = proportion of samples in subset <span class=arithmatex>\(v\)</span></p> <p>The decision tree algorithm selects the split with maximum information gain at each node.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># Example: Calculate entropy for a node</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=k>def</span><span class=w> </span><span class=nf>calculate_entropy</span><span class=p>(</span><span class=n>labels</span><span class=p>):</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Calculate entropy of a label distribution.&quot;&quot;&quot;</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>    <span class=n>_</span><span class=p>,</span> <span class=n>counts</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>return_counts</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>    <span class=n>probabilities</span> <span class=o>=</span> <span class=n>counts</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>    <span class=n>entropy</span> <span class=o>=</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>probabilities</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log2</span><span class=p>(</span><span class=n>probabilities</span> <span class=o>+</span> <span class=mf>1e-10</span><span class=p>))</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>    <span class=k>return</span> <span class=n>entropy</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a><span class=c1># Example node with 50 benign, 50 malignant samples</span>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a><span class=n>mixed_node</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=mi>50</span> <span class=o>+</span> <span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=mi>50</span><span class=p>)</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a><span class=n>pure_node</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=mi>100</span><span class=p>)</span>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Entropy of mixed node (50/50): </span><span class=si>{</span><span class=n>calculate_entropy</span><span class=p>(</span><span class=n>mixed_node</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Entropy of pure node (100/0): </span><span class=si>{</span><span class=n>calculate_entropy</span><span class=p>(</span><span class=n>pure_node</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-3-15><a id=__codelineno-3-15 name=__codelineno-3-15 href=#__codelineno-3-15></a>
</span><span id=__span-3-16><a id=__codelineno-3-16 name=__codelineno-3-16 href=#__codelineno-3-16></a><span class=c1># After a good split: 10 malignant + 90 benign vs 40 malignant + 10 benign</span>
</span><span id=__span-3-17><a id=__codelineno-3-17 name=__codelineno-3-17 href=#__codelineno-3-17></a><span class=n>left_child</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=mi>90</span> <span class=o>+</span> <span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=mi>10</span><span class=p>)</span>
</span><span id=__span-3-18><a id=__codelineno-3-18 name=__codelineno-3-18 href=#__codelineno-3-18></a><span class=n>right_child</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=mi>10</span> <span class=o>+</span> <span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=mi>40</span><span class=p>)</span>
</span><span id=__span-3-19><a id=__codelineno-3-19 name=__codelineno-3-19 href=#__codelineno-3-19></a>
</span><span id=__span-3-20><a id=__codelineno-3-20 name=__codelineno-3-20 href=#__codelineno-3-20></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Entropy of left child: </span><span class=si>{</span><span class=n>calculate_entropy</span><span class=p>(</span><span class=n>left_child</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-3-21><a id=__codelineno-3-21 name=__codelineno-3-21 href=#__codelineno-3-21></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Entropy of right child: </span><span class=si>{</span><span class=n>calculate_entropy</span><span class=p>(</span><span class=n>right_child</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-3-22><a id=__codelineno-3-22 name=__codelineno-3-22 href=#__codelineno-3-22></a>
</span><span id=__span-3-23><a id=__codelineno-3-23 name=__codelineno-3-23 href=#__codelineno-3-23></a><span class=c1># Weighted average entropy after split</span>
</span><span id=__span-3-24><a id=__codelineno-3-24 name=__codelineno-3-24 href=#__codelineno-3-24></a><span class=n>weighted_entropy</span> <span class=o>=</span> <span class=p>(</span><span class=mi>100</span><span class=o>/</span><span class=mi>150</span> <span class=o>*</span> <span class=n>calculate_entropy</span><span class=p>(</span><span class=n>left_child</span><span class=p>)</span> <span class=o>+</span>
</span><span id=__span-3-25><a id=__codelineno-3-25 name=__codelineno-3-25 href=#__codelineno-3-25></a>                   <span class=mi>50</span><span class=o>/</span><span class=mi>150</span> <span class=o>*</span> <span class=n>calculate_entropy</span><span class=p>(</span><span class=n>right_child</span><span class=p>))</span>
</span><span id=__span-3-26><a id=__codelineno-3-26 name=__codelineno-3-26 href=#__codelineno-3-26></a><span class=n>info_gain</span> <span class=o>=</span> <span class=n>calculate_entropy</span><span class=p>(</span><span class=n>mixed_node</span><span class=p>)</span> <span class=o>-</span> <span class=n>weighted_entropy</span>
</span><span id=__span-3-27><a id=__codelineno-3-27 name=__codelineno-3-27 href=#__codelineno-3-27></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Information gain from split: </span><span class=si>{</span><span class=n>info_gain</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=gini-impurity>Gini Impurity<a class=headerlink href=#gini-impurity title="Permanent link">&para;</a></h3> <p>An alternative to entropy is <strong>Gini impurity</strong>, which measures the probability of misclassifying a randomly chosen element:</p> <div class=arithmatex>\[Gini(S) = 1 - \sum_{i=1}^{k} p_i^2\]</div> <p>Properties: - Minimum Gini = 0 (pure node) - Maximum Gini = <span class=arithmatex>\(1 - \frac{1}{k}\)</span> for <span class=arithmatex>\(k\)</span> classes (uniform distribution) - For binary classification: max Gini = 0.5 when <span class=arithmatex>\(p_1 = p_2 = 0.5\)</span></p> <p>Gini impurity is computationally cheaper than entropy (no logarithms) and often produces similar trees. Scikit-learn uses Gini by default.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=k>def</span><span class=w> </span><span class=nf>calculate_gini</span><span class=p>(</span><span class=n>labels</span><span class=p>):</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Calculate Gini impurity of a label distribution.&quot;&quot;&quot;</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>    <span class=n>_</span><span class=p>,</span> <span class=n>counts</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>return_counts</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>    <span class=n>probabilities</span> <span class=o>=</span> <span class=n>counts</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>    <span class=n>gini</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>probabilities</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>    <span class=k>return</span> <span class=n>gini</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Gini of mixed node (50/50): </span><span class=si>{</span><span class=n>calculate_gini</span><span class=p>(</span><span class=n>mixed_node</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Gini of pure node (100/0): </span><span class=si>{</span><span class=n>calculate_gini</span><span class=p>(</span><span class=n>pure_node</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Gini of left child: </span><span class=si>{</span><span class=n>calculate_gini</span><span class=p>(</span><span class=n>left_child</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Gini of right child: </span><span class=si>{</span><span class=n>calculate_gini</span><span class=p>(</span><span class=n>right_child</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>The comparison:</p> <table> <thead> <tr> <th>Criterion</th> <th>Formula</th> <th>Range (binary)</th> <th>Computation</th> <th>Common Use</th> </tr> </thead> <tbody> <tr> <td><strong>Entropy</strong></td> <td><span class=arithmatex>\(-\sum p_i \log_2(p_i)\)</span></td> <td>[0, 1]</td> <td>Slower (log)</td> <td>Theoretical analysis, information theory</td> </tr> <tr> <td><strong>Gini Impurity</strong></td> <td><span class=arithmatex>\(1 - \sum p_i^2\)</span></td> <td>[0, 0.5]</td> <td>Faster (squares)</td> <td>Default in scikit-learn, practical applications</td> </tr> </tbody> </table> <p>Both criteria produce similar trees in practice. Entropy tends to favor more balanced splits, while Gini may create slightly more skewed partitions.</p> <h4 id=entropy-and-gini-impurity-interactive-comparison>Entropy and Gini Impurity Interactive Comparison<a class=headerlink href=#entropy-and-gini-impurity-interactive-comparison title="Permanent link">&para;</a></h4> <iframe src=../../sims/entropy-gini-comparison/main.html width=100% height=780px style="border: 1px solid #ccc; border-radius: 4px;"></iframe> <p><a class=md-button href=../../sims/entropy-gini-comparison/main.html target=_blank>View Fullscreen</a> | <a href=../../sims/entropy-gini-comparison/ >Documentation</a></p> <p>This interactive visualization compares entropy (blue) and Gini impurity (orange) as class proportions change. Move the slider to see how both measures respond, and click the split buttons to see examples of high and low information gain splits. Both measures peak at 50/50 distribution (maximum uncertainty) and reach zero for pure nodes.</p> <h2 id=overfitting-and-underfitting-the-bias-variance-tradeoff>Overfitting and Underfitting: The Bias-Variance Tradeoff<a class=headerlink href=#overfitting-and-underfitting-the-bias-variance-tradeoff title="Permanent link">&para;</a></h2> <p>Decision trees naturally tend toward <strong>overfitting</strong>—learning patterns specific to the training data that don't generalize to new data. This occurs because trees can grow arbitrarily deep, creating complex decision boundaries that perfectly fit training samples but fail on test data.</p> <p><strong>Overfitting</strong>: Model is too complex - Symptoms: Training accuracy near 100%, much lower test accuracy - Cause: Tree depth too deep, capturing noise and outliers - Effect: Poor generalization to new data</p> <p><strong>Underfitting</strong>: Model is too simple - Symptoms: Low training and test accuracy - Cause: Tree depth too shallow, insufficient complexity - Effect: Cannot capture true patterns in data</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=c1># Demonstrate overfitting with unrestricted tree</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=n>dt_overfit</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>  <span class=c1># No depth limit</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=n>dt_overfit</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=n>train_acc_overfit</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_train</span><span class=p>,</span> <span class=n>dt_overfit</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_train</span><span class=p>))</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a><span class=n>test_acc_overfit</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>dt_overfit</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>))</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Overfitting Example (no depth limit):&quot;</span><span class=p>)</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Training accuracy: </span><span class=si>{</span><span class=n>train_acc_overfit</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Test accuracy: </span><span class=si>{</span><span class=n>test_acc_overfit</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Tree depth: </span><span class=si>{</span><span class=n>dt_overfit</span><span class=o>.</span><span class=n>get_depth</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Number of leaves: </span><span class=si>{</span><span class=n>dt_overfit</span><span class=o>.</span><span class=n>get_n_leaves</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a><span class=c1># Demonstrate underfitting with very shallow tree</span>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a><span class=n>dt_underfit</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>max_depth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a><span class=n>dt_underfit</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a><span class=n>train_acc_underfit</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_train</span><span class=p>,</span> <span class=n>dt_underfit</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_train</span><span class=p>))</span>
</span><span id=__span-5-19><a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a><span class=n>test_acc_underfit</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>dt_underfit</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>))</span>
</span><span id=__span-5-20><a id=__codelineno-5-20 name=__codelineno-5-20 href=#__codelineno-5-20></a>
</span><span id=__span-5-21><a id=__codelineno-5-21 name=__codelineno-5-21 href=#__codelineno-5-21></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Underfitting Example (max_depth=2):&quot;</span><span class=p>)</span>
</span><span id=__span-5-22><a id=__codelineno-5-22 name=__codelineno-5-22 href=#__codelineno-5-22></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Training accuracy: </span><span class=si>{</span><span class=n>train_acc_underfit</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-23><a id=__codelineno-5-23 name=__codelineno-5-23 href=#__codelineno-5-23></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Test accuracy: </span><span class=si>{</span><span class=n>test_acc_underfit</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-24><a id=__codelineno-5-24 name=__codelineno-5-24 href=#__codelineno-5-24></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Tree depth: </span><span class=si>{</span><span class=n>dt_underfit</span><span class=o>.</span><span class=n>get_depth</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-25><a id=__codelineno-5-25 name=__codelineno-5-25 href=#__codelineno-5-25></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Number of leaves: </span><span class=si>{</span><span class=n>dt_underfit</span><span class=o>.</span><span class=n>get_n_leaves</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-26><a id=__codelineno-5-26 name=__codelineno-5-26 href=#__codelineno-5-26></a>
</span><span id=__span-5-27><a id=__codelineno-5-27 name=__codelineno-5-27 href=#__codelineno-5-27></a><span class=c1># Optimal complexity</span>
</span><span id=__span-5-28><a id=__codelineno-5-28 name=__codelineno-5-28 href=#__codelineno-5-28></a><span class=n>dt_optimal</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>max_depth</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-5-29><a id=__codelineno-5-29 name=__codelineno-5-29 href=#__codelineno-5-29></a><span class=n>dt_optimal</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-5-30><a id=__codelineno-5-30 name=__codelineno-5-30 href=#__codelineno-5-30></a>
</span><span id=__span-5-31><a id=__codelineno-5-31 name=__codelineno-5-31 href=#__codelineno-5-31></a><span class=n>train_acc_optimal</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_train</span><span class=p>,</span> <span class=n>dt_optimal</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_train</span><span class=p>))</span>
</span><span id=__span-5-32><a id=__codelineno-5-32 name=__codelineno-5-32 href=#__codelineno-5-32></a><span class=n>test_acc_optimal</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>dt_optimal</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>))</span>
</span><span id=__span-5-33><a id=__codelineno-5-33 name=__codelineno-5-33 href=#__codelineno-5-33></a>
</span><span id=__span-5-34><a id=__codelineno-5-34 name=__codelineno-5-34 href=#__codelineno-5-34></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Balanced Example (max_depth=5):&quot;</span><span class=p>)</span>
</span><span id=__span-5-35><a id=__codelineno-5-35 name=__codelineno-5-35 href=#__codelineno-5-35></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Training accuracy: </span><span class=si>{</span><span class=n>train_acc_optimal</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-36><a id=__codelineno-5-36 name=__codelineno-5-36 href=#__codelineno-5-36></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Test accuracy: </span><span class=si>{</span><span class=n>test_acc_optimal</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-37><a id=__codelineno-5-37 name=__codelineno-5-37 href=#__codelineno-5-37></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Tree depth: </span><span class=si>{</span><span class=n>dt_optimal</span><span class=o>.</span><span class=n>get_depth</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-5-38><a id=__codelineno-5-38 name=__codelineno-5-38 href=#__codelineno-5-38></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Number of leaves: </span><span class=si>{</span><span class=n>dt_optimal</span><span class=o>.</span><span class=n>get_n_leaves</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <div class="admonition warning"> <p class=admonition-title>Perfect Training Accuracy is a Red Flag</p> <p>When a decision tree achieves 100% training accuracy, it's almost certainly overfitting. The tree has memorized specific training examples rather than learning general patterns.</p> </div> <h3 id=controlling-tree-complexity>Controlling Tree Complexity<a class=headerlink href=#controlling-tree-complexity title="Permanent link">&para;</a></h3> <p>To prevent overfitting, we constrain tree growth using hyperparameters:</p> <p><strong>Tree Depth (<code>max_depth</code>)</strong>: Maximum levels from root to leaf - Small depth → underfitting (too simple) - Large depth → overfitting (too complex) - Typical values: 3-10 for interpretability, 10-30 for performance</p> <p><strong>Minimum Samples per Split (<code>min_samples_split</code>)</strong>: Minimum samples required to split a node - Higher values → fewer splits → simpler trees - Prevents splits on small subsets that may be noise</p> <p><strong>Minimum Samples per Leaf (<code>min_samples_leaf</code>)</strong>: Minimum samples required in a leaf node - Forces leaves to generalize over multiple examples - Reduces overfitting to individual outliers</p> <p><strong>Pruning</strong>: Remove branches that provide little predictive power - Pre-pruning: Stop growing tree early (using hyperparameters above) - Post-pruning: Grow full tree, then remove branches (less common in scikit-learn)</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1># Find optimal depth using cross-validation</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>cross_val_score</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=n>depths</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>20</span><span class=p>)</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=n>train_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a><span class=n>cv_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a><span class=k>for</span> <span class=n>depth</span> <span class=ow>in</span> <span class=n>depths</span><span class=p>:</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>    <span class=n>dt</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>max_depth</span><span class=o>=</span><span class=n>depth</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>    <span class=c1># Training accuracy</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>    <span class=n>dt</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a>    <span class=n>train_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_train</span><span class=p>,</span> <span class=n>dt</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_train</span><span class=p>)))</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a>    <span class=c1># Cross-validation accuracy</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a>    <span class=n>cv_score</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>dt</span><span class=p>,</span> <span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a>    <span class=n>cv_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>cv_score</span><span class=p>)</span>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a><span class=c1># Plot bias-variance tradeoff</span>
</span><span id=__span-6-20><a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-6-21><a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>depths</span><span class=p>,</span> <span class=n>train_scores</span><span class=p>,</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;o&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Training Accuracy&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-6-22><a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>depths</span><span class=p>,</span> <span class=n>cv_scores</span><span class=p>,</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;s&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;CV Accuracy&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-6-23><a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Tree Depth&#39;</span><span class=p>)</span>
</span><span id=__span-6-24><a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Accuracy&#39;</span><span class=p>)</span>
</span><span id=__span-6-25><a id=__codelineno-6-25 name=__codelineno-6-25 href=#__codelineno-6-25></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Bias-Variance Tradeoff: Finding Optimal Tree Depth&#39;</span><span class=p>)</span>
</span><span id=__span-6-26><a id=__codelineno-6-26 name=__codelineno-6-26 href=#__codelineno-6-26></a><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span><span id=__span-6-27><a id=__codelineno-6-27 name=__codelineno-6-27 href=#__codelineno-6-27></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-6-28><a id=__codelineno-6-28 name=__codelineno-6-28 href=#__codelineno-6-28></a><span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>depths</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>cv_scores</span><span class=p>)],</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span>
</span><span id=__span-6-29><a id=__codelineno-6-29 name=__codelineno-6-29 href=#__codelineno-6-29></a>            <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Optimal depth=</span><span class=si>{</span><span class=n>depths</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>cv_scores</span><span class=p>)]</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span><span id=__span-6-30><a id=__codelineno-6-30 name=__codelineno-6-30 href=#__codelineno-6-30></a><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span><span id=__span-6-31><a id=__codelineno-6-31 name=__codelineno-6-31 href=#__codelineno-6-31></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span><span id=__span-6-32><a id=__codelineno-6-32 name=__codelineno-6-32 href=#__codelineno-6-32></a>
</span><span id=__span-6-33><a id=__codelineno-6-33 name=__codelineno-6-33 href=#__codelineno-6-33></a><span class=n>optimal_depth</span> <span class=o>=</span> <span class=n>depths</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>cv_scores</span><span class=p>)]</span>
</span><span id=__span-6-34><a id=__codelineno-6-34 name=__codelineno-6-34 href=#__codelineno-6-34></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Optimal tree depth: </span><span class=si>{</span><span class=n>optimal_depth</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-35><a id=__codelineno-6-35 name=__codelineno-6-35 href=#__codelineno-6-35></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best CV accuracy: </span><span class=si>{</span><span class=nb>max</span><span class=p>(</span><span class=n>cv_scores</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>This plot reveals the classic bias-variance tradeoff pattern: training accuracy increases monotonically with depth (lower bias), while cross-validation accuracy peaks then declines (variance increases past optimal point).</p> <h2 id=feature-space-partitioning>Feature Space Partitioning<a class=headerlink href=#feature-space-partitioning title="Permanent link">&para;</a></h2> <p>Decision trees partition the feature space into axis-aligned rectangular regions. Each split creates a boundary perpendicular to one feature axis, dividing the space into two sub-regions.</p> <p>For a 2D feature space: - First split: Vertical or horizontal line dividing space - Second split: Additional line subdividing one half - Continued splits: Increasingly fine-grained rectangular partition</p> <p>This geometric interpretation helps understand decision trees' strengths and limitations:</p> <p><strong>Strengths:</strong> - Clear, interpretable boundaries - Handles non-linear relationships - No assumptions about data distribution</p> <p><strong>Limitations:</strong> - Cannot learn diagonal boundaries efficiently (requires many splits) - Struggles with rotated data - Creates "staircase" boundaries for smooth, curved decision surfaces</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=c1># Visualize decision boundaries for 2D data</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>make_classification</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=kn>from</span><span class=w> </span><span class=nn>matplotlib.colors</span><span class=w> </span><span class=kn>import</span> <span class=n>ListedColormap</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=c1># Create 2D synthetic data</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=n>X_2d</span><span class=p>,</span> <span class=n>y_2d</span> <span class=o>=</span> <span class=n>make_classification</span><span class=p>(</span><span class=n>n_samples</span><span class=o>=</span><span class=mi>300</span><span class=p>,</span> <span class=n>n_features</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>n_redundant</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>                                  <span class=n>n_informative</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>n_clusters_per_class</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>                                  <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=c1># Train trees with different depths</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a><span class=n>depths</span> <span class=o>=</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>10</span><span class=p>]</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a><span class=n>cmap_light</span> <span class=o>=</span> <span class=n>ListedColormap</span><span class=p>([</span><span class=s1>&#39;#FFAAAA&#39;</span><span class=p>,</span> <span class=s1>&#39;#AAAAFF&#39;</span><span class=p>])</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a><span class=n>cmap_bold</span> <span class=o>=</span> <span class=n>ListedColormap</span><span class=p>([</span><span class=s1>&#39;#FF0000&#39;</span><span class=p>,</span> <span class=s1>&#39;#0000FF&#39;</span><span class=p>])</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a><span class=k>for</span> <span class=n>idx</span><span class=p>,</span> <span class=n>depth</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>depths</span><span class=p>):</span>
</span><span id=__span-7-18><a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a>    <span class=n>dt</span> <span class=o>=</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>max_depth</span><span class=o>=</span><span class=n>depth</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-7-19><a id=__codelineno-7-19 name=__codelineno-7-19 href=#__codelineno-7-19></a>    <span class=n>dt</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_2d</span><span class=p>,</span> <span class=n>y_2d</span><span class=p>)</span>
</span><span id=__span-7-20><a id=__codelineno-7-20 name=__codelineno-7-20 href=#__codelineno-7-20></a>
</span><span id=__span-7-21><a id=__codelineno-7-21 name=__codelineno-7-21 href=#__codelineno-7-21></a>    <span class=c1># Create mesh for decision boundary</span>
</span><span id=__span-7-22><a id=__codelineno-7-22 name=__codelineno-7-22 href=#__codelineno-7-22></a>    <span class=n>h</span> <span class=o>=</span> <span class=mf>0.02</span>
</span><span id=__span-7-23><a id=__codelineno-7-23 name=__codelineno-7-23 href=#__codelineno-7-23></a>    <span class=n>x_min</span><span class=p>,</span> <span class=n>x_max</span> <span class=o>=</span> <span class=n>X_2d</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>X_2d</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>+</span> <span class=mi>1</span>
</span><span id=__span-7-24><a id=__codelineno-7-24 name=__codelineno-7-24 href=#__codelineno-7-24></a>    <span class=n>y_min</span><span class=p>,</span> <span class=n>y_max</span> <span class=o>=</span> <span class=n>X_2d</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>X_2d</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>+</span> <span class=mi>1</span>
</span><span id=__span-7-25><a id=__codelineno-7-25 name=__codelineno-7-25 href=#__codelineno-7-25></a>    <span class=n>xx</span><span class=p>,</span> <span class=n>yy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>meshgrid</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>x_min</span><span class=p>,</span> <span class=n>x_max</span><span class=p>,</span> <span class=n>h</span><span class=p>),</span>
</span><span id=__span-7-26><a id=__codelineno-7-26 name=__codelineno-7-26 href=#__codelineno-7-26></a>                         <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>y_min</span><span class=p>,</span> <span class=n>y_max</span><span class=p>,</span> <span class=n>h</span><span class=p>))</span>
</span><span id=__span-7-27><a id=__codelineno-7-27 name=__codelineno-7-27 href=#__codelineno-7-27></a>
</span><span id=__span-7-28><a id=__codelineno-7-28 name=__codelineno-7-28 href=#__codelineno-7-28></a>    <span class=c1># Predict for each point in mesh</span>
</span><span id=__span-7-29><a id=__codelineno-7-29 name=__codelineno-7-29 href=#__codelineno-7-29></a>    <span class=n>Z</span> <span class=o>=</span> <span class=n>dt</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>c_</span><span class=p>[</span><span class=n>xx</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span> <span class=n>yy</span><span class=o>.</span><span class=n>ravel</span><span class=p>()])</span>
</span><span id=__span-7-30><a id=__codelineno-7-30 name=__codelineno-7-30 href=#__codelineno-7-30></a>    <span class=n>Z</span> <span class=o>=</span> <span class=n>Z</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>xx</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-7-31><a id=__codelineno-7-31 name=__codelineno-7-31 href=#__codelineno-7-31></a>
</span><span id=__span-7-32><a id=__codelineno-7-32 name=__codelineno-7-32 href=#__codelineno-7-32></a>    <span class=c1># Plot</span>
</span><span id=__span-7-33><a id=__codelineno-7-33 name=__codelineno-7-33 href=#__codelineno-7-33></a>    <span class=n>axes</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>.</span><span class=n>contourf</span><span class=p>(</span><span class=n>xx</span><span class=p>,</span> <span class=n>yy</span><span class=p>,</span> <span class=n>Z</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=n>cmap_light</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.8</span><span class=p>)</span>
</span><span id=__span-7-34><a id=__codelineno-7-34 name=__codelineno-7-34 href=#__codelineno-7-34></a>    <span class=n>axes</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X_2d</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>X_2d</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>c</span><span class=o>=</span><span class=n>y_2d</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=n>cmap_bold</span><span class=p>,</span>
</span><span id=__span-7-35><a id=__codelineno-7-35 name=__codelineno-7-35 href=#__codelineno-7-35></a>                     <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span><span id=__span-7-36><a id=__codelineno-7-36 name=__codelineno-7-36 href=#__codelineno-7-36></a>    <span class=n>axes</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Decision Tree (depth=</span><span class=si>{</span><span class=n>depth</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
</span><span id=__span-7-37><a id=__codelineno-7-37 name=__codelineno-7-37 href=#__codelineno-7-37></a>    <span class=n>axes</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Feature 1&#39;</span><span class=p>)</span>
</span><span id=__span-7-38><a id=__codelineno-7-38 name=__codelineno-7-38 href=#__codelineno-7-38></a>    <span class=n>axes</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Feature 2&#39;</span><span class=p>)</span>
</span><span id=__span-7-39><a id=__codelineno-7-39 name=__codelineno-7-39 href=#__codelineno-7-39></a>
</span><span id=__span-7-40><a id=__codelineno-7-40 name=__codelineno-7-40 href=#__codelineno-7-40></a><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span><span id=__span-7-41><a id=__codelineno-7-41 name=__codelineno-7-41 href=#__codelineno-7-41></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>Notice how deeper trees create more rectangular partitions, capturing finer details but risking overfitting. The axis-aligned nature means diagonal boundaries require multiple splits to approximate.</p> <h2 id=loss-functions-and-cross-entropy-loss>Loss Functions and Cross-Entropy Loss<a class=headerlink href=#loss-functions-and-cross-entropy-loss title="Permanent link">&para;</a></h2> <p>In classification, decision trees minimize a <strong>loss function</strong> that quantifies prediction error. The most common loss for probabilistic classifiers is <strong>cross-entropy loss</strong>, which penalizes confident wrong predictions more than uncertain ones.</p> <p>For binary classification, cross-entropy loss for a single example is:</p> <div class=arithmatex>\[L(y, \hat{p}) = -y \log(\hat{p}) - (1-y) \log(1-\hat{p})\]</div> <p>where: - <span class=arithmatex>\(y \in \{0, 1\}\)</span> is the true label - <span class=arithmatex>\(\hat{p}\)</span> is the predicted probability of class 1</p> <p>For multi-class classification:</p> <div class=arithmatex>\[L(y, \hat{\mathbf{p}}) = -\sum_{i=1}^{k} y_i \log(\hat{p}_i)\]</div> <p>where <span class=arithmatex>\(y_i\)</span> is 1 if the true class is <span class=arithmatex>\(i\)</span>, 0 otherwise (one-hot encoding).</p> <p>Decision trees don't directly optimize cross-entropy during training (they use Gini or entropy for splits), but cross-entropy provides a principled way to evaluate predicted class probabilities.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>log_loss</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=c1># Get probability predictions</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=n>y_prob</span> <span class=o>=</span> <span class=n>dt_optimal</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=c1># Calculate cross-entropy loss</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=n>ce_loss</span> <span class=o>=</span> <span class=n>log_loss</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_prob</span><span class=p>)</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Cross-entropy loss: </span><span class=si>{</span><span class=n>ce_loss</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a><span class=c1># Compare with accuracy</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a><span class=n>test_acc</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>dt_optimal</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>))</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test accuracy: </span><span class=si>{</span><span class=n>test_acc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a><span class=c1># Show how confident wrong predictions increase loss</span>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a><span class=n>correct_pred</span> <span class=o>=</span> <span class=n>y_prob</span><span class=p>[</span><span class=n>y_test</span> <span class=o>==</span> <span class=n>dt_optimal</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)]</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a><span class=n>incorrect_pred</span> <span class=o>=</span> <span class=n>y_prob</span><span class=p>[</span><span class=n>y_test</span> <span class=o>!=</span> <span class=n>dt_optimal</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)]</span>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Average confidence on correct predictions: </span><span class=si>{</span><span class=n>correct_pred</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-8-19><a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Average confidence on incorrect predictions: </span><span class=si>{</span><span class=n>incorrect_pred</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>Cross-entropy penalizes confident mistakes more heavily than uncertain ones, encouraging well-calibrated probability estimates.</p> <h2 id=visualizing-decision-trees>Visualizing Decision Trees<a class=headerlink href=#visualizing-decision-trees title="Permanent link">&para;</a></h2> <p>One of decision trees' greatest strengths is interpretability—we can visualize the learned rules and understand how predictions are made.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.tree</span><span class=w> </span><span class=kn>import</span> <span class=n>plot_tree</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=c1># Visualize the optimal tree</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=n>plot_tree</span><span class=p>(</span><span class=n>dt_optimal</span><span class=p>,</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>          <span class=n>feature_names</span><span class=o>=</span><span class=n>cancer</span><span class=o>.</span><span class=n>feature_names</span><span class=p>,</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a>          <span class=n>class_names</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;Malignant&#39;</span><span class=p>,</span> <span class=s1>&#39;Benign&#39;</span><span class=p>],</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>          <span class=n>filled</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a>          <span class=n>rounded</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a>          <span class=n>fontsize</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&quot;Decision Tree for Breast Cancer Classification (depth=5)&quot;</span><span class=p>)</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a>
</span><span id=__span-9-14><a id=__codelineno-9-14 name=__codelineno-9-14 href=#__codelineno-9-14></a><span class=c1># Feature importance</span>
</span><span id=__span-9-15><a id=__codelineno-9-15 name=__codelineno-9-15 href=#__codelineno-9-15></a><span class=n>feature_importance</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
</span><span id=__span-9-16><a id=__codelineno-9-16 name=__codelineno-9-16 href=#__codelineno-9-16></a>    <span class=s1>&#39;feature&#39;</span><span class=p>:</span> <span class=n>cancer</span><span class=o>.</span><span class=n>feature_names</span><span class=p>,</span>
</span><span id=__span-9-17><a id=__codelineno-9-17 name=__codelineno-9-17 href=#__codelineno-9-17></a>    <span class=s1>&#39;importance&#39;</span><span class=p>:</span> <span class=n>dt_optimal</span><span class=o>.</span><span class=n>feature_importances_</span>
</span><span id=__span-9-18><a id=__codelineno-9-18 name=__codelineno-9-18 href=#__codelineno-9-18></a><span class=p>})</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;importance&#39;</span><span class=p>,</span> <span class=n>ascending</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span><span id=__span-9-19><a id=__codelineno-9-19 name=__codelineno-9-19 href=#__codelineno-9-19></a>
</span><span id=__span-9-20><a id=__codelineno-9-20 name=__codelineno-9-20 href=#__codelineno-9-20></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Top 10 Most Important Features:&quot;</span><span class=p>)</span>
</span><span id=__span-9-21><a id=__codelineno-9-21 name=__codelineno-9-21 href=#__codelineno-9-21></a><span class=nb>print</span><span class=p>(</span><span class=n>feature_importance</span><span class=o>.</span><span class=n>head</span><span class=p>(</span><span class=mi>10</span><span class=p>))</span>
</span><span id=__span-9-22><a id=__codelineno-9-22 name=__codelineno-9-22 href=#__codelineno-9-22></a>
</span><span id=__span-9-23><a id=__codelineno-9-23 name=__codelineno-9-23 href=#__codelineno-9-23></a><span class=c1># Plot feature importance</span>
</span><span id=__span-9-24><a id=__codelineno-9-24 name=__codelineno-9-24 href=#__codelineno-9-24></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-9-25><a id=__codelineno-9-25 name=__codelineno-9-25 href=#__codelineno-9-25></a><span class=n>top_features</span> <span class=o>=</span> <span class=n>feature_importance</span><span class=o>.</span><span class=n>head</span><span class=p>(</span><span class=mi>15</span><span class=p>)</span>
</span><span id=__span-9-26><a id=__codelineno-9-26 name=__codelineno-9-26 href=#__codelineno-9-26></a><span class=n>plt</span><span class=o>.</span><span class=n>barh</span><span class=p>(</span><span class=n>top_features</span><span class=p>[</span><span class=s1>&#39;feature&#39;</span><span class=p>],</span> <span class=n>top_features</span><span class=p>[</span><span class=s1>&#39;importance&#39;</span><span class=p>])</span>
</span><span id=__span-9-27><a id=__codelineno-9-27 name=__codelineno-9-27 href=#__codelineno-9-27></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Feature Importance&#39;</span><span class=p>)</span>
</span><span id=__span-9-28><a id=__codelineno-9-28 name=__codelineno-9-28 href=#__codelineno-9-28></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Top 15 Feature Importances in Decision Tree&#39;</span><span class=p>)</span>
</span><span id=__span-9-29><a id=__codelineno-9-29 name=__codelineno-9-29 href=#__codelineno-9-29></a><span class=n>plt</span><span class=o>.</span><span class=n>gca</span><span class=p>()</span><span class=o>.</span><span class=n>invert_yaxis</span><span class=p>()</span>
</span><span id=__span-9-30><a id=__codelineno-9-30 name=__codelineno-9-30 href=#__codelineno-9-30></a><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span><span id=__span-9-31><a id=__codelineno-9-31 name=__codelineno-9-31 href=#__codelineno-9-31></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>Feature importance reveals which features the tree relies on most for splits. Features appearing near the root or in many nodes have higher importance.</p> <div class="admonition tip"> <p class=admonition-title>Reading Tree Visualizations</p> <ul> <li><strong>Node color intensity</strong>: Darker colors indicate more samples in that class</li> <li><strong>Sample count</strong>: Number of training examples reaching that node</li> <li><strong>Value</strong>: Number of samples per class at that node</li> <li><strong>Gini/Entropy</strong>: Impurity measure at that node</li> <li><strong>Path from root to leaf</strong>: Decision rule for a specific prediction</li> </ul> </div> <h2 id=practical-considerations-and-best-practices>Practical Considerations and Best Practices<a class=headerlink href=#practical-considerations-and-best-practices title="Permanent link">&para;</a></h2> <p>Decision trees excel in many scenarios but have important limitations to consider:</p> <p><strong>When to Use Decision Trees:</strong> - Need interpretable models (medical, legal, financial domains) - Data has mix of categorical and continuous features - Non-linear relationships exist - Interactions between features matter - Robust to outliers (doesn't use distances)</p> <p><strong>When to Avoid Decision Trees:</strong> - Need smooth decision boundaries - Very high-dimensional data (&gt;100 features) - Features are highly correlated - Require stable predictions (trees are sensitive to data changes)</p> <p><strong>Best Practices:</strong></p> <ol> <li><strong>Always set max_depth</strong>: Prevents overfitting, improves interpretability</li> <li><strong>Use cross-validation</strong>: Find optimal hyperparameters systematically</li> <li><strong>Check feature importance</strong>: Validate that important features make domain sense</li> <li><strong>Compare training vs test accuracy</strong>: Monitor for overfitting</li> <li><strong>Consider ensemble methods</strong>: Random forests (next section) often outperform single trees</li> </ol> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># Example: Proper hyperparameter tuning with grid search</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>GridSearchCV</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a><span class=n>param_grid</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>    <span class=s1>&#39;max_depth&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>    <span class=s1>&#39;min_samples_split&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>    <span class=s1>&#39;min_samples_leaf&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>    <span class=s1>&#39;criterion&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;gini&#39;</span><span class=p>,</span> <span class=s1>&#39;entropy&#39;</span><span class=p>]</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a><span class=p>}</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a><span class=n>grid_search</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>    <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>    <span class=n>param_grid</span><span class=p>,</span>
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>    <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>    <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>,</span>
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a>    <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span>
</span><span id=__span-10-17><a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a><span class=p>)</span>
</span><span id=__span-10-18><a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a>
</span><span id=__span-10-19><a id=__codelineno-10-19 name=__codelineno-10-19 href=#__codelineno-10-19></a><span class=n>grid_search</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-10-20><a id=__codelineno-10-20 name=__codelineno-10-20 href=#__codelineno-10-20></a>
</span><span id=__span-10-21><a id=__codelineno-10-21 name=__codelineno-10-21 href=#__codelineno-10-21></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Best hyperparameters:&quot;</span><span class=p>)</span>
</span><span id=__span-10-22><a id=__codelineno-10-22 name=__codelineno-10-22 href=#__codelineno-10-22></a><span class=nb>print</span><span class=p>(</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span>
</span><span id=__span-10-23><a id=__codelineno-10-23 name=__codelineno-10-23 href=#__codelineno-10-23></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Best CV accuracy: </span><span class=si>{</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_score_</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-24><a id=__codelineno-10-24 name=__codelineno-10-24 href=#__codelineno-10-24></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test accuracy: </span><span class=si>{</span><span class=n>grid_search</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test</span><span class=p>,</span><span class=w> </span><span class=n>y_test</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=random-forests-ensemble-of-trees>Random Forests: Ensemble of Trees<a class=headerlink href=#random-forests-ensemble-of-trees title="Permanent link">&para;</a></h2> <p>A single decision tree's predictions can be unstable—small changes in training data may produce very different trees. <strong>Random forests</strong> address this by training multiple trees on random subsets of data and averaging their predictions.</p> <p>Random forest algorithm: 1. Create many bootstrap samples (random sampling with replacement) 2. Train a decision tree on each bootstrap sample 3. For each tree, consider only random subset of features at each split 4. Predict by majority vote (classification) or averaging (regression)</p> <p>This ensemble approach reduces variance while maintaining low bias, often outperforming single trees.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.ensemble</span><span class=w> </span><span class=kn>import</span> <span class=n>RandomForestClassifier</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a><span class=c1># Train random forest</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a><span class=n>rf_classifier</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>n_estimators</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>max_depth</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>                                       <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a><span class=n>rf_classifier</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a><span class=c1># Evaluate</span>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a><span class=n>rf_train_acc</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_train</span><span class=p>,</span> <span class=n>rf_classifier</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_train</span><span class=p>))</span>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a><span class=n>rf_test_acc</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>rf_classifier</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>))</span>
</span><span id=__span-11-11><a id=__codelineno-11-11 name=__codelineno-11-11 href=#__codelineno-11-11></a>
</span><span id=__span-11-12><a id=__codelineno-11-12 name=__codelineno-11-12 href=#__codelineno-11-12></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Random Forest Performance:&quot;</span><span class=p>)</span>
</span><span id=__span-11-13><a id=__codelineno-11-13 name=__codelineno-11-13 href=#__codelineno-11-13></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Training accuracy: </span><span class=si>{</span><span class=n>rf_train_acc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-11-14><a id=__codelineno-11-14 name=__codelineno-11-14 href=#__codelineno-11-14></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Test accuracy: </span><span class=si>{</span><span class=n>rf_test_acc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-11-15><a id=__codelineno-11-15 name=__codelineno-11-15 href=#__codelineno-11-15></a>
</span><span id=__span-11-16><a id=__codelineno-11-16 name=__codelineno-11-16 href=#__codelineno-11-16></a><span class=c1># Compare with single tree</span>
</span><span id=__span-11-17><a id=__codelineno-11-17 name=__codelineno-11-17 href=#__codelineno-11-17></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Single Decision Tree Performance:&quot;</span><span class=p>)</span>
</span><span id=__span-11-18><a id=__codelineno-11-18 name=__codelineno-11-18 href=#__codelineno-11-18></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Training accuracy: </span><span class=si>{</span><span class=n>train_acc_optimal</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-11-19><a id=__codelineno-11-19 name=__codelineno-11-19 href=#__codelineno-11-19></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Test accuracy: </span><span class=si>{</span><span class=n>test_acc_optimal</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-11-20><a id=__codelineno-11-20 name=__codelineno-11-20 href=#__codelineno-11-20></a>
</span><span id=__span-11-21><a id=__codelineno-11-21 name=__codelineno-11-21 href=#__codelineno-11-21></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Improvement from ensemble: </span><span class=si>{</span><span class=p>(</span><span class=n>rf_test_acc</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=n>test_acc_optimal</span><span class=p>)</span><span class=o>*</span><span class=mi>100</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>%&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>Random forests typically improve test accuracy by 2-5% while reducing overfitting. The tradeoff: loss of interpretability (100 trees are harder to understand than 1).</p> <h2 id=key-takeaways>Key Takeaways<a class=headerlink href=#key-takeaways title="Permanent link">&para;</a></h2> <p>This chapter explored decision trees, an interpretable and versatile machine learning algorithm:</p> <ul> <li> <p><strong>Decision trees</strong> recursively partition feature space using a hierarchy of feature tests, making predictions at leaf nodes</p> </li> <li> <p><strong>Tree structure</strong> consists of internal nodes (feature tests), branches (outcomes), and leaf nodes (predictions), organized by depth</p> </li> <li> <p><strong>Splitting criteria</strong> like entropy and Gini impurity quantify node purity; trees choose splits that maximize information gain or minimize impurity</p> </li> <li> <p><strong>Overfitting</strong> occurs when trees grow too deep, memorizing training data; <strong>underfitting</strong> occurs when trees are too shallow to capture patterns</p> </li> <li> <p><strong>Tree depth control</strong> via max_depth, min_samples_split, and pruning prevents overfitting while maintaining predictive power</p> </li> <li> <p><strong>Feature space partitioning</strong> creates axis-aligned rectangular regions; interpretable but cannot efficiently learn diagonal boundaries</p> </li> <li> <p><strong>Cross-entropy loss</strong> measures prediction quality for probabilistic classification, penalizing confident wrong predictions</p> </li> <li> <p><strong>Random forests</strong> combine multiple trees trained on random data subsets, reducing variance and improving generalization</p> </li> </ul> <p>Decision trees provide a strong foundation for understanding more sophisticated algorithms, including ensemble methods and gradient boosting covered in advanced courses. Their interpretability makes them invaluable when stakeholders need to understand and trust model decisions.</p> <p>In the next chapter, we'll explore logistic regression, which takes a different approach to classification using probabilistic modeling and linear decision boundaries.</p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 | CC BY-NC-SA 4.0 DEED </div> </div> <div class=md-social> <a href=https://github.com/AnvithPothula target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/anvith-pothula target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>