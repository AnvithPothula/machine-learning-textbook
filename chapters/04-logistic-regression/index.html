<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A comprehensive intelligent textbook on machine learning algorithms and applications"><meta name=author content="Anvith Pothula"><link href=https://example.com/chapters/04-logistic-regression/ rel=canonical><link href=../03-decision-trees/quiz/ rel=prev><link href=quiz/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Content - Machine Learning - Algorithms and Applications</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#logistic-regression-and-classification class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-header__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Machine Learning - Algorithms and Applications </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Content </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../course-description/ class=md-tabs__link> Course Description </a> </li> <li class=md-tabs__item> <a href=../../faq/ class=md-tabs__link> FAQ </a> </li> <li class=md-tabs__item> <a href=../../glossary/ class=md-tabs__link> Glossary </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Chapters </a> </li> <li class=md-tabs__item> <a href=../../sims/ class=md-tabs__link> MicroSims </a> </li> <li class=md-tabs__item> <a href=../../learning-graph/ class=md-tabs__link> Learning Graph </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-nav__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Machine Learning - Algorithms and Applications </label> <div class=md-nav__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-nav__item> <a href=../../course-description/ class=md-nav__link> <span class=md-ellipsis> Course Description </span> </a> </li> <li class=md-nav__item> <a href=../../faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> <li class=md-nav__item> <a href=../../glossary/ class=md-nav__link> <span class=md-ellipsis> Glossary </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> Chapters </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Chapters </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_2> <label class=md-nav__link for=__nav_5_2 id=__nav_5_2_label tabindex> <span class=md-ellipsis> 1. ML Fundamentals </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> 1. ML Fundamentals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_3> <label class=md-nav__link for=__nav_5_3 id=__nav_5_3_label tabindex> <span class=md-ellipsis> 2. K-Nearest Neighbors </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_3_label aria-expanded=false> <label class=md-nav__title for=__nav_5_3> <span class="md-nav__icon md-icon"></span> 2. K-Nearest Neighbors </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../02-k-nearest-neighbors/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../02-k-nearest-neighbors/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_4> <label class=md-nav__link for=__nav_5_4 id=__nav_5_4_label tabindex> <span class=md-ellipsis> 3. Decision Trees </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_4_label aria-expanded=false> <label class=md-nav__title for=__nav_5_4> <span class="md-nav__icon md-icon"></span> 3. Decision Trees </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../03-decision-trees/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../03-decision-trees/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_5 checked> <label class=md-nav__link for=__nav_5_5 id=__nav_5_5_label tabindex> <span class=md-ellipsis> 4. Logistic Regression </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5_5> <span class="md-nav__icon md-icon"></span> 4. Logistic Regression </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Content </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Content </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#from-regression-to-classification class=md-nav__link> <span class=md-ellipsis> From Regression to Classification </span> </a> <nav class=md-nav aria-label="From Regression to Classification"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-problem-with-linear-regression-for-classification class=md-nav__link> <span class=md-ellipsis> The Problem with Linear Regression for Classification </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#the-sigmoid-function class=md-nav__link> <span class=md-ellipsis> The Sigmoid Function </span> </a> <nav class=md-nav aria-label="The Sigmoid Function"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sigmoid-as-an-activation-function class=md-nav__link> <span class=md-ellipsis> Sigmoid as an Activation Function </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#binary-classification-with-logistic-regression class=md-nav__link> <span class=md-ellipsis> Binary Classification with Logistic Regression </span> </a> <nav class=md-nav aria-label="Binary Classification with Logistic Regression"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#making-class-predictions class=md-nav__link> <span class=md-ellipsis> Making Class Predictions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#maximum-likelihood-estimation-and-log-loss class=md-nav__link> <span class=md-ellipsis> Maximum Likelihood Estimation and Log-Loss </span> </a> <nav class=md-nav aria-label="Maximum Likelihood Estimation and Log-Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-likelihood-principle class=md-nav__link> <span class=md-ellipsis> The Likelihood Principle </span> </a> </li> <li class=md-nav__item> <a href=#from-likelihood-to-log-loss class=md-nav__link> <span class=md-ellipsis> From Likelihood to Log-Loss </span> </a> </li> <li class=md-nav__item> <a href=#interpreting-log-loss class=md-nav__link> <span class=md-ellipsis> Interpreting Log-Loss </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multiclass-classification-strategies class=md-nav__link> <span class=md-ellipsis> Multiclass Classification Strategies </span> </a> <nav class=md-nav aria-label="Multiclass Classification Strategies"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#one-vs-all-one-vs-rest class=md-nav__link> <span class=md-ellipsis> One-vs-All (One-vs-Rest) </span> </a> </li> <li class=md-nav__item> <a href=#one-vs-one class=md-nav__link> <span class=md-ellipsis> One-vs-One </span> </a> </li> <li class=md-nav__item> <a href=#direct-multiclass-logistic-regression-the-softmax-function class=md-nav__link> <span class=md-ellipsis> Direct Multiclass Logistic Regression: The Softmax Function </span> </a> </li> <li class=md-nav__item> <a href=#implementing-multiclass-logistic-regression class=md-nav__link> <span class=md-ellipsis> Implementing Multiclass Logistic Regression </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#logistic-regression-in-practice class=md-nav__link> <span class=md-ellipsis> Logistic Regression in Practice </span> </a> <nav class=md-nav aria-label="Logistic Regression in Practice"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#preprocessing-and-feature-engineering class=md-nav__link> <span class=md-ellipsis> Preprocessing and Feature Engineering </span> </a> </li> <li class=md-nav__item> <a href=#interpreting-coefficients class=md-nav__link> <span class=md-ellipsis> Interpreting Coefficients </span> </a> </li> <li class=md-nav__item> <a href=#regularization-and-model-complexity class=md-nav__link> <span class=md-ellipsis> Regularization and Model Complexity </span> </a> </li> <li class=md-nav__item> <a href=#when-to-use-logistic-regression class=md-nav__link> <span class=md-ellipsis> When to Use Logistic Regression </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#interactive-visualization-sigmoid-function-explorer class=md-nav__link> <span class=md-ellipsis> Interactive Visualization: Sigmoid Function Explorer </span> </a> </li> <li class=md-nav__item> <a href=#interactive-visualization-multiclass-decision-boundaries class=md-nav__link> <span class=md-ellipsis> Interactive Visualization: Multiclass Decision Boundaries </span> </a> </li> <li class=md-nav__item> <a href=#summary_1 class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#key-takeaways class=md-nav__link> <span class=md-ellipsis> Key Takeaways </span> </a> </li> <li class=md-nav__item> <a href=#further-reading class=md-nav__link> <span class=md-ellipsis> Further Reading </span> </a> </li> <li class=md-nav__item> <a href=#exercises class=md-nav__link> <span class=md-ellipsis> Exercises </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_6> <label class=md-nav__link for=__nav_5_6 id=__nav_5_6_label tabindex> <span class=md-ellipsis> 5. Regularization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_6_label aria-expanded=false> <label class=md-nav__title for=__nav_5_6> <span class="md-nav__icon md-icon"></span> 5. Regularization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../05-regularization/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../05-regularization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_7> <label class=md-nav__link for=__nav_5_7 id=__nav_5_7_label tabindex> <span class=md-ellipsis> 6. Support Vector Machines </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_7_label aria-expanded=false> <label class=md-nav__title for=__nav_5_7> <span class="md-nav__icon md-icon"></span> 6. Support Vector Machines </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../06-support-vector-machines/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../06-support-vector-machines/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_8> <label class=md-nav__link for=__nav_5_8 id=__nav_5_8_label tabindex> <span class=md-ellipsis> 7. K-Means Clustering </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_8_label aria-expanded=false> <label class=md-nav__title for=__nav_5_8> <span class="md-nav__icon md-icon"></span> 7. K-Means Clustering </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../07-k-means-clustering/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../07-k-means-clustering/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_9> <label class=md-nav__link for=__nav_5_9 id=__nav_5_9_label tabindex> <span class=md-ellipsis> 8. Data Preprocessing </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_9_label aria-expanded=false> <label class=md-nav__title for=__nav_5_9> <span class="md-nav__icon md-icon"></span> 8. Data Preprocessing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../08-data-preprocessing/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../08-data-preprocessing/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_10> <label class=md-nav__link for=__nav_5_10 id=__nav_5_10_label tabindex> <span class=md-ellipsis> 9. Neural Networks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_10_label aria-expanded=false> <label class=md-nav__title for=__nav_5_10> <span class="md-nav__icon md-icon"></span> 9. Neural Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../09-neural-networks/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../09-neural-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_11> <label class=md-nav__link for=__nav_5_11 id=__nav_5_11_label tabindex> <span class=md-ellipsis> 10. Convolutional Networks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_11_label aria-expanded=false> <label class=md-nav__title for=__nav_5_11> <span class="md-nav__icon md-icon"></span> 10. Convolutional Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../10-convolutional-networks/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../10-convolutional-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_12> <label class=md-nav__link for=__nav_5_12 id=__nav_5_12_label tabindex> <span class=md-ellipsis> 11. Transfer Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_12_label aria-expanded=false> <label class=md-nav__title for=__nav_5_12> <span class="md-nav__icon md-icon"></span> 11. Transfer Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../11-transfer-learning/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../11-transfer-learning/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_13> <label class=md-nav__link for=__nav_5_13 id=__nav_5_13_label tabindex> <span class=md-ellipsis> 12. Evaluation & Optimization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_13_label aria-expanded=false> <label class=md-nav__title for=__nav_5_13> <span class="md-nav__icon md-icon"></span> 12. Evaluation & Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../12-evaluation-optimization/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../12-evaluation-optimization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> MicroSims </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> MicroSims </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../sims/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../../sims/activation-functions/ class=md-nav__link> <span class=md-ellipsis> Activation Functions </span> </a> </li> <li class=md-nav__item> <a href=../../sims/categorical-encoding-explorer/ class=md-nav__link> <span class=md-ellipsis> Categorical Encoding Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/cnn-architecture/ class=md-nav__link> <span class=md-ellipsis> CNN Architecture </span> </a> </li> <li class=md-nav__item> <a href=../../sims/confusion-matrix-explorer/ class=md-nav__link> <span class=md-ellipsis> Confusion Matrix Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/convolution-operation/ class=md-nav__link> <span class=md-ellipsis> Convolution Operation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/distance-metrics/ class=md-nav__link> <span class=md-ellipsis> Distance Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../sims/entropy-gini-comparison/ class=md-nav__link> <span class=md-ellipsis> Entropy-Gini Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/feature-scaling-visualizer/ class=md-nav__link> <span class=md-ellipsis> Feature Scaling Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/k-selection-simulator/ class=md-nav__link> <span class=md-ellipsis> K-Selection Simulator </span> </a> </li> <li class=md-nav__item> <a href=../../sims/kfold-cross-validation/ class=md-nav__link> <span class=md-ellipsis> K-Fold Cross Validation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/lasso-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Lasso Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/network-architecture-visualizer/ class=md-nav__link> <span class=md-ellipsis> Network Architecture Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/ridge-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Ridge Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/roc-curve-comparison/ class=md-nav__link> <span class=md-ellipsis> ROC Curve Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/sigmoid-explorer/ class=md-nav__link> <span class=md-ellipsis> Sigmoid Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/svm-margin-maximization/ class=md-nav__link> <span class=md-ellipsis> SVM Margin Maximization </span> </a> </li> <li class=md-nav__item> <a href=../../sims/training-validation-curves/ class=md-nav__link> <span class=md-ellipsis> Training Validation Curves </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex=0> <span class=md-ellipsis> Learning Graph </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Learning Graph </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../learning-graph/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../sims/graph-viewer/ class=md-nav__link> <span class=md-ellipsis> Graph Viewer </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/course-description-assessment/ class=md-nav__link> <span class=md-ellipsis> Course Description Assessment </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-list/ class=md-nav__link> <span class=md-ellipsis> Concept List </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-taxonomy/ class=md-nav__link> <span class=md-ellipsis> Concept Taxonomy </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.csv class=md-nav__link> <span class=md-ellipsis> Learning Graph (CSV) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.json class=md-nav__link> <span class=md-ellipsis> Learning Graph (JSON) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/quality-metrics/ class=md-nav__link> <span class=md-ellipsis> Quality Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/taxonomy-distribution/ class=md-nav__link> <span class=md-ellipsis> Taxonomy Distribution </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/glossary-quality-report/ class=md-nav__link> <span class=md-ellipsis> Glossary Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-quality-report/ class=md-nav__link> <span class=md-ellipsis> FAQ Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-coverage-gaps/ class=md-nav__link> <span class=md-ellipsis> FAQ Coverage Gaps </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/book-metrics/ class=md-nav__link> <span class=md-ellipsis> Book Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/chapter-metrics/ class=md-nav__link> <span class=md-ellipsis> Chapter Metrics </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#from-regression-to-classification class=md-nav__link> <span class=md-ellipsis> From Regression to Classification </span> </a> <nav class=md-nav aria-label="From Regression to Classification"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-problem-with-linear-regression-for-classification class=md-nav__link> <span class=md-ellipsis> The Problem with Linear Regression for Classification </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#the-sigmoid-function class=md-nav__link> <span class=md-ellipsis> The Sigmoid Function </span> </a> <nav class=md-nav aria-label="The Sigmoid Function"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sigmoid-as-an-activation-function class=md-nav__link> <span class=md-ellipsis> Sigmoid as an Activation Function </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#binary-classification-with-logistic-regression class=md-nav__link> <span class=md-ellipsis> Binary Classification with Logistic Regression </span> </a> <nav class=md-nav aria-label="Binary Classification with Logistic Regression"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#making-class-predictions class=md-nav__link> <span class=md-ellipsis> Making Class Predictions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#maximum-likelihood-estimation-and-log-loss class=md-nav__link> <span class=md-ellipsis> Maximum Likelihood Estimation and Log-Loss </span> </a> <nav class=md-nav aria-label="Maximum Likelihood Estimation and Log-Loss"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-likelihood-principle class=md-nav__link> <span class=md-ellipsis> The Likelihood Principle </span> </a> </li> <li class=md-nav__item> <a href=#from-likelihood-to-log-loss class=md-nav__link> <span class=md-ellipsis> From Likelihood to Log-Loss </span> </a> </li> <li class=md-nav__item> <a href=#interpreting-log-loss class=md-nav__link> <span class=md-ellipsis> Interpreting Log-Loss </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multiclass-classification-strategies class=md-nav__link> <span class=md-ellipsis> Multiclass Classification Strategies </span> </a> <nav class=md-nav aria-label="Multiclass Classification Strategies"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#one-vs-all-one-vs-rest class=md-nav__link> <span class=md-ellipsis> One-vs-All (One-vs-Rest) </span> </a> </li> <li class=md-nav__item> <a href=#one-vs-one class=md-nav__link> <span class=md-ellipsis> One-vs-One </span> </a> </li> <li class=md-nav__item> <a href=#direct-multiclass-logistic-regression-the-softmax-function class=md-nav__link> <span class=md-ellipsis> Direct Multiclass Logistic Regression: The Softmax Function </span> </a> </li> <li class=md-nav__item> <a href=#implementing-multiclass-logistic-regression class=md-nav__link> <span class=md-ellipsis> Implementing Multiclass Logistic Regression </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#logistic-regression-in-practice class=md-nav__link> <span class=md-ellipsis> Logistic Regression in Practice </span> </a> <nav class=md-nav aria-label="Logistic Regression in Practice"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#preprocessing-and-feature-engineering class=md-nav__link> <span class=md-ellipsis> Preprocessing and Feature Engineering </span> </a> </li> <li class=md-nav__item> <a href=#interpreting-coefficients class=md-nav__link> <span class=md-ellipsis> Interpreting Coefficients </span> </a> </li> <li class=md-nav__item> <a href=#regularization-and-model-complexity class=md-nav__link> <span class=md-ellipsis> Regularization and Model Complexity </span> </a> </li> <li class=md-nav__item> <a href=#when-to-use-logistic-regression class=md-nav__link> <span class=md-ellipsis> When to Use Logistic Regression </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#interactive-visualization-sigmoid-function-explorer class=md-nav__link> <span class=md-ellipsis> Interactive Visualization: Sigmoid Function Explorer </span> </a> </li> <li class=md-nav__item> <a href=#interactive-visualization-multiclass-decision-boundaries class=md-nav__link> <span class=md-ellipsis> Interactive Visualization: Multiclass Decision Boundaries </span> </a> </li> <li class=md-nav__item> <a href=#summary_1 class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#key-takeaways class=md-nav__link> <span class=md-ellipsis> Key Takeaways </span> </a> </li> <li class=md-nav__item> <a href=#further-reading class=md-nav__link> <span class=md-ellipsis> Further Reading </span> </a> </li> <li class=md-nav__item> <a href=#exercises class=md-nav__link> <span class=md-ellipsis> Exercises </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=logistic-regression-and-classification>Logistic Regression and Classification<a class=headerlink href=#logistic-regression-and-classification title="Permanent link">&para;</a></h1> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">&para;</a></h2> <p>This chapter introduces logistic regression, a fundamental algorithm for classification that uses probabilistic modeling to predict class membership. Students will learn how the sigmoid function transforms linear combinations of features into probabilities, understand the log-loss (cross-entropy) objective function, and explore maximum likelihood estimation. The chapter extends beyond binary classification to cover multiclass problems through one-vs-all and one-vs-one strategies, and introduces the softmax function for directly modeling multiple classes. By mastering logistic regression, students will understand the bridge between linear models and probabilistic classification.</p> <h2 id=concepts-covered>Concepts Covered<a class=headerlink href=#concepts-covered title="Permanent link">&para;</a></h2> <p>This chapter covers the following 10 concepts from the learning graph:</p> <ol> <li>Logistic Regression</li> <li>Sigmoid Function</li> <li>Sigmoid Activation</li> <li>Log-Loss</li> <li>Binary Classification</li> <li>Multiclass Classification</li> <li>Maximum Likelihood</li> <li>One-vs-All</li> <li>One-vs-One</li> <li>Softmax Function</li> </ol> <h2 id=prerequisites>Prerequisites<a class=headerlink href=#prerequisites title="Permanent link">&para;</a></h2> <p>This chapter builds on concepts from:</p> <ul> <li><a href=../01-intro-to-ml-fundamentals/ >Chapter 1: Introduction to Machine Learning Fundamentals</a></li> <li><a href=../03-decision-trees/ >Chapter 3: Decision Trees and Tree-Based Learning</a></li> </ul> <hr> <h2 id=from-regression-to-classification>From Regression to Classification<a class=headerlink href=#from-regression-to-classification title="Permanent link">&para;</a></h2> <p>Linear regression, with its familiar form <span class=arithmatex>\(y = mx + b\)</span>, excels at predicting continuous numerical values. When you need to predict whether a penguin is male or female, whether an email is spam or not spam, or which species of iris flower you're observing, however, linear regression encounters fundamental limitations. Classification requires predicting discrete categories rather than continuous values, and this calls for a different approach.</p> <h3 id=the-problem-with-linear-regression-for-classification>The Problem with Linear Regression for Classification<a class=headerlink href=#the-problem-with-linear-regression-for-classification title="Permanent link">&para;</a></h3> <p>Consider a binary classification task where we want to predict penguin sex (male or female) based on physical measurements. If we encode the classes as 0 and 1 and apply standard linear regression, we face several conceptual difficulties:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>LinearRegression</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=c1># Load penguin data</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=n>penguins</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;https://raw.githubusercontent.com/sziccardi/MLCamp2025_DataRepository/main/penguins.csv&#39;</span><span class=p>)</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a><span class=c1># Convert categorical variables to numerical format</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=n>penguins2</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>get_dummies</span><span class=p>(</span><span class=n>penguins</span><span class=p>,</span> <span class=n>drop_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;int&#39;</span><span class=p>)</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a><span class=c1># Prepare features and target</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a><span class=n>predictors</span> <span class=o>=</span> <span class=n>penguins2</span><span class=o>.</span><span class=n>columns</span><span class=p>[</span><span class=mi>0</span><span class=p>:</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a><span class=n>X</span> <span class=o>=</span> <span class=n>penguins2</span><span class=p>[</span><span class=n>predictors</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a><span class=n>Y</span> <span class=o>=</span> <span class=n>penguins2</span><span class=p>[</span><span class=s2>&quot;sex_male&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a><span class=c1># Fit linear regression model</span>
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a><span class=n>linear_regressor</span> <span class=o>=</span> <span class=n>LinearRegression</span><span class=p>()</span>
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a><span class=n>linear_regressor</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a><span class=n>Y_pred</span> <span class=o>=</span> <span class=n>linear_regressor</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a>
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a><span class=c1># Visualize the problem</span>
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-0-24><a id=__codelineno-0-24 name=__codelineno-0-24 href=#__codelineno-0-24></a><span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>Y_pred</span><span class=p>,</span> <span class=n>Y</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span><span id=__span-0-25><a id=__codelineno-0-25 name=__codelineno-0-25 href=#__codelineno-0-25></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;Predicted&quot;</span><span class=p>)</span>
</span><span id=__span-0-26><a id=__codelineno-0-26 name=__codelineno-0-26 href=#__codelineno-0-26></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;Actual&quot;</span><span class=p>)</span>
</span><span id=__span-0-27><a id=__codelineno-0-27 name=__codelineno-0-27 href=#__codelineno-0-27></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&quot;Linear Regression for Binary Classification&quot;</span><span class=p>)</span>
</span><span id=__span-0-28><a id=__codelineno-0-28 name=__codelineno-0-28 href=#__codelineno-0-28></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>The predictions from linear regression are not constrained to the interval [0, 1]. The model might predict values like 1.3 or -0.2, which are meaningless as probabilities or class labels. While we could threshold predictions at 0.5 to assign classes, the unconstrained output range makes it difficult to interpret predictions probabilistically.</p> <p>What we need is a transformation that takes any real-valued linear combination of features and maps it to a value between 0 and 1something we can interpret as a probability.</p> <h2 id=the-sigmoid-function>The Sigmoid Function<a class=headerlink href=#the-sigmoid-function title="Permanent link">&para;</a></h2> <p>The <strong>sigmoid function</strong> (also called the <strong>logistic function</strong>) provides exactly this transformation. Mathematically, it's defined as:</p> <div class=arithmatex>\[\sigma(z) = \frac{1}{1 + e^{-z}}\]</div> <p>where <span class=arithmatex>\(z\)</span> can be any real number. The sigmoid function has several remarkable properties that make it ideal for classification:</p> <ol> <li><strong>Range</strong>: The output is always between 0 and 1, regardless of the input value</li> <li><strong>Monotonicity</strong>: As <span class=arithmatex>\(z\)</span> increases, <span class=arithmatex>\(\sigma(z)\)</span> increases smoothly</li> <li><strong>Interpretability</strong>: The output can be interpreted as a probability</li> <li><strong>Differentiability</strong>: The function is smooth and differentiable everywhere</li> </ol> <p>Let's visualize the sigmoid function to understand its behavior:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># Plot the sigmoid function</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=n>xvals</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=o>-</span><span class=mi>6</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>200</span><span class=p>)</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=n>f</span> <span class=o>=</span> <span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=mi>1</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>x</span><span class=p>))</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>xvals</span><span class=p>,</span> <span class=n>f</span><span class=p>(</span><span class=n>xvals</span><span class=p>),</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a><span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;red&quot;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a><span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;red&quot;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a><span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;green&quot;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a><span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&quot;gray&quot;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s2>&quot;--&quot;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;z&quot;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;(z)&quot;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&quot;The Sigmoid Function&quot;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-1-15><a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>Notice how the sigmoid function smoothly transitions from 0 to 1, with the steepest change occurring around <span class=arithmatex>\(z = 0\)</span>. When <span class=arithmatex>\(z = 0\)</span>, the sigmoid outputs exactly 0.5. As <span class=arithmatex>\(z\)</span> approaches positive infinity, the output approaches 1, and as <span class=arithmatex>\(z\)</span> approaches negative infinity, the output approaches 0.</p> <h3 id=sigmoid-as-an-activation-function>Sigmoid as an Activation Function<a class=headerlink href=#sigmoid-as-an-activation-function title="Permanent link">&para;</a></h3> <p>In the context of machine learning and neural networks, the sigmoid is often referred to as an <strong>activation function</strong>. When used as a <strong>sigmoid activation</strong>, it transforms the weighted sum of inputs into a probability-like output. This concept becomes particularly important in neural networks, where sigmoid units were historically used as the primary nonlinear transformation.</p> <p>The sigmoid function can also be written in the equivalent form:</p> <div class=arithmatex>\[\sigma(z) = \frac{e^z}{1 + e^z}\]</div> <p>This alternative formulation highlights the exponential relationship and is particularly useful when deriving the softmax function for multiclass problems.</p> <h2 id=binary-classification-with-logistic-regression>Binary Classification with Logistic Regression<a class=headerlink href=#binary-classification-with-logistic-regression title="Permanent link">&para;</a></h2> <p><strong>Logistic regression</strong> applies the sigmoid transformation to a linear combination of features, creating a probabilistic binary classifier. The model has the form:</p> <div class=arithmatex>\[z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k\]</div> <div class=arithmatex>\[P(y = 1 | \mathbf{x}) = \sigma(z) = \frac{1}{1 + e^{-z}}\]</div> <p>where <span class=arithmatex>\(\mathbf{x} = (x_1, x_2, \ldots, x_k)\)</span> represents the feature vector, <span class=arithmatex>\(\boldsymbol{\beta} = (\beta_0, \beta_1, \ldots, \beta_k)\)</span> are the model parameters, and <span class=arithmatex>\(P(y = 1 | \mathbf{x})\)</span> is the probability that the instance belongs to class 1 given its features.</p> <p>The model outputs a probability between 0 and 1. For <strong>binary classification</strong>, we typically apply a decision threshold (usually 0.5) to convert this probability into a class prediction:</p> <div class=arithmatex>\[\hat{y} = \begin{cases} 1 &amp; \text{if } P(y = 1 | \mathbf{x}) \geq 0.5 \\ 0 &amp; \text{otherwise} \end{cases}\]</div> <p>Let's apply logistic regression to the penguin sex classification problem:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>LogisticRegression</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=c1># Fit logistic regression model</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=n>logistic_regressor</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>(</span><span class=n>max_iter</span><span class=o>=</span><span class=mi>10000</span><span class=p>)</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=n>logistic_regressor</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=o>.</span><span class=n>ravel</span><span class=p>())</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a><span class=c1># Get probability predictions</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a><span class=n>Y_pred_prob</span> <span class=o>=</span> <span class=n>logistic_regressor</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=c1># Display first 10 predictions</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;First 10 probability predictions:&quot;</span><span class=p>)</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a><span class=nb>print</span><span class=p>(</span><span class=n>Y_pred_prob</span><span class=p>[</span><span class=mi>0</span><span class=p>:</span><span class=mi>10</span><span class=p>,</span> <span class=p>:])</span>
</span></code></pre></div> <p>The <code>predict_proba</code> method returns a two-column array. The first column contains <span class=arithmatex>\(P(y = 0 | \mathbf{x})\)</span> (probability of female), and the second column contains <span class=arithmatex>\(P(y = 1 | \mathbf{x})\)</span> (probability of male). Note that these probabilities sum to 1 for each instance.</p> <p>We can visualize how the logistic regression predictions differ from linear regression:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>Y_pred_prob</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>Y</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;Predicted Probability (Male)&quot;</span><span class=p>)</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;Actual Label&quot;</span><span class=p>)</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&quot;Logistic Regression Predictions&quot;</span><span class=p>)</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>Unlike linear regression, logistic regression constrains all predictions to the [0, 1] interval, making them interpretable as probabilities.</p> <h3 id=making-class-predictions>Making Class Predictions<a class=headerlink href=#making-class-predictions title="Permanent link">&para;</a></h3> <p>The <code>predict</code> method applies the default 0.5 threshold to generate class predictions:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># Get class predictions</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=n>Y_pred</span> <span class=o>=</span> <span class=n>logistic_regressor</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=c1># Evaluate using confusion matrix</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>confusion_matrix</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=n>cm</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>Y</span><span class=p>,</span> <span class=n>Y_pred</span><span class=p>)</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Confusion Matrix:&quot;</span><span class=p>)</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a><span class=nb>print</span><span class=p>(</span><span class=n>cm</span><span class=p>)</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a><span class=c1># Show as percentages</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a><span class=n>cm_normalized</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>Y</span><span class=p>,</span> <span class=n>Y_pred</span><span class=p>,</span> <span class=n>normalize</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Confusion Matrix (Normalized):&quot;</span><span class=p>)</span>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a><span class=nb>print</span><span class=p>(</span><span class=n>cm_normalized</span><span class=p>)</span>
</span></code></pre></div> <p>The confusion matrix shows that the model correctly classifies most penguins, with a small number of false positives and false negatives. The normalized version expresses these counts as proportions of the total dataset.</p> <div class="admonition tip"> <p class=admonition-title>Interpreting the Confusion Matrix</p> <p>For binary classification, the confusion matrix has the form:</p> <table> <thead> <tr> <th></th> <th>Predicted 0</th> <th>Predicted 1</th> </tr> </thead> <tbody> <tr> <td><strong>Actual 0</strong></td> <td>True Neg</td> <td>False Pos</td> </tr> <tr> <td><strong>Actual 1</strong></td> <td>False Neg</td> <td>True Pos</td> </tr> </tbody> </table> <p>The diagonal elements represent correct predictions, while off-diagonal elements represent errors.</p> </div> <h2 id=maximum-likelihood-estimation-and-log-loss>Maximum Likelihood Estimation and Log-Loss<a class=headerlink href=#maximum-likelihood-estimation-and-log-loss title="Permanent link">&para;</a></h2> <p>How does logistic regression determine the optimal parameters <span class=arithmatex>\(\boldsymbol{\beta}\)</span>? Unlike linear regression, which minimizes squared error, logistic regression uses <strong>maximum likelihood estimation</strong> (MLE).</p> <h3 id=the-likelihood-principle>The Likelihood Principle<a class=headerlink href=#the-likelihood-principle title="Permanent link">&para;</a></h3> <p>Given a dataset with <span class=arithmatex>\(n\)</span> instances, where each instance <span class=arithmatex>\(i\)</span> has features <span class=arithmatex>\(\mathbf{x}_i\)</span> and true label <span class=arithmatex>\(y_i \in \{0, 1\}\)</span>, the likelihood of the data under our model is:</p> <div class=arithmatex>\[L(\boldsymbol{\beta}) = \prod_{i=1}^{n} P(y_i | \mathbf{x}_i; \boldsymbol{\beta})\]</div> <p>For each instance, this probability is:</p> <div class=arithmatex>\[P(y_i | \mathbf{x}_i; \boldsymbol{\beta}) = \begin{cases} \sigma(z_i) &amp; \text{if } y_i = 1 \\ 1 - \sigma(z_i) &amp; \text{if } y_i = 0 \end{cases}\]</div> <p>This can be written compactly as:</p> <div class=arithmatex>\[P(y_i | \mathbf{x}_i; \boldsymbol{\beta}) = \sigma(z_i)^{y_i} (1 - \sigma(z_i))^{1-y_i}\]</div> <h3 id=from-likelihood-to-log-loss>From Likelihood to Log-Loss<a class=headerlink href=#from-likelihood-to-log-loss title="Permanent link">&para;</a></h3> <p>Taking the logarithm of the likelihood (which is monotonic and thus preserves the location of the maximum) gives us the log-likelihood:</p> <div class=arithmatex>\[\log L(\boldsymbol{\beta}) = \sum_{i=1}^{n} \left[ y_i \log \sigma(z_i) + (1-y_i) \log(1-\sigma(z_i)) \right]\]</div> <p>Machine learning practitioners typically work with loss functions (which we minimize) rather than likelihood functions (which we maximize). The <strong>log-loss</strong> (also called <strong>binary cross-entropy</strong>) is the negative average log-likelihood:</p> <div class=arithmatex>\[\text{Log-Loss} = -\frac{1}{n} \sum_{i=1}^{n} \left[ y_i \log \hat{p}_i + (1-y_i) \log(1-\hat{p}_i) \right]\]</div> <p>where <span class=arithmatex>\(\hat{p}_i = \sigma(z_i)\)</span> is the predicted probability for instance <span class=arithmatex>\(i\)</span>.</p> <h3 id=interpreting-log-loss>Interpreting Log-Loss<a class=headerlink href=#interpreting-log-loss title="Permanent link">&para;</a></h3> <p>Log-loss penalizes confident wrong predictions heavily. If the true label is 1 and the model predicts a probability near 0, the term <span class=arithmatex>\(\log \hat{p}_i\)</span> approaches negative infinity, resulting in a very large loss. Conversely, correct predictions with high confidence yield low loss values.</p> <p>Consider these examples:</p> <ul> <li>True label = 1, predicted probability = 0.9: Loss = <span class=arithmatex>\(-\log(0.9) \approx 0.105\)</span> (small penalty)</li> <li>True label = 1, predicted probability = 0.5: Loss = <span class=arithmatex>\(-\log(0.5) \approx 0.693\)</span> (moderate penalty)</li> <li>True label = 1, predicted probability = 0.1: Loss = <span class=arithmatex>\(-\log(0.1) \approx 2.303\)</span> (large penalty)</li> </ul> <p>Scikit-learn's <code>LogisticRegression</code> uses optimization algorithms (like L-BFGS or stochastic gradient descent) to find the parameters <span class=arithmatex>\(\boldsymbol{\beta}\)</span> that minimize the log-loss, optionally with regularization terms added to prevent overfitting.</p> <div class="admonition note"> <p class=admonition-title>Regularization in Logistic Regression</p> <p>The <code>C</code> parameter in scikit-learn's <code>LogisticRegression</code> controls regularization strength. Smaller values of <code>C</code> specify stronger regularization. The default is <code>C=1.0</code>.</p> </div> <h2 id=multiclass-classification-strategies>Multiclass Classification Strategies<a class=headerlink href=#multiclass-classification-strategies title="Permanent link">&para;</a></h2> <p>Many real-world problems involve predicting one of several classes rather than just two. <strong>Multiclass classification</strong> requires extending binary methods to handle multiple categories. There are several standard approaches for adapting binary classifiers to multiclass problems.</p> <h3 id=one-vs-all-one-vs-rest>One-vs-All (One-vs-Rest)<a class=headerlink href=#one-vs-all-one-vs-rest title="Permanent link">&para;</a></h3> <p>The <strong>one-vs-all</strong> (OvA) strategy, also called one-vs-rest, trains <span class=arithmatex>\(K\)</span> separate binary classifiers for a <span class=arithmatex>\(K\)</span>-class problem. For each class <span class=arithmatex>\(k\)</span>:</p> <ol> <li>Create a binary classification task where class <span class=arithmatex>\(k\)</span> is the positive class and all other classes are grouped as the negative class</li> <li>Train a binary classifier on this transformed dataset</li> <li>The classifier learns to distinguish "class <span class=arithmatex>\(k\)</span>" from "not class <span class=arithmatex>\(k\)</span>"</li> </ol> <p>During prediction, all <span class=arithmatex>\(K\)</span> classifiers generate scores for a new instance. The class with the highest score (or highest predicted probability) is selected as the final prediction.</p> <p><strong>Advantages:</strong> - Simple to implement and understand - Requires training only <span class=arithmatex>\(K\)</span> classifiers - Works with any binary classifier</p> <p><strong>Disadvantages:</strong> - Class imbalance (one positive class vs. many negative classes combined) - Classifiers are not directly comparable (trained on different datasets)</p> <h3 id=one-vs-one>One-vs-One<a class=headerlink href=#one-vs-one title="Permanent link">&para;</a></h3> <p>The <strong>one-vs-one</strong> (OvO) strategy trains a binary classifier for every pair of classes. For <span class=arithmatex>\(K\)</span> classes, this requires training <span class=arithmatex>\(\binom{K}{2} = \frac{K(K-1)}{2}\)</span> classifiers.</p> <p>For each pair of classes <span class=arithmatex>\((i, j)\)</span>:</p> <ol> <li>Create a binary dataset containing only instances from classes <span class=arithmatex>\(i\)</span> and <span class=arithmatex>\(j\)</span></li> <li>Train a binary classifier to distinguish class <span class=arithmatex>\(i\)</span> from class <span class=arithmatex>\(j\)</span></li> </ol> <p>During prediction, each of the <span class=arithmatex>\(\binom{K}{2}\)</span> classifiers votes for one class. The class that receives the most votes is selected as the final prediction.</p> <p><strong>Advantages:</strong> - Each classifier trains on a balanced, smaller dataset - Can be more accurate for some problems - Parallelizable (classifiers are independent)</p> <p><strong>Disadvantages:</strong> - Requires <span class=arithmatex>\(O(K^2)\)</span> classifiers, which can be expensive for large <span class=arithmatex>\(K\)</span> - Voting can be ambiguous (ties, no clear majority)</p> <div class="admonition warning"> <p class=admonition-title>Computational Considerations</p> <p>For 10 classes, one-vs-one requires 45 classifiers. For 100 classes, it requires 4,950 classifiers. The computational cost can become prohibitive for problems with many classes.</p> </div> <h3 id=direct-multiclass-logistic-regression-the-softmax-function>Direct Multiclass Logistic Regression: The Softmax Function<a class=headerlink href=#direct-multiclass-logistic-regression-the-softmax-function title="Permanent link">&para;</a></h3> <p>Rather than training multiple binary classifiers, we can directly extend logistic regression to handle multiple classes using the <strong>softmax function</strong>. For <span class=arithmatex>\(K\)</span> classes, we learn <span class=arithmatex>\(K\)</span> separate linear models:</p> <div class=arithmatex>\[z_k = \beta_{k,0} + \beta_{k,1} x_1 + \beta_{k,2} x_2 + \cdots + \beta_{k,p} x_p\]</div> <p>for <span class=arithmatex>\(k = 1, 2, \ldots, K\)</span>. The softmax function then converts these scores into probabilities:</p> <div class=arithmatex>\[P(y = k | \mathbf{x}) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}}\]</div> <p>The softmax ensures that:</p> <ol> <li>All probabilities are positive</li> <li>All probabilities sum to 1: <span class=arithmatex>\(\sum_{k=1}^{K} P(y = k | \mathbf{x}) = 1\)</span></li> <li>The class with the highest score <span class=arithmatex>\(z_k\)</span> gets the highest probability</li> </ol> <p>Notice that softmax is a generalization of the sigmoid function. For <span class=arithmatex>\(K = 2\)</span> classes, softmax reduces to the binary sigmoid formulation.</p> <h3 id=implementing-multiclass-logistic-regression>Implementing Multiclass Logistic Regression<a class=headerlink href=#implementing-multiclass-logistic-regression title="Permanent link">&para;</a></h3> <p>Let's apply multinomial logistic regression to the classic Iris dataset, which has three classes (setosa, versicolor, virginica):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=c1># Load Iris dataset</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=n>iris_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;https://raw.githubusercontent.com/sziccardi/MLCamp2025_DataRepository/main/iris.csv&#39;</span><span class=p>)</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=c1># Convert species names to numerical labels</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=n>labels</span><span class=p>,</span> <span class=n>unique</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>factorize</span><span class=p>(</span><span class=n>iris_df</span><span class=p>[</span><span class=s1>&#39;species&#39;</span><span class=p>])</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=c1># Prepare features and target</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class=n>X</span> <span class=o>=</span> <span class=n>iris_df</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>:</span><span class=mi>5</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>  <span class=c1># Use sepal and petal measurements</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=n>y</span> <span class=o>=</span> <span class=n>labels</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a><span class=c1># Train multinomial logistic regression</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a><span class=n>mc_lr</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>(</span><span class=n>multi_class</span><span class=o>=</span><span class=s1>&#39;multinomial&#39;</span><span class=p>,</span> <span class=n>solver</span><span class=o>=</span><span class=s1>&#39;lbfgs&#39;</span><span class=p>,</span> <span class=n>max_iter</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a><span class=n>mc_lr</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a><span class=c1># Get probability predictions for first 5 instances</span>
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a><span class=n>probs</span> <span class=o>=</span> <span class=n>mc_lr</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X</span><span class=p>)[</span><span class=mi>0</span><span class=p>:</span><span class=mi>5</span><span class=p>,</span> <span class=p>:]</span>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Probability predictions (first 5 instances):&quot;</span><span class=p>)</span>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a><span class=nb>print</span><span class=p>(</span><span class=n>probs</span><span class=p>)</span>
</span></code></pre></div> <p>The <code>predict_proba</code> output now has three columns, one for each class. Each row sums to 1, representing a complete probability distribution over the three species.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1># Generate class predictions</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=n>preds</span> <span class=o>=</span> <span class=n>mc_lr</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=c1># Evaluate with confusion matrix</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=n>cm</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>preds</span><span class=p>)</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Confusion Matrix:&quot;</span><span class=p>)</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a><span class=nb>print</span><span class=p>(</span><span class=n>cm</span><span class=p>)</span>
</span></code></pre></div> <p>For the Iris dataset, logistic regression typically achieves near-perfect classification, as evidenced by a diagonal confusion matrix with few or no off-diagonal errors.</p> <div class="admonition tip"> <p class=admonition-title>Choosing Multiclass Strategies</p> <ul> <li><strong>Use softmax (multinomial)</strong> when you want calibrated probabilities and direct multiclass modeling</li> <li><strong>Use one-vs-all</strong> for faster training with many classes and simpler implementation</li> <li><strong>Use one-vs-one</strong> when you have moderate numbers of classes and want high accuracy</li> </ul> </div> <h2 id=logistic-regression-in-practice>Logistic Regression in Practice<a class=headerlink href=#logistic-regression-in-practice title="Permanent link">&para;</a></h2> <h3 id=preprocessing-and-feature-engineering>Preprocessing and Feature Engineering<a class=headerlink href=#preprocessing-and-feature-engineering title="Permanent link">&para;</a></h3> <p>While logistic regression doesn't require features to be normally distributed (unlike linear discriminant analysis), standardizing features often improves convergence and numerical stability:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=c1># Split data</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>                                                      <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y</span><span class=p>)</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=c1># Standardize features</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=n>X_train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a><span class=n>X_test_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a><span class=c1># Train on scaled data</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a><span class=n>lr</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>(</span><span class=n>max_iter</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a><span class=n>lr</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a><span class=c1># Evaluate</span>
</span><span id=__span-7-18><a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a><span class=n>train_score</span> <span class=o>=</span> <span class=n>lr</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-7-19><a id=__codelineno-7-19 name=__codelineno-7-19 href=#__codelineno-7-19></a><span class=n>test_score</span> <span class=o>=</span> <span class=n>lr</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span><span id=__span-7-20><a id=__codelineno-7-20 name=__codelineno-7-20 href=#__codelineno-7-20></a>
</span><span id=__span-7-21><a id=__codelineno-7-21 name=__codelineno-7-21 href=#__codelineno-7-21></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Training accuracy: </span><span class=si>{</span><span class=n>train_score</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-7-22><a id=__codelineno-7-22 name=__codelineno-7-22 href=#__codelineno-7-22></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test accuracy: </span><span class=si>{</span><span class=n>test_score</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=interpreting-coefficients>Interpreting Coefficients<a class=headerlink href=#interpreting-coefficients title="Permanent link">&para;</a></h3> <p>The coefficients <span class=arithmatex>\(\boldsymbol{\beta}\)</span> in logistic regression indicate how each feature influences the log-odds of the positive class:</p> <div class=arithmatex>\[\log \frac{P(y=1|\mathbf{x})}{P(y=0|\mathbf{x})} = \beta_0 + \beta_1 x_1 + \cdots + \beta_k x_k\]</div> <p>A positive coefficient <span class=arithmatex>\(\beta_j\)</span> means that increasing feature <span class=arithmatex>\(x_j\)</span> increases the log-odds (and thus the probability) of class 1. The magnitude indicates the strength of the effect.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=c1># Display coefficients for binary logistic regression</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=n>feature_names</span> <span class=o>=</span> <span class=n>iris_df</span><span class=o>.</span><span class=n>columns</span><span class=p>[</span><span class=mi>1</span><span class=p>:</span><span class=mi>5</span><span class=p>]</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=n>coefficients</span> <span class=o>=</span> <span class=n>lr</span><span class=o>.</span><span class=n>coef_</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>coef</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>feature_names</span><span class=p>,</span> <span class=n>coefficients</span><span class=p>):</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>coef</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=regularization-and-model-complexity>Regularization and Model Complexity<a class=headerlink href=#regularization-and-model-complexity title="Permanent link">&para;</a></h3> <p>The <code>C</code> parameter controls the inverse of regularization strength:</p> <ul> <li><strong>Large C</strong> (e.g., 100): Weak regularization, model fits training data closely (risk of overfitting)</li> <li><strong>Small C</strong> (e.g., 0.01): Strong regularization, model is simpler and more robust (risk of underfitting)</li> </ul> <p>You can tune <code>C</code> using cross-validation:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>cross_val_score</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=c1># Test different C values</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=n>C_values</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.001</span><span class=p>,</span> <span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>,</span> <span class=mf>100.0</span><span class=p>]</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a><span class=k>for</span> <span class=n>C</span> <span class=ow>in</span> <span class=n>C_values</span><span class=p>:</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a>    <span class=n>lr</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>(</span><span class=n>C</span><span class=o>=</span><span class=n>C</span><span class=p>,</span> <span class=n>max_iter</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>lr</span><span class=p>,</span> <span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;C=</span><span class=si>{</span><span class=n>C</span><span class=si>:</span><span class=s2>6.3f</span><span class=si>}</span><span class=s2>: CV accuracy = </span><span class=si>{</span><span class=n>scores</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> (+/- </span><span class=si>{</span><span class=n>scores</span><span class=o>.</span><span class=n>std</span><span class=p>()</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=when-to-use-logistic-regression>When to Use Logistic Regression<a class=headerlink href=#when-to-use-logistic-regression title="Permanent link">&para;</a></h3> <p><strong>Strengths:</strong> - Fast to train and predict - Provides calibrated probability estimates - Interpretable coefficients - Works well with linearly separable classes - Effective with regularization for high-dimensional data</p> <p><strong>Limitations:</strong> - Assumes linear decision boundaries - May underfit complex, nonlinear relationships - Sensitive to outliers in features (though less so than linear regression) - Requires relatively more data for high-dimensional problems</p> <h2 id=interactive-visualization-sigmoid-function-explorer>Interactive Visualization: Sigmoid Function Explorer<a class=headerlink href=#interactive-visualization-sigmoid-function-explorer title="Permanent link">&para;</a></h2> <p>This interactive visualization shows how the sigmoid function <span class=arithmatex>\(\sigma(z) = \frac{1}{1+e^{-z}}\)</span> transforms a linear function <span class=arithmatex>\(z = mx + b\)</span> into probabilities. Adjust the slope to control prediction confidence (steeper = more confident) and the intercept to shift the decision boundary.</p> <iframe src=../../sims/sigmoid-explorer/main.html width=100% height=680px style="border: 1px solid #ccc; border-radius: 4px;"></iframe> <p><a class=md-button href=../../sims/sigmoid-explorer/main.html target=_blank>View Fullscreen</a> | <a href=../../sims/sigmoid-explorer/ >Documentation</a></p> <h2 id=interactive-visualization-multiclass-decision-boundaries>Interactive Visualization: Multiclass Decision Boundaries<a class=headerlink href=#interactive-visualization-multiclass-decision-boundaries title="Permanent link">&para;</a></h2> <pre class=mermaid><code>graph LR
    Input["Feature Space&lt;br/&gt;(x, x)"]
    OVA["One-vs-All&lt;br/&gt;(K binary classifiers)"]
    OVO["One-vs-One&lt;br/&gt;(K choose 2 classifiers)"]
    Softmax["Softmax/Multinomial&lt;br/&gt;(single K-class model)"]
    Output["Predicted Class&lt;br/&gt;+ Probabilities"]

    Input --&gt; OVA
    Input --&gt; OVO
    Input --&gt; Softmax
    OVA --&gt; Output
    OVO --&gt; Output
    Softmax --&gt; Output

    classDef strategyNode fill:#9f7aea,stroke:#6b46c1,stroke-width:2px,color:#fff,font-size:14px
    classDef dataNode fill:#4299e1,stroke:#2c5282,stroke-width:2px,color:#fff,font-size:14px

    class Input,Output dataNode
    class OVA,OVO,Softmax strategyNode

    linkStyle default stroke:#666,stroke-width:2px</code></pre> <p><strong>Multiclass Strategies</strong>: (1) <strong>One-vs-All</strong>: Train K binary classifiers, pick class with highest confidence; (2) <strong>One-vs-One</strong>: Train K(K-1)/2 pairwise classifiers, use voting; (3) <strong>Softmax</strong>: Direct multinomial model with exp normalization ensuring probabilities sum to 1.</p> <h2 id=summary_1>Summary<a class=headerlink href=#summary_1 title="Permanent link">&para;</a></h2> <p>Logistic regression bridges the gap between linear regression and classification by applying the sigmoid transformation to produce probability estimates. The sigmoid function constrains outputs to [0, 1], enabling probabilistic interpretation and principled decision-making. Through maximum likelihood estimation and log-loss minimization, logistic regression learns decision boundaries that separate classes effectively.</p> <p>For multiclass problems, we have several strategies: one-vs-all trains <span class=arithmatex>\(K\)</span> binary classifiers, one-vs-one trains <span class=arithmatex>\(\binom{K}{2}\)</span> pairwise classifiers, and the softmax function enables direct multinomial modeling. Each approach has trade-offs in computational cost, accuracy, and interpretability.</p> <p>The concepts introduced in this chaptersigmoid activation, log-loss, and softmaxform the foundation for understanding neural networks, where these functions appear as building blocks in more complex architectures. Logistic regression remains a valuable tool for its simplicity, interpretability, and effectiveness on linearly separable problems.</p> <h2 id=key-takeaways>Key Takeaways<a class=headerlink href=#key-takeaways title="Permanent link">&para;</a></h2> <ol> <li>The <strong>sigmoid function</strong> maps any real number to the interval [0, 1], enabling probabilistic interpretation</li> <li><strong>Logistic regression</strong> applies sigmoid transformation to a linear combination of features for binary classification</li> <li><strong>Log-loss</strong> (binary cross-entropy) measures the quality of probability predictions and is minimized during training</li> <li><strong>Maximum likelihood estimation</strong> provides the theoretical foundation for learning logistic regression parameters</li> <li><strong>One-vs-all</strong> and <strong>one-vs-one</strong> are strategies for extending binary classifiers to multiclass problems</li> <li>The <strong>softmax function</strong> generalizes sigmoid to multiple classes, producing a probability distribution over <span class=arithmatex>\(K\)</span> classes</li> <li>Regularization (controlled by parameter <code>C</code>) balances model complexity and generalization</li> <li>Logistic regression works best for linearly separable problems but can be extended with polynomial features or combined with other methods</li> </ol> <h2 id=further-reading>Further Reading<a class=headerlink href=#further-reading title="Permanent link">&para;</a></h2> <ul> <li>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The Elements of Statistical Learning</em> (Chapter 4: Linear Methods for Classification)</li> <li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em> (Chapter 4: Linear Models for Classification)</li> <li>Murphy, K. P. (2012). <em>Machine Learning: A Probabilistic Perspective</em> (Chapter 8: Logistic Regression)</li> <li>Scikit-learn documentation: <a href=https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression>Logistic Regression</a></li> </ul> <h2 id=exercises>Exercises<a class=headerlink href=#exercises title="Permanent link">&para;</a></h2> <ol> <li> <p><strong>Sigmoid Properties</strong>: Prove that the sigmoid function <span class=arithmatex>\(\sigma(z) = \frac{1}{1+e^{-z}}\)</span> has the derivative <span class=arithmatex>\(\sigma'(z) = \sigma(z)(1-\sigma(z))\)</span>. Why is this property useful for gradient-based optimization?</p> </li> <li> <p><strong>Log-Loss Calculation</strong>: Given three predictions: (true=1, predicted=0.8), (true=0, predicted=0.3), (true=1, predicted=0.6), calculate the average log-loss. Which prediction contributes most to the loss?</p> </li> <li> <p><strong>Multiclass Comparison</strong>: Implement logistic regression on a dataset with 5 classes using both one-vs-all and softmax strategies. Compare training time, prediction time, and accuracy. Under what conditions might one approach be preferable?</p> </li> <li> <p><strong>Feature Scaling Impact</strong>: Train logistic regression on the Iris dataset with and without feature standardization. Compare convergence speed and final accuracy. Explain the differences.</p> </li> <li> <p><strong>Regularization Tuning</strong>: Use grid search with cross-validation to find the optimal <code>C</code> parameter for logistic regression on a high-dimensional dataset. Plot the relationship between <code>C</code> and cross-validation score.</p> </li> <li> <p><strong>Coefficient Interpretation</strong>: Train a logistic regression model and interpret the sign and magnitude of each coefficient. Create a visualization showing feature importance based on coefficient values.</p> </li> </ol> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 | CC BY-NC-SA 4.0 DEED </div> </div> <div class=md-social> <a href=https://github.com/AnvithPothula target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/anvith-pothula target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>