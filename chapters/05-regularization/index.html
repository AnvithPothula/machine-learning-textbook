<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Preventing overfitting through L1 and L2 regularization, Ridge and Lasso regression"><meta name=author content="Anvith Pothula"><link href=https://example.com/chapters/05-regularization/ rel=canonical><link href=../04-logistic-regression/quiz/ rel=prev><link href=quiz/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Regularization Techniques - Machine Learning - Algorithms and Applications</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#regularization-techniques class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-header__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Machine Learning - Algorithms and Applications </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Regularization Techniques </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../course-description/ class=md-tabs__link> Course Description </a> </li> <li class=md-tabs__item> <a href=../../faq/ class=md-tabs__link> FAQ </a> </li> <li class=md-tabs__item> <a href=../../glossary/ class=md-tabs__link> Glossary </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Chapters </a> </li> <li class=md-tabs__item> <a href=../../sims/ class=md-tabs__link> MicroSims </a> </li> <li class=md-tabs__item> <a href=../../learning-graph/ class=md-tabs__link> Learning Graph </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-nav__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Machine Learning - Algorithms and Applications </label> <div class=md-nav__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-nav__item> <a href=../../course-description/ class=md-nav__link> <span class=md-ellipsis> Course Description </span> </a> </li> <li class=md-nav__item> <a href=../../faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> <li class=md-nav__item> <a href=../../glossary/ class=md-nav__link> <span class=md-ellipsis> Glossary </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> Chapters </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Chapters </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_2> <label class=md-nav__link for=__nav_5_2 id=__nav_5_2_label tabindex> <span class=md-ellipsis> 1. ML Fundamentals </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> 1. ML Fundamentals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_3> <label class=md-nav__link for=__nav_5_3 id=__nav_5_3_label tabindex> <span class=md-ellipsis> 2. K-Nearest Neighbors </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_3_label aria-expanded=false> <label class=md-nav__title for=__nav_5_3> <span class="md-nav__icon md-icon"></span> 2. K-Nearest Neighbors </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../02-k-nearest-neighbors/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../02-k-nearest-neighbors/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_4> <label class=md-nav__link for=__nav_5_4 id=__nav_5_4_label tabindex> <span class=md-ellipsis> 3. Decision Trees </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_4_label aria-expanded=false> <label class=md-nav__title for=__nav_5_4> <span class="md-nav__icon md-icon"></span> 3. Decision Trees </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../03-decision-trees/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../03-decision-trees/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_5> <label class=md-nav__link for=__nav_5_5 id=__nav_5_5_label tabindex> <span class=md-ellipsis> 4. Logistic Regression </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5_5> <span class="md-nav__icon md-icon"></span> 4. Logistic Regression </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../04-logistic-regression/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../04-logistic-regression/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_6 checked> <label class=md-nav__link for=__nav_5_6 id=__nav_5_6_label tabindex> <span class=md-ellipsis> 5. Regularization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_6_label aria-expanded=true> <label class=md-nav__title for=__nav_5_6> <span class="md-nav__icon md-icon"></span> 5. Regularization </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Content </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Content </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#the-problem-of-overfitting class=md-nav__link> <span class=md-ellipsis> The Problem of Overfitting </span> </a> </li> <li class=md-nav__item> <a href=#l2-regularization-and-ridge-regression class=md-nav__link> <span class=md-ellipsis> L2 Regularization and Ridge Regression </span> </a> <nav class=md-nav aria-label="L2 Regularization and Ridge Regression"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#understanding-the-l2-penalty class=md-nav__link> <span class=md-ellipsis> Understanding the L2 Penalty </span> </a> </li> <li class=md-nav__item> <a href=#ridge-regression-implementation class=md-nav__link> <span class=md-ellipsis> Ridge Regression Implementation </span> </a> </li> <li class=md-nav__item> <a href=#geometric-interpretation-of-ridge-regression class=md-nav__link> <span class=md-ellipsis> Geometric Interpretation of Ridge Regression </span> </a> </li> <li class=md-nav__item> <a href=#visualizing-coefficient-paths class=md-nav__link> <span class=md-ellipsis> Visualizing Coefficient Paths </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#l1-regularization-and-lasso-regression class=md-nav__link> <span class=md-ellipsis> L1 Regularization and Lasso Regression </span> </a> <nav class=md-nav aria-label="L1 Regularization and Lasso Regression"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-power-of-l1-automatic-feature-selection class=md-nav__link> <span class=md-ellipsis> The Power of L1: Automatic Feature Selection </span> </a> </li> <li class=md-nav__item> <a href=#lasso-regression-implementation class=md-nav__link> <span class=md-ellipsis> Lasso Regression Implementation </span> </a> </li> <li class=md-nav__item> <a href=#geometric-interpretation-of-lasso-regression class=md-nav__link> <span class=md-ellipsis> Geometric Interpretation of Lasso Regression </span> </a> </li> <li class=md-nav__item> <a href=#lasso-coefficient-paths class=md-nav__link> <span class=md-ellipsis> Lasso Coefficient Paths </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#comparing-ridge-and-lasso class=md-nav__link> <span class=md-ellipsis> Comparing Ridge and Lasso </span> </a> <nav class=md-nav aria-label="Comparing Ridge and Lasso"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#when-to-use-ridge-vs-lasso class=md-nav__link> <span class=md-ellipsis> When to Use Ridge vs Lasso </span> </a> </li> <li class=md-nav__item> <a href=#elastic-net-combining-l1-and-l2 class=md-nav__link> <span class=md-ellipsis> Elastic Net: Combining L1 and L2 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#selecting-the-regularization-parameter class=md-nav__link> <span class=md-ellipsis> Selecting the Regularization Parameter </span> </a> <nav class=md-nav aria-label="Selecting the Regularization Parameter"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#cross-validation-for-lambda-selection class=md-nav__link> <span class=md-ellipsis> Cross-Validation for Lambda Selection </span> </a> </li> <li class=md-nav__item> <a href=#automated-hyperparameter-tuning class=md-nav__link> <span class=md-ellipsis> Automated Hyperparameter Tuning </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#regularization-in-classification class=md-nav__link> <span class=md-ellipsis> Regularization in Classification </span> </a> <nav class=md-nav aria-label="Regularization in Classification"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#regularized-logistic-regression class=md-nav__link> <span class=md-ellipsis> Regularized Logistic Regression </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#practical-considerations class=md-nav__link> <span class=md-ellipsis> Practical Considerations </span> </a> <nav class=md-nav aria-label="Practical Considerations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#always-standardize-features class=md-nav__link> <span class=md-ellipsis> Always Standardize Features </span> </a> </li> <li class=md-nav__item> <a href=#intercept-term class=md-nav__link> <span class=md-ellipsis> Intercept Term </span> </a> </li> <li class=md-nav__item> <a href=#regularization-path-algorithms class=md-nav__link> <span class=md-ellipsis> Regularization Path Algorithms </span> </a> </li> <li class=md-nav__item> <a href=#convergence-and-tolerance class=md-nav__link> <span class=md-ellipsis> Convergence and Tolerance </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#ridge-vs-lasso-key-differences class=md-nav__link> <span class=md-ellipsis> Ridge vs Lasso: Key Differences </span> </a> </li> <li class=md-nav__item> <a href=#summary_1 class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#key-takeaways class=md-nav__link> <span class=md-ellipsis> Key Takeaways </span> </a> </li> <li class=md-nav__item> <a href=#further-reading class=md-nav__link> <span class=md-ellipsis> Further Reading </span> </a> </li> <li class=md-nav__item> <a href=#exercises class=md-nav__link> <span class=md-ellipsis> Exercises </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_7> <label class=md-nav__link for=__nav_5_7 id=__nav_5_7_label tabindex> <span class=md-ellipsis> 6. Support Vector Machines </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_7_label aria-expanded=false> <label class=md-nav__title for=__nav_5_7> <span class="md-nav__icon md-icon"></span> 6. Support Vector Machines </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../06-support-vector-machines/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../06-support-vector-machines/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_8> <label class=md-nav__link for=__nav_5_8 id=__nav_5_8_label tabindex> <span class=md-ellipsis> 7. K-Means Clustering </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_8_label aria-expanded=false> <label class=md-nav__title for=__nav_5_8> <span class="md-nav__icon md-icon"></span> 7. K-Means Clustering </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../07-k-means-clustering/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../07-k-means-clustering/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_9> <label class=md-nav__link for=__nav_5_9 id=__nav_5_9_label tabindex> <span class=md-ellipsis> 8. Data Preprocessing </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_9_label aria-expanded=false> <label class=md-nav__title for=__nav_5_9> <span class="md-nav__icon md-icon"></span> 8. Data Preprocessing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../08-data-preprocessing/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../08-data-preprocessing/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_10> <label class=md-nav__link for=__nav_5_10 id=__nav_5_10_label tabindex> <span class=md-ellipsis> 9. Neural Networks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_10_label aria-expanded=false> <label class=md-nav__title for=__nav_5_10> <span class="md-nav__icon md-icon"></span> 9. Neural Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../09-neural-networks/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../09-neural-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_11> <label class=md-nav__link for=__nav_5_11 id=__nav_5_11_label tabindex> <span class=md-ellipsis> 10. Convolutional Networks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_11_label aria-expanded=false> <label class=md-nav__title for=__nav_5_11> <span class="md-nav__icon md-icon"></span> 10. Convolutional Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../10-convolutional-networks/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../10-convolutional-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_12> <label class=md-nav__link for=__nav_5_12 id=__nav_5_12_label tabindex> <span class=md-ellipsis> 11. Transfer Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_12_label aria-expanded=false> <label class=md-nav__title for=__nav_5_12> <span class="md-nav__icon md-icon"></span> 11. Transfer Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../11-transfer-learning/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../11-transfer-learning/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_13> <label class=md-nav__link for=__nav_5_13 id=__nav_5_13_label tabindex> <span class=md-ellipsis> 12. Evaluation & Optimization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_13_label aria-expanded=false> <label class=md-nav__title for=__nav_5_13> <span class="md-nav__icon md-icon"></span> 12. Evaluation & Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../12-evaluation-optimization/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../12-evaluation-optimization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> MicroSims </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> MicroSims </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../sims/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../../sims/activation-functions/ class=md-nav__link> <span class=md-ellipsis> Activation Functions </span> </a> </li> <li class=md-nav__item> <a href=../../sims/categorical-encoding-explorer/ class=md-nav__link> <span class=md-ellipsis> Categorical Encoding Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/cnn-architecture/ class=md-nav__link> <span class=md-ellipsis> CNN Architecture </span> </a> </li> <li class=md-nav__item> <a href=../../sims/confusion-matrix-explorer/ class=md-nav__link> <span class=md-ellipsis> Confusion Matrix Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/convolution-operation/ class=md-nav__link> <span class=md-ellipsis> Convolution Operation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/distance-metrics/ class=md-nav__link> <span class=md-ellipsis> Distance Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../sims/entropy-gini-comparison/ class=md-nav__link> <span class=md-ellipsis> Entropy-Gini Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/feature-scaling-visualizer/ class=md-nav__link> <span class=md-ellipsis> Feature Scaling Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/k-selection-simulator/ class=md-nav__link> <span class=md-ellipsis> K-Selection Simulator </span> </a> </li> <li class=md-nav__item> <a href=../../sims/kfold-cross-validation/ class=md-nav__link> <span class=md-ellipsis> K-Fold Cross Validation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/lasso-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Lasso Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/network-architecture-visualizer/ class=md-nav__link> <span class=md-ellipsis> Network Architecture Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/ridge-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Ridge Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/roc-curve-comparison/ class=md-nav__link> <span class=md-ellipsis> ROC Curve Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/sigmoid-explorer/ class=md-nav__link> <span class=md-ellipsis> Sigmoid Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/svm-margin-maximization/ class=md-nav__link> <span class=md-ellipsis> SVM Margin Maximization </span> </a> </li> <li class=md-nav__item> <a href=../../sims/training-validation-curves/ class=md-nav__link> <span class=md-ellipsis> Training Validation Curves </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex=0> <span class=md-ellipsis> Learning Graph </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Learning Graph </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../learning-graph/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../sims/graph-viewer/ class=md-nav__link> <span class=md-ellipsis> Graph Viewer </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/course-description-assessment/ class=md-nav__link> <span class=md-ellipsis> Course Description Assessment </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-list/ class=md-nav__link> <span class=md-ellipsis> Concept List </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-taxonomy/ class=md-nav__link> <span class=md-ellipsis> Concept Taxonomy </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.csv class=md-nav__link> <span class=md-ellipsis> Learning Graph (CSV) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.json class=md-nav__link> <span class=md-ellipsis> Learning Graph (JSON) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/quality-metrics/ class=md-nav__link> <span class=md-ellipsis> Quality Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/taxonomy-distribution/ class=md-nav__link> <span class=md-ellipsis> Taxonomy Distribution </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/glossary-quality-report/ class=md-nav__link> <span class=md-ellipsis> Glossary Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-quality-report/ class=md-nav__link> <span class=md-ellipsis> FAQ Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-coverage-gaps/ class=md-nav__link> <span class=md-ellipsis> FAQ Coverage Gaps </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/book-metrics/ class=md-nav__link> <span class=md-ellipsis> Book Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/chapter-metrics/ class=md-nav__link> <span class=md-ellipsis> Chapter Metrics </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#the-problem-of-overfitting class=md-nav__link> <span class=md-ellipsis> The Problem of Overfitting </span> </a> </li> <li class=md-nav__item> <a href=#l2-regularization-and-ridge-regression class=md-nav__link> <span class=md-ellipsis> L2 Regularization and Ridge Regression </span> </a> <nav class=md-nav aria-label="L2 Regularization and Ridge Regression"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#understanding-the-l2-penalty class=md-nav__link> <span class=md-ellipsis> Understanding the L2 Penalty </span> </a> </li> <li class=md-nav__item> <a href=#ridge-regression-implementation class=md-nav__link> <span class=md-ellipsis> Ridge Regression Implementation </span> </a> </li> <li class=md-nav__item> <a href=#geometric-interpretation-of-ridge-regression class=md-nav__link> <span class=md-ellipsis> Geometric Interpretation of Ridge Regression </span> </a> </li> <li class=md-nav__item> <a href=#visualizing-coefficient-paths class=md-nav__link> <span class=md-ellipsis> Visualizing Coefficient Paths </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#l1-regularization-and-lasso-regression class=md-nav__link> <span class=md-ellipsis> L1 Regularization and Lasso Regression </span> </a> <nav class=md-nav aria-label="L1 Regularization and Lasso Regression"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-power-of-l1-automatic-feature-selection class=md-nav__link> <span class=md-ellipsis> The Power of L1: Automatic Feature Selection </span> </a> </li> <li class=md-nav__item> <a href=#lasso-regression-implementation class=md-nav__link> <span class=md-ellipsis> Lasso Regression Implementation </span> </a> </li> <li class=md-nav__item> <a href=#geometric-interpretation-of-lasso-regression class=md-nav__link> <span class=md-ellipsis> Geometric Interpretation of Lasso Regression </span> </a> </li> <li class=md-nav__item> <a href=#lasso-coefficient-paths class=md-nav__link> <span class=md-ellipsis> Lasso Coefficient Paths </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#comparing-ridge-and-lasso class=md-nav__link> <span class=md-ellipsis> Comparing Ridge and Lasso </span> </a> <nav class=md-nav aria-label="Comparing Ridge and Lasso"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#when-to-use-ridge-vs-lasso class=md-nav__link> <span class=md-ellipsis> When to Use Ridge vs Lasso </span> </a> </li> <li class=md-nav__item> <a href=#elastic-net-combining-l1-and-l2 class=md-nav__link> <span class=md-ellipsis> Elastic Net: Combining L1 and L2 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#selecting-the-regularization-parameter class=md-nav__link> <span class=md-ellipsis> Selecting the Regularization Parameter </span> </a> <nav class=md-nav aria-label="Selecting the Regularization Parameter"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#cross-validation-for-lambda-selection class=md-nav__link> <span class=md-ellipsis> Cross-Validation for Lambda Selection </span> </a> </li> <li class=md-nav__item> <a href=#automated-hyperparameter-tuning class=md-nav__link> <span class=md-ellipsis> Automated Hyperparameter Tuning </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#regularization-in-classification class=md-nav__link> <span class=md-ellipsis> Regularization in Classification </span> </a> <nav class=md-nav aria-label="Regularization in Classification"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#regularized-logistic-regression class=md-nav__link> <span class=md-ellipsis> Regularized Logistic Regression </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#practical-considerations class=md-nav__link> <span class=md-ellipsis> Practical Considerations </span> </a> <nav class=md-nav aria-label="Practical Considerations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#always-standardize-features class=md-nav__link> <span class=md-ellipsis> Always Standardize Features </span> </a> </li> <li class=md-nav__item> <a href=#intercept-term class=md-nav__link> <span class=md-ellipsis> Intercept Term </span> </a> </li> <li class=md-nav__item> <a href=#regularization-path-algorithms class=md-nav__link> <span class=md-ellipsis> Regularization Path Algorithms </span> </a> </li> <li class=md-nav__item> <a href=#convergence-and-tolerance class=md-nav__link> <span class=md-ellipsis> Convergence and Tolerance </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#ridge-vs-lasso-key-differences class=md-nav__link> <span class=md-ellipsis> Ridge vs Lasso: Key Differences </span> </a> </li> <li class=md-nav__item> <a href=#summary_1 class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#key-takeaways class=md-nav__link> <span class=md-ellipsis> Key Takeaways </span> </a> </li> <li class=md-nav__item> <a href=#further-reading class=md-nav__link> <span class=md-ellipsis> Further Reading </span> </a> </li> <li class=md-nav__item> <a href=#exercises class=md-nav__link> <span class=md-ellipsis> Exercises </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=regularization-techniques>Regularization Techniques<a class=headerlink href=#regularization-techniques title="Permanent link">&para;</a></h1> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">&para;</a></h2> <p>This chapter focuses on regularization methods that prevent overfitting by constraining model complexity. Students will learn how L1 (Lasso) and L2 (Ridge) regularization add penalty terms to the loss function to discourage large parameter values, understand the geometric interpretation of these constraints, and discover how L1 regularization can perform automatic feature selection by driving some weights to exactly zero. The chapter demonstrates practical applications of Ridge and Lasso regression and explains how to select appropriate regularization strength through cross-validation. These techniques are fundamental for building models that generalize well to unseen data.</p> <h2 id=concepts-covered>Concepts Covered<a class=headerlink href=#concepts-covered title="Permanent link">&para;</a></h2> <p>This chapter covers the following 5 concepts from the learning graph:</p> <ol> <li>Regularization</li> <li>L1 Regularization</li> <li>L2 Regularization</li> <li>Ridge Regression</li> <li>Lasso Regression</li> </ol> <h2 id=prerequisites>Prerequisites<a class=headerlink href=#prerequisites title="Permanent link">&para;</a></h2> <p>This chapter builds on concepts from:</p> <ul> <li><a href=../01-intro-to-ml-fundamentals/ >Chapter 1: Introduction to Machine Learning Fundamentals</a></li> <li><a href=../03-decision-trees/ >Chapter 3: Decision Trees and Tree-Based Learning</a></li> </ul> <hr> <h2 id=the-problem-of-overfitting>The Problem of Overfitting<a class=headerlink href=#the-problem-of-overfitting title="Permanent link">&para;</a></h2> <p>Machine learning models face a fundamental challenge: they must learn patterns from training data while maintaining the ability to generalize to new, unseen examples. When models become too complex, they can memorize the training data—including its noise and peculiarities—rather than learning the underlying patterns. This phenomenon, called <strong>overfitting</strong>, results in excellent training performance but poor performance on test data.</p> <p>Consider a linear regression problem where we predict automobile fuel efficiency (mpg) from various features. As we learned in previous chapters, linear regression finds coefficients that minimize the sum of squared errors:</p> <div class=arithmatex>\[\min_{\boldsymbol{\beta}} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \min_{\boldsymbol{\beta}} \sum_{i=1}^{n} (y_i - \boldsymbol{\beta}^T \mathbf{x}_i)^2\]</div> <p>When we have many features relative to the number of training examples, or when features are highly correlated, the model can fit the training data almost perfectly by assigning very large positive and negative coefficients. These extreme coefficients capture noise rather than signal, leading to poor generalization.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>LinearRegression</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=c1># Load automobile dataset</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a><span class=n>Auto</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;https://raw.githubusercontent.com/sziccardi/MLCamp2025_DataRepository/main/Auto.csv&#39;</span><span class=p>)</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=c1># Create polynomial features to demonstrate overfitting</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a><span class=n>X</span> <span class=o>=</span> <span class=n>Auto</span><span class=p>[[</span><span class=s2>&quot;weight&quot;</span><span class=p>]]</span><span class=o>.</span><span class=n>values</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a><span class=n>y</span> <span class=o>=</span> <span class=n>Auto</span><span class=p>[</span><span class=s2>&quot;mpg&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a><span class=c1># Add polynomial features up to degree 10</span>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a><span class=n>X_poly</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>column_stack</span><span class=p>([</span><span class=n>X</span><span class=o>**</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>)])</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a><span class=c1># Split data</span>
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X_poly</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a><span class=c1># Fit without regularization</span>
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a><span class=n>model</span> <span class=o>=</span> <span class=n>LinearRegression</span><span class=p>()</span>
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a>
</span><span id=__span-0-24><a id=__codelineno-0-24 name=__codelineno-0-24 href=#__codelineno-0-24></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Training R²:&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>))</span>
</span><span id=__span-0-25><a id=__codelineno-0-25 name=__codelineno-0-25 href=#__codelineno-0-25></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Test R²:&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>))</span>
</span><span id=__span-0-26><a id=__codelineno-0-26 name=__codelineno-0-26 href=#__codelineno-0-26></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Coefficients (first 5):&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>coef_</span><span class=p>[:</span><span class=mi>5</span><span class=p>])</span>
</span><span id=__span-0-27><a id=__codelineno-0-27 name=__codelineno-0-27 href=#__codelineno-0-27></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Coefficient magnitudes range:&quot;</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>coef_</span><span class=p>)),</span> <span class=s2>&quot;to&quot;</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>coef_</span><span class=p>)))</span>
</span></code></pre></div> <p>In this example, the high-degree polynomial features allow the model to fit training data extremely well, but the large coefficient magnitudes indicate overfitting. The model has learned to memorize training examples rather than discover generalizable patterns.</p> <p><strong>Regularization</strong> provides a principled solution to overfitting by adding a penalty term to the loss function that discourages large coefficient values. This forces the model to find simpler explanations that are more likely to generalize.</p> <h2 id=l2-regularization-and-ridge-regression>L2 Regularization and Ridge Regression<a class=headerlink href=#l2-regularization-and-ridge-regression title="Permanent link">&para;</a></h2> <p><strong>L2 regularization</strong>, also called <strong>Ridge regularization</strong>, adds a penalty proportional to the sum of squared coefficients to the loss function. The modified objective becomes:</p> <div class=arithmatex>\[\min_{\boldsymbol{\beta}} \sum_{i=1}^{n} (y_i - \boldsymbol{\beta}^T \mathbf{x}_i)^2 + \lambda \sum_{j=1}^{p} \beta_j^2\]</div> <p>where:</p> <ul> <li>The first term is the standard sum of squared errors (residual sum of squares)</li> <li>The second term is the <strong>L2 penalty</strong>: <span class=arithmatex>\(\lambda \|\boldsymbol{\beta}\|_2^2 = \lambda \sum_{j=1}^{p} \beta_j^2\)</span></li> <li><span class=arithmatex>\(\lambda \geq 0\)</span> is the <strong>regularization parameter</strong> controlling penalty strength</li> <li><span class=arithmatex>\(p\)</span> is the number of features</li> </ul> <h3 id=understanding-the-l2-penalty>Understanding the L2 Penalty<a class=headerlink href=#understanding-the-l2-penalty title="Permanent link">&para;</a></h3> <p>The L2 penalty term <span class=arithmatex>\(\sum_{j=1}^{p} \beta_j^2\)</span> grows quadratically with coefficient magnitude. This creates several important effects:</p> <ol> <li><strong>Shrinkage</strong>: Coefficients are "shrunk" toward zero, but rarely become exactly zero</li> <li><strong>Smooth solutions</strong>: The quadratic penalty is differentiable everywhere, leading to stable optimization</li> <li><strong>Correlated features</strong>: When features are correlated, Ridge tends to assign similar weights to them rather than arbitrarily choosing one</li> </ol> <p>The regularization parameter <span class=arithmatex>\(\lambda\)</span> controls the trade-off:</p> <ul> <li><span class=arithmatex>\(\lambda = 0\)</span>: No regularization, equivalent to ordinary least squares</li> <li>Small <span class=arithmatex>\(\lambda\)</span>: Weak penalty, model can use large coefficients</li> <li>Large <span class=arithmatex>\(\lambda\)</span>: Strong penalty, coefficients shrink toward zero, potentially underfitting</li> </ul> <h3 id=ridge-regression-implementation>Ridge Regression Implementation<a class=headerlink href=#ridge-regression-implementation title="Permanent link">&para;</a></h3> <p><strong>Ridge regression</strong> applies L2 regularization to linear regression. Scikit-learn provides the <code>Ridge</code> class for this purpose:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>Ridge</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class=c1># Standardize features (important for regularization)</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=n>X_train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a><span class=n>X_test_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a><span class=c1># Fit Ridge regression with different alpha values</span>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a><span class=c1># Note: scikit-learn uses &#39;alpha&#39; instead of &#39;lambda&#39;</span>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a><span class=n>alphas</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>,</span> <span class=mf>100.0</span><span class=p>]</span>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a><span class=k>for</span> <span class=n>alpha</span> <span class=ow>in</span> <span class=n>alphas</span><span class=p>:</span>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a>    <span class=n>ridge</span> <span class=o>=</span> <span class=n>Ridge</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=n>alpha</span><span class=p>)</span>
</span><span id=__span-1-15><a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a>    <span class=n>ridge</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-1-16><a id=__codelineno-1-16 name=__codelineno-1-16 href=#__codelineno-1-16></a>
</span><span id=__span-1-17><a id=__codelineno-1-17 name=__codelineno-1-17 href=#__codelineno-1-17></a>    <span class=n>train_score</span> <span class=o>=</span> <span class=n>ridge</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-1-18><a id=__codelineno-1-18 name=__codelineno-1-18 href=#__codelineno-1-18></a>    <span class=n>test_score</span> <span class=o>=</span> <span class=n>ridge</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span><span id=__span-1-19><a id=__codelineno-1-19 name=__codelineno-1-19 href=#__codelineno-1-19></a>    <span class=n>max_coef</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>ridge</span><span class=o>.</span><span class=n>coef_</span><span class=p>))</span>
</span><span id=__span-1-20><a id=__codelineno-1-20 name=__codelineno-1-20 href=#__codelineno-1-20></a>
</span><span id=__span-1-21><a id=__codelineno-1-21 name=__codelineno-1-21 href=#__codelineno-1-21></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Alpha=</span><span class=si>{</span><span class=n>alpha</span><span class=si>:</span><span class=s2>6.2f</span><span class=si>}</span><span class=s2>: Train R²=</span><span class=si>{</span><span class=n>train_score</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, Test R²=</span><span class=si>{</span><span class=n>test_score</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, Max|coef|=</span><span class=si>{</span><span class=n>max_coef</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <div class="admonition note"> <p class=admonition-title>Feature Scaling for Regularization</p> <p>Always standardize features before applying regularization! The penalty term <span class=arithmatex>\(\sum \beta_j^2\)</span> treats all coefficients equally, but features on different scales lead to coefficients of different magnitudes. Standardization ensures fair penalization across all features.</p> </div> <h3 id=geometric-interpretation-of-ridge-regression>Geometric Interpretation of Ridge Regression<a class=headerlink href=#geometric-interpretation-of-ridge-regression title="Permanent link">&para;</a></h3> <p>We can visualize Ridge regression geometrically in coefficient space. For two coefficients <span class=arithmatex>\(\beta_1\)</span> and <span class=arithmatex>\(\beta_2\)</span>, the constraint <span class=arithmatex>\(\beta_1^2 + \beta_2^2 \leq t\)</span> defines a circle (in higher dimensions, a hypersphere).</p> <p>The Ridge solution is the point where the smallest error contour (ellipse from the squared error term) touches this circular constraint region. The smooth circular boundary means the solution typically lies in the interior, not at a boundary where coefficients are exactly zero.</p> <h4 id=ridge-regression-geometry>Ridge Regression Geometry<a class=headerlink href=#ridge-regression-geometry title="Permanent link">&para;</a></h4> <iframe src=../../sims/ridge-regression-geometry/main.html width=100% height=582 frameborder=0></iframe> <h3 id=visualizing-coefficient-paths>Visualizing Coefficient Paths<a class=headerlink href=#visualizing-coefficient-paths title="Permanent link">&para;</a></h3> <p>A powerful way to understand Ridge regression is to plot how coefficients change as <span class=arithmatex>\(\lambda\)</span> increases:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># Compute Ridge solutions for a range of alpha values</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>alphas_range</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>logspace</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=n>coefs</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=k>for</span> <span class=n>alpha</span> <span class=ow>in</span> <span class=n>alphas_range</span><span class=p>:</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a>    <span class=n>ridge</span> <span class=o>=</span> <span class=n>Ridge</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=n>alpha</span><span class=p>)</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>    <span class=n>ridge</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>    <span class=n>coefs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>ridge</span><span class=o>.</span><span class=n>coef_</span><span class=p>)</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=c1># Plot coefficient paths</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>alphas_range</span><span class=p>,</span> <span class=n>coefs</span><span class=p>)</span>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a><span class=n>plt</span><span class=o>.</span><span class=n>xscale</span><span class=p>(</span><span class=s1>&#39;log&#39;</span><span class=p>)</span>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Alpha (λ)&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Coefficient Value&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-2-16><a id=__codelineno-2-16 name=__codelineno-2-16 href=#__codelineno-2-16></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Ridge Regression: Coefficient Paths&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span><span id=__span-2-17><a id=__codelineno-2-17 name=__codelineno-2-17 href=#__codelineno-2-17></a><span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mf>0.8</span><span class=p>)</span>
</span><span id=__span-2-18><a id=__codelineno-2-18 name=__codelineno-2-18 href=#__codelineno-2-18></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-2-19><a id=__codelineno-2-19 name=__codelineno-2-19 href=#__codelineno-2-19></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>This <strong>regularization path</strong> plot shows that as <span class=arithmatex>\(\lambda\)</span> increases, all coefficients shrink smoothly toward zero. Unlike L1 regularization (which we'll see next), coefficients approach zero asymptotically but never reach exactly zero.</p> <h2 id=l1-regularization-and-lasso-regression>L1 Regularization and Lasso Regression<a class=headerlink href=#l1-regularization-and-lasso-regression title="Permanent link">&para;</a></h2> <p><strong>L1 regularization</strong>, also called <strong>Lasso regularization</strong> (Least Absolute Shrinkage and Selection Operator), replaces the squared penalty with an absolute value penalty:</p> <div class=arithmatex>\[\min_{\boldsymbol{\beta}} \sum_{i=1}^{n} (y_i - \boldsymbol{\beta}^T \mathbf{x}_i)^2 + \lambda \sum_{j=1}^{p} |\beta_j|\]</div> <p>The L1 penalty term is <span class=arithmatex>\(\lambda \|\boldsymbol{\beta}\|_1 = \lambda \sum_{j=1}^{p} |\beta_j|\)</span>, the sum of absolute coefficient values.</p> <h3 id=the-power-of-l1-automatic-feature-selection>The Power of L1: Automatic Feature Selection<a class=headerlink href=#the-power-of-l1-automatic-feature-selection title="Permanent link">&para;</a></h3> <p>The most remarkable property of L1 regularization is that it can drive coefficients to <strong>exactly zero</strong>, effectively removing features from the model. This provides automatic <strong>feature selection</strong>: the model itself decides which features are most important.</p> <p>Why does L1 produce exact zeros while L2 doesn't? The difference lies in the geometry:</p> <ul> <li><strong>L2 penalty</strong> (<span class=arithmatex>\(\beta^2\)</span>): Smooth and differentiable everywhere, gradient approaches zero as <span class=arithmatex>\(\beta\)</span> approaches zero</li> <li><strong>L1 penalty</strong> (<span class=arithmatex>\(|\beta|\)</span>): Has a "corner" at zero with constant gradient, allowing coefficients to hit exactly zero</li> </ul> <p>This makes Lasso particularly valuable when:</p> <ol> <li>You have many features and suspect only a subset are truly predictive</li> <li>You want an interpretable model with fewer features</li> <li>You need to reduce model complexity for deployment or computational efficiency</li> </ol> <h3 id=lasso-regression-implementation>Lasso Regression Implementation<a class=headerlink href=#lasso-regression-implementation title="Permanent link">&para;</a></h3> <p>Scikit-learn provides the <code>Lasso</code> class for L1-regularized regression:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>Lasso</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=c1># Fit Lasso regression with different alpha values</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=n>alphas</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>,</span> <span class=mf>100.0</span><span class=p>]</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a><span class=k>for</span> <span class=n>alpha</span> <span class=ow>in</span> <span class=n>alphas</span><span class=p>:</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>    <span class=n>lasso</span> <span class=o>=</span> <span class=n>Lasso</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=n>alpha</span><span class=p>,</span> <span class=n>max_iter</span><span class=o>=</span><span class=mi>10000</span><span class=p>)</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>    <span class=n>lasso</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>    <span class=n>train_score</span> <span class=o>=</span> <span class=n>lasso</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>    <span class=n>test_score</span> <span class=o>=</span> <span class=n>lasso</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>    <span class=n>n_nonzero</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>lasso</span><span class=o>.</span><span class=n>coef_</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>)</span>
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a>
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Alpha=</span><span class=si>{</span><span class=n>alpha</span><span class=si>:</span><span class=s2>6.2f</span><span class=si>}</span><span class=s2>: Train R²=</span><span class=si>{</span><span class=n>train_score</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, Test R²=</span><span class=si>{</span><span class=n>test_score</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, Non-zero coefs=</span><span class=si>{</span><span class=n>n_nonzero</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>Notice how the number of non-zero coefficients decreases as <span class=arithmatex>\(\lambda\)</span> increases. Lasso is performing feature selection automatically!</p> <h3 id=geometric-interpretation-of-lasso-regression>Geometric Interpretation of Lasso Regression<a class=headerlink href=#geometric-interpretation-of-lasso-regression title="Permanent link">&para;</a></h3> <p>For two coefficients, the L1 constraint <span class=arithmatex>\(|\beta_1| + |\beta_2| \leq t\)</span> defines a diamond (in higher dimensions, a hypercube rotated 45°). The diamond has corners along the coordinate axes.</p> <p>When the error contour touches the constraint region, it's more likely to touch at a corner where one or more coefficients are exactly zero. This is why Lasso produces sparse solutions.</p> <h4 id=lasso-regression-geometry>Lasso Regression Geometry<a class=headerlink href=#lasso-regression-geometry title="Permanent link">&para;</a></h4> <iframe src=../../sims/lasso-regression-geometry/main.html width=100% height=582 frameborder=0></iframe> <h3 id=lasso-coefficient-paths>Lasso Coefficient Paths<a class=headerlink href=#lasso-coefficient-paths title="Permanent link">&para;</a></h3> <p>Plotting Lasso coefficient paths reveals the feature selection behavior:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># Compute Lasso solutions for a range of alpha values</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=n>alphas_range</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>logspace</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=n>coefs</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=k>for</span> <span class=n>alpha</span> <span class=ow>in</span> <span class=n>alphas_range</span><span class=p>:</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>    <span class=n>lasso</span> <span class=o>=</span> <span class=n>Lasso</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=n>alpha</span><span class=p>,</span> <span class=n>max_iter</span><span class=o>=</span><span class=mi>10000</span><span class=p>)</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>    <span class=n>lasso</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>    <span class=n>coefs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>lasso</span><span class=o>.</span><span class=n>coef_</span><span class=p>)</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a><span class=c1># Plot coefficient paths</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>alphas_range</span><span class=p>,</span> <span class=n>coefs</span><span class=p>)</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a><span class=n>plt</span><span class=o>.</span><span class=n>xscale</span><span class=p>(</span><span class=s1>&#39;log&#39;</span><span class=p>)</span>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Alpha (λ)&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Coefficient Value&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-4-16><a id=__codelineno-4-16 name=__codelineno-4-16 href=#__codelineno-4-16></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Lasso Regression: Coefficient Paths&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span><span id=__span-4-17><a id=__codelineno-4-17 name=__codelineno-4-17 href=#__codelineno-4-17></a><span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mf>0.8</span><span class=p>)</span>
</span><span id=__span-4-18><a id=__codelineno-4-18 name=__codelineno-4-18 href=#__codelineno-4-18></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-4-19><a id=__codelineno-4-19 name=__codelineno-4-19 href=#__codelineno-4-19></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>The Lasso paths show coefficients hitting exactly zero at different values of <span class=arithmatex>\(\lambda\)</span>. The order in which coefficients become zero indicates their relative importance: features whose coefficients remain non-zero at higher <span class=arithmatex>\(\lambda\)</span> values are more predictive.</p> <h2 id=comparing-ridge-and-lasso>Comparing Ridge and Lasso<a class=headerlink href=#comparing-ridge-and-lasso title="Permanent link">&para;</a></h2> <p>Both Ridge and Lasso address overfitting through regularization, but they have distinct characteristics:</p> <table> <thead> <tr> <th>Property</th> <th>Ridge (L2)</th> <th>Lasso (L1)</th> </tr> </thead> <tbody> <tr> <td><strong>Penalty</strong></td> <td><span class=arithmatex>\(\lambda \sum \beta_j^2\)</span></td> <td><span class=arithmatex>\(\lambda \sum \|\beta_j\|\)</span></td> </tr> <tr> <td><strong>Coefficient shrinkage</strong></td> <td>Smooth, asymptotic to zero</td> <td>Can reach exactly zero</td> </tr> <tr> <td><strong>Feature selection</strong></td> <td>No (all features retained)</td> <td>Yes (automatic)</td> </tr> <tr> <td><strong>Correlated features</strong></td> <td>Assigns similar weights</td> <td>Arbitrarily selects one</td> </tr> <tr> <td><strong>Solution uniqueness</strong></td> <td>Always unique</td> <td>May have multiple solutions</td> </tr> <tr> <td><strong>Computational cost</strong></td> <td>Fast (closed form)</td> <td>Slower (iterative optimization)</td> </tr> <tr> <td><strong>Interpretability</strong></td> <td>All features contribute</td> <td>Sparse model, easier to interpret</td> </tr> </tbody> </table> <h3 id=when-to-use-ridge-vs-lasso>When to Use Ridge vs Lasso<a class=headerlink href=#when-to-use-ridge-vs-lasso title="Permanent link">&para;</a></h3> <p><strong>Use Ridge when:</strong></p> <ul> <li>All features are potentially relevant</li> <li>Features are highly correlated (multicollinearity)</li> <li>You want stable, unique solutions</li> <li>Computational speed is critical</li> </ul> <p><strong>Use Lasso when:</strong></p> <ul> <li>You suspect many features are irrelevant</li> <li>You need automatic feature selection</li> <li>Interpretability is important (fewer features)</li> <li>You want a sparse model for deployment</li> </ul> <p><strong>Use both (Elastic Net) when:</strong></p> <ul> <li>You want a balance between Ridge and Lasso properties</li> <li>You have groups of correlated features and want to select groups</li> <li>You're unsure which regularization type is better</li> </ul> <h3 id=elastic-net-combining-l1-and-l2>Elastic Net: Combining L1 and L2<a class=headerlink href=#elastic-net-combining-l1-and-l2 title="Permanent link">&para;</a></h3> <p><strong>Elastic Net</strong> combines both L1 and L2 penalties:</p> <div class=arithmatex>\[\min_{\boldsymbol{\beta}} \sum_{i=1}^{n} (y_i - \boldsymbol{\beta}^T \mathbf{x}_i)^2 + \lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2\]</div> <p>Alternatively, it can be parameterized with a mixing parameter <span class=arithmatex>\(\alpha \in [0, 1]\)</span>:</p> <div class=arithmatex>\[\text{Penalty} = \lambda \left[ \alpha \|\boldsymbol{\beta}\|_1 + (1-\alpha) \|\boldsymbol{\beta}\|_2^2 \right]\]</div> <p>where <span class=arithmatex>\(\alpha = 0\)</span> gives Ridge, <span class=arithmatex>\(\alpha = 1\)</span> gives Lasso, and intermediate values blend the two.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>ElasticNet</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=c1># Elastic Net with balanced L1 and L2</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=n>elastic</span> <span class=o>=</span> <span class=n>ElasticNet</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>l1_ratio</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>max_iter</span><span class=o>=</span><span class=mi>10000</span><span class=p>)</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=n>elastic</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Training R²:&quot;</span><span class=p>,</span> <span class=n>elastic</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>))</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Test R²:&quot;</span><span class=p>,</span> <span class=n>elastic</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>,</span> <span class=n>y_test</span><span class=p>))</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Non-zero coefficients:&quot;</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>elastic</span><span class=o>.</span><span class=n>coef_</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>))</span>
</span></code></pre></div> <h2 id=selecting-the-regularization-parameter>Selecting the Regularization Parameter<a class=headerlink href=#selecting-the-regularization-parameter title="Permanent link">&para;</a></h2> <p>Choosing the optimal <span class=arithmatex>\(\lambda\)</span> is critical: too small allows overfitting, too large causes underfitting. <strong>Cross-validation</strong> provides a principled method for selecting <span class=arithmatex>\(\lambda\)</span>.</p> <h3 id=cross-validation-for-lambda-selection>Cross-Validation for Lambda Selection<a class=headerlink href=#cross-validation-for-lambda-selection title="Permanent link">&para;</a></h3> <p>We evaluate model performance across a range of <span class=arithmatex>\(\lambda\)</span> values using k-fold cross-validation:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>cross_val_score</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=c1># Test range of alpha values for Ridge</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=n>alphas</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>logspace</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=n>ridge_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a><span class=k>for</span> <span class=n>alpha</span> <span class=ow>in</span> <span class=n>alphas</span><span class=p>:</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>    <span class=n>ridge</span> <span class=o>=</span> <span class=n>Ridge</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=n>alpha</span><span class=p>)</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>ridge</span><span class=p>,</span> <span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;r2&#39;</span><span class=p>)</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>    <span class=n>ridge_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>scores</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a><span class=c1># Find optimal alpha</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a><span class=n>optimal_alpha_ridge</span> <span class=o>=</span> <span class=n>alphas</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>ridge_scores</span><span class=p>)]</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a><span class=c1># Plot cross-validation curve</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>alphas</span><span class=p>,</span> <span class=n>ridge_scores</span><span class=p>,</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Ridge&#39;</span><span class=p>)</span>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a><span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>optimal_alpha_ridge</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;blue&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Optimal α=</span><span class=si>{</span><span class=n>optimal_alpha_ridge</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a><span class=n>plt</span><span class=o>.</span><span class=n>xscale</span><span class=p>(</span><span class=s1>&#39;log&#39;</span><span class=p>)</span>
</span><span id=__span-6-20><a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Alpha (λ)&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-6-21><a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Cross-Validation R²&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-6-22><a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Ridge Regression: Cross-Validation Score vs Regularization Strength&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span><span id=__span-6-23><a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span><span id=__span-6-24><a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-6-25><a id=__codelineno-6-25 name=__codelineno-6-25 href=#__codelineno-6-25></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span><span id=__span-6-26><a id=__codelineno-6-26 name=__codelineno-6-26 href=#__codelineno-6-26></a>
</span><span id=__span-6-27><a id=__codelineno-6-27 name=__codelineno-6-27 href=#__codelineno-6-27></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Optimal alpha for Ridge: </span><span class=si>{</span><span class=n>optimal_alpha_ridge</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>The cross-validation curve typically shows:</p> <ol> <li><strong>Left side (small λ)</strong>: High variance, potential overfitting</li> <li><strong>Middle (optimal λ)</strong>: Best bias-variance trade-off</li> <li><strong>Right side (large λ)</strong>: High bias, underfitting</li> </ol> <h3 id=automated-hyperparameter-tuning>Automated Hyperparameter Tuning<a class=headerlink href=#automated-hyperparameter-tuning title="Permanent link">&para;</a></h3> <p>Scikit-learn provides <code>RidgeCV</code> and <code>LassoCV</code> for automatic cross-validated <span class=arithmatex>\(\lambda\)</span> selection:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>RidgeCV</span><span class=p>,</span> <span class=n>LassoCV</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=c1># Ridge with automatic alpha selection</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=n>ridge_cv</span> <span class=o>=</span> <span class=n>RidgeCV</span><span class=p>(</span><span class=n>alphas</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>logspace</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>100</span><span class=p>),</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=n>ridge_cv</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Optimal Ridge alpha:&quot;</span><span class=p>,</span> <span class=n>ridge_cv</span><span class=o>.</span><span class=n>alpha_</span><span class=p>)</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Test R²:&quot;</span><span class=p>,</span> <span class=n>ridge_cv</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>,</span> <span class=n>y_test</span><span class=p>))</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=c1># Lasso with automatic alpha selection</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a><span class=n>lasso_cv</span> <span class=o>=</span> <span class=n>LassoCV</span><span class=p>(</span><span class=n>alphas</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>logspace</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>100</span><span class=p>),</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>max_iter</span><span class=o>=</span><span class=mi>10000</span><span class=p>)</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a><span class=n>lasso_cv</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Optimal Lasso alpha:&quot;</span><span class=p>,</span> <span class=n>lasso_cv</span><span class=o>.</span><span class=n>alpha_</span><span class=p>)</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Test R²:&quot;</span><span class=p>,</span> <span class=n>lasso_cv</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>,</span> <span class=n>y_test</span><span class=p>))</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Non-zero coefficients:&quot;</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>lasso_cv</span><span class=o>.</span><span class=n>coef_</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>))</span>
</span></code></pre></div> <p>These cross-validated variants automatically search over the specified alpha values and select the one with the best cross-validation performance.</p> <h2 id=regularization-in-classification>Regularization in Classification<a class=headerlink href=#regularization-in-classification title="Permanent link">&para;</a></h2> <p>Regularization applies to classification algorithms as well. Logistic regression, SVMs, and neural networks all benefit from L1 and L2 penalties.</p> <h3 id=regularized-logistic-regression>Regularized Logistic Regression<a class=headerlink href=#regularized-logistic-regression title="Permanent link">&para;</a></h3> <p>Scikit-learn's <code>LogisticRegression</code> includes L2 regularization by default, controlled by the <code>C</code> parameter (note: <code>C = 1/λ</code>, so smaller <code>C</code> means stronger regularization):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>LogisticRegression</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_iris</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a><span class=c1># Load iris dataset</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=n>iris</span> <span class=o>=</span> <span class=n>load_iris</span><span class=p>()</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>target</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a><span class=c1># Split and scale</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y</span><span class=p>)</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a><span class=n>X_train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a><span class=n>X_test_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a><span class=c1># Compare different regularization strengths</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a><span class=n>C_values</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>,</span> <span class=mf>100.0</span><span class=p>]</span>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a><span class=k>for</span> <span class=n>C</span> <span class=ow>in</span> <span class=n>C_values</span><span class=p>:</span>
</span><span id=__span-8-19><a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a>    <span class=n>lr</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>(</span><span class=n>C</span><span class=o>=</span><span class=n>C</span><span class=p>,</span> <span class=n>max_iter</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-8-20><a id=__codelineno-8-20 name=__codelineno-8-20 href=#__codelineno-8-20></a>    <span class=n>lr</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-8-21><a id=__codelineno-8-21 name=__codelineno-8-21 href=#__codelineno-8-21></a>
</span><span id=__span-8-22><a id=__codelineno-8-22 name=__codelineno-8-22 href=#__codelineno-8-22></a>    <span class=n>train_acc</span> <span class=o>=</span> <span class=n>lr</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-8-23><a id=__codelineno-8-23 name=__codelineno-8-23 href=#__codelineno-8-23></a>    <span class=n>test_acc</span> <span class=o>=</span> <span class=n>lr</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span><span id=__span-8-24><a id=__codelineno-8-24 name=__codelineno-8-24 href=#__codelineno-8-24></a>
</span><span id=__span-8-25><a id=__codelineno-8-25 name=__codelineno-8-25 href=#__codelineno-8-25></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;C=</span><span class=si>{</span><span class=n>C</span><span class=si>:</span><span class=s2>6.2f</span><span class=si>}</span><span class=s2> (λ=</span><span class=si>{</span><span class=mi>1</span><span class=o>/</span><span class=n>C</span><span class=si>:</span><span class=s2>6.2f</span><span class=si>}</span><span class=s2>): Train Acc=</span><span class=si>{</span><span class=n>train_acc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, Test Acc=</span><span class=si>{</span><span class=n>test_acc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>For L1 regularization in logistic regression, specify <code>penalty='l1'</code> and use the <code>saga</code> or <code>liblinear</code> solver:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=c1># L1-regularized logistic regression</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=n>lr_l1</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>(</span><span class=n>penalty</span><span class=o>=</span><span class=s1>&#39;l1&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>solver</span><span class=o>=</span><span class=s1>&#39;saga&#39;</span><span class=p>,</span> <span class=n>max_iter</span><span class=o>=</span><span class=mi>10000</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=n>lr_l1</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Test Accuracy:&quot;</span><span class=p>,</span> <span class=n>lr_l1</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>,</span> <span class=n>y_test</span><span class=p>))</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Non-zero coefficients per class:&quot;</span><span class=p>)</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>coef</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>lr_l1</span><span class=o>.</span><span class=n>coef_</span><span class=p>):</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Class </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>coef</span><span class=w> </span><span class=o>!=</span><span class=w> </span><span class=mi>0</span><span class=p>)</span><span class=si>}</span><span class=s2> features&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=practical-considerations>Practical Considerations<a class=headerlink href=#practical-considerations title="Permanent link">&para;</a></h2> <h3 id=always-standardize-features>Always Standardize Features<a class=headerlink href=#always-standardize-features title="Permanent link">&para;</a></h3> <p>Regularization penalizes coefficient magnitudes, so feature scaling is essential:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># BAD: Regularization without scaling</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=n>ridge_bad</span> <span class=o>=</span> <span class=n>Ridge</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a><span class=n>ridge_bad</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>  <span class=c1># Features have different scales!</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a><span class=c1># GOOD: Standardize first</span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a><span class=n>X_train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a><span class=n>X_test_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a><span class=n>ridge_good</span> <span class=o>=</span> <span class=n>Ridge</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a><span class=n>ridge_good</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span></code></pre></div> <p>Without standardization, features with larger natural scales dominate the penalty term, leading to unfair shrinkage.</p> <h3 id=intercept-term>Intercept Term<a class=headerlink href=#intercept-term title="Permanent link">&para;</a></h3> <p>Typically, we <strong>do not</strong> regularize the intercept term <span class=arithmatex>\(\beta_0\)</span>. Scikit-learn handles this automatically with <code>fit_intercept=True</code> (the default).</p> <h3 id=regularization-path-algorithms>Regularization Path Algorithms<a class=headerlink href=#regularization-path-algorithms title="Permanent link">&para;</a></h3> <p>For Lasso and Elastic Net, specialized algorithms compute the entire regularization path (solutions for all <span class=arithmatex>\(\lambda\)</span> values) efficiently. Scikit-learn uses these algorithms internally in <code>LassoCV</code> and <code>ElasticNetCV</code>.</p> <h3 id=convergence-and-tolerance>Convergence and Tolerance<a class=headerlink href=#convergence-and-tolerance title="Permanent link">&para;</a></h3> <p>Lasso optimization uses iterative algorithms that may not converge with default settings for some problems. Increase <code>max_iter</code> or adjust <code>tol</code> if you see convergence warnings:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=n>lasso</span> <span class=o>=</span> <span class=n>Lasso</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>max_iter</span><span class=o>=</span><span class=mi>10000</span><span class=p>,</span> <span class=n>tol</span><span class=o>=</span><span class=mf>1e-4</span><span class=p>)</span>
</span></code></pre></div> <h2 id=ridge-vs-lasso-key-differences>Ridge vs Lasso: Key Differences<a class=headerlink href=#ridge-vs-lasso-key-differences title="Permanent link">&para;</a></h2> <p>The fundamental difference between Ridge and Lasso regularization lies in their behavior as <span class=arithmatex>\(\lambda\)</span> increases:</p> <table> <thead> <tr> <th>Property</th> <th>Ridge (L2)</th> <th>Lasso (L1)</th> </tr> </thead> <tbody> <tr> <td><strong>Constraint Shape</strong></td> <td>Circle: <span class=arithmatex>\(\beta_1^2 + \beta_2^2 \leq t\)</span></td> <td>Diamond: <span class=arithmatex>\(\|\beta_1\| + \|\beta_2\| \leq t\)</span></td> </tr> <tr> <td><strong>Coefficient Shrinkage</strong></td> <td>Smooth, asymptotic to zero</td> <td>Can reach exactly zero</td> </tr> <tr> <td><strong>Feature Selection</strong></td> <td>No (all coefficients remain)</td> <td>Yes (automatic)</td> </tr> <tr> <td><strong>Best When</strong></td> <td>All features relevant</td> <td>Many irrelevant features</td> </tr> <tr> <td><strong>Handling Multicollinearity</strong></td> <td>Excellent</td> <td>Picks one feature arbitrarily</td> </tr> <tr> <td><strong>Sparsity</strong></td> <td>Dense solutions</td> <td>Sparse solutions</td> </tr> <tr> <td><strong>Computational Cost</strong></td> <td>Closed-form solution</td> <td>Iterative (coordinate descent)</td> </tr> </tbody> </table> <p><strong>When to Use:</strong> - <strong>Ridge</strong>: You believe most features contribute to the prediction, want stable coefficients, or have multicollinear features - <strong>Lasso</strong>: You have many features and suspect only a subset are important, want an interpretable model, or need automatic feature selection - <strong>Elastic Net</strong>: Combines both L1 and L2, balancing feature selection with handling multicollinearity</p> <h2 id=summary_1>Summary<a class=headerlink href=#summary_1 title="Permanent link">&para;</a></h2> <p>Regularization is an essential technique for building machine learning models that generalize well beyond their training data. By adding penalty terms to the loss function, we constrain model complexity and prevent overfitting.</p> <p><strong>L2 regularization</strong> (Ridge) adds a penalty proportional to the sum of squared coefficients, shrinking them smoothly toward zero. Ridge is stable, fast, and works well when all features contribute to the prediction.</p> <p><strong>L1 regularization</strong> (Lasso) adds a penalty proportional to the sum of absolute coefficient values, driving some coefficients to exactly zero. Lasso performs automatic feature selection, producing sparse, interpretable models.</p> <p>The choice between Ridge and Lasso depends on your problem characteristics and goals. Cross-validation provides a principled method for selecting the regularization parameter <span class=arithmatex>\(\lambda\)</span>, balancing the bias-variance trade-off to optimize generalization performance.</p> <p>These regularization techniques extend beyond linear regression to classification (logistic regression, SVMs) and deep learning (neural networks), making them fundamental tools in every machine learning practitioner's toolkit.</p> <h2 id=key-takeaways>Key Takeaways<a class=headerlink href=#key-takeaways title="Permanent link">&para;</a></h2> <ol> <li><strong>Regularization</strong> prevents overfitting by adding a penalty term that discourages large coefficients</li> <li><strong>L2 regularization</strong> uses a squared penalty (<span class=arithmatex>\(\sum \beta_j^2\)</span>) and shrinks coefficients smoothly toward zero</li> <li><strong>Ridge regression</strong> applies L2 regularization to linear regression, providing stable solutions</li> <li><strong>L1 regularization</strong> uses an absolute value penalty (<span class=arithmatex>\(\sum |\beta_j|\)</span>) and can set coefficients to exactly zero</li> <li><strong>Lasso regression</strong> applies L1 regularization, performing automatic feature selection</li> <li><strong>Geometric interpretation</strong>: L2 creates circular constraints, L1 creates diamond constraints with corners on axes</li> <li><strong>Cross-validation</strong> is the standard method for selecting the optimal regularization strength <span class=arithmatex>\(\lambda\)</span></li> <li><strong>Feature standardization</strong> is essential before applying regularization to ensure fair penalization</li> <li><strong>Ridge</strong> is preferred when all features are relevant; <strong>Lasso</strong> when many features are irrelevant</li> <li><strong>Elastic Net</strong> combines L1 and L2 to balance their properties</li> </ol> <h2 id=further-reading>Further Reading<a class=headerlink href=#further-reading title="Permanent link">&para;</a></h2> <ul> <li>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The Elements of Statistical Learning</em> (Chapter 3: Linear Methods for Regression, Section 3.4)</li> <li>James, G., Witten, D., Hastie, T., &amp; Tibshirani, R. (2013). <em>An Introduction to Statistical Learning</em> (Chapter 6: Linear Model Selection and Regularization)</li> <li>Tibshirani, R. (1996). "Regression Shrinkage and Selection via the Lasso." <em>Journal of the Royal Statistical Society: Series B</em>, 58(1), 267-288.</li> <li>Scikit-learn documentation: <a href=https://scikit-learn.org/stable/modules/linear_model.html>Linear Models</a></li> </ul> <h2 id=exercises>Exercises<a class=headerlink href=#exercises title="Permanent link">&para;</a></h2> <ol> <li> <p><strong>Coefficient Paths</strong>: Generate a synthetic dataset with 20 features where only 5 are truly predictive (others are noise). Fit Ridge and Lasso with a range of <span class=arithmatex>\(\lambda\)</span> values and plot coefficient paths. Which method correctly identifies the true features?</p> </li> <li> <p><strong>Bias-Variance Decomposition</strong>: Implement a simulation that computes bias and variance of Ridge predictions for different <span class=arithmatex>\(\lambda\)</span> values. Plot bias, variance, and total error vs <span class=arithmatex>\(\lambda\)</span> to visualize the bias-variance trade-off.</p> </li> <li> <p><strong>Multicollinearity</strong>: Create a dataset where two features are highly correlated (<span class=arithmatex>\(r &gt; 0.9\)</span>). Compare how Ridge and Lasso handle these correlated features as <span class=arithmatex>\(\lambda\)</span> increases.</p> </li> <li> <p><strong>Cross-Validation Implementation</strong>: Implement k-fold cross-validation from scratch to select the optimal <span class=arithmatex>\(\lambda\)</span> for Ridge regression. Compare your results to scikit-learn's <code>RidgeCV</code>.</p> </li> <li> <p><strong>Regularization in Classification</strong>: Apply L1 and L2 regularized logistic regression to a high-dimensional classification dataset (e.g., text classification with bag-of-words features). Analyze which features are selected by Lasso and their interpretation.</p> </li> <li> <p><strong>Elastic Net Tuning</strong>: Use grid search to find optimal values of both <span class=arithmatex>\(\lambda\)</span> and the L1/L2 mixing parameter for Elastic Net on a real dataset. Visualize the 2D grid of cross-validation scores.</p> </li> </ol> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 | CC BY-NC-SA 4.0 DEED </div> </div> <div class=md-social> <a href=https://github.com/AnvithPothula target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/anvith-pothula target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>