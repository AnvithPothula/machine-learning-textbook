<!DOCTYPE html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Maximum margin classification, kernel trick, and nonlinear decision boundaries"><meta name=author content="Anvith Pothula"><link href=https://example.com/chapters/06-support-vector-machines/ rel=canonical><link href=../05-regularization/quiz/ rel=prev><link href=quiz/ rel=next><link rel=icon href=../../img/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Support Vector Machines - Machine Learning - Algorithms and Applications</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link href=../../assets/stylesheets/glightbox.min.css rel=stylesheet><script src=../../assets/javascripts/glightbox.min.js></script><style id=glightbox-style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#support-vector-machines class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-header__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <img src=../../img/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Machine Learning - Algorithms and Applications </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Support Vector Machines </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-nav__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <img src=../../img/logo.png alt=logo> </a> Machine Learning - Algorithms and Applications </label> <div class=md-nav__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-nav__item> <a href=../../course-description/ class=md-nav__link> <span class=md-ellipsis> Course Description </span> </a> </li> <li class=md-nav__item> <a href=../../faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> <li class=md-nav__item> <a href=../../glossary/ class=md-nav__link> <span class=md-ellipsis> Glossary </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> Chapters </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Chapters </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_2> <div class="md-nav__link md-nav__container"> <a href=../01-intro-to-ml-fundamentals/ class="md-nav__link "> <span class=md-ellipsis> 1. ML Fundamentals </span> </a> <label class="md-nav__link " for=__nav_5_2 id=__nav_5_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> 1. ML Fundamentals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_3> <div class="md-nav__link md-nav__container"> <a href=../02-k-nearest-neighbors/ class="md-nav__link "> <span class=md-ellipsis> 2. K-Nearest Neighbors </span> </a> <label class="md-nav__link " for=__nav_5_3 id=__nav_5_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_3_label aria-expanded=false> <label class=md-nav__title for=__nav_5_3> <span class="md-nav__icon md-icon"></span> 2. K-Nearest Neighbors </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../02-k-nearest-neighbors/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_4> <div class="md-nav__link md-nav__container"> <a href=../03-decision-trees/ class="md-nav__link "> <span class=md-ellipsis> 3. Decision Trees </span> </a> <label class="md-nav__link " for=__nav_5_4 id=__nav_5_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_4_label aria-expanded=false> <label class=md-nav__title for=__nav_5_4> <span class="md-nav__icon md-icon"></span> 3. Decision Trees </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../03-decision-trees/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_5> <div class="md-nav__link md-nav__container"> <a href=../04-logistic-regression/ class="md-nav__link "> <span class=md-ellipsis> 4. Logistic Regression </span> </a> <label class="md-nav__link " for=__nav_5_5 id=__nav_5_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5_5> <span class="md-nav__icon md-icon"></span> 4. Logistic Regression </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../04-logistic-regression/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_6> <div class="md-nav__link md-nav__container"> <a href=../05-regularization/ class="md-nav__link "> <span class=md-ellipsis> 5. Regularization </span> </a> <label class="md-nav__link " for=__nav_5_6 id=__nav_5_6_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_6_label aria-expanded=false> <label class=md-nav__title for=__nav_5_6> <span class="md-nav__icon md-icon"></span> 5. Regularization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../05-regularization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_7 checked> <div class="md-nav__link md-nav__container"> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 6. Support Vector Machines </span> </a> <label class="md-nav__link md-nav__link--active" for=__nav_5_7 id=__nav_5_7_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_7_label aria-expanded=true> <label class=md-nav__title for=__nav_5_7> <span class="md-nav__icon md-icon"></span> 6. Support Vector Machines </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_8> <div class="md-nav__link md-nav__container"> <a href=../07-k-means-clustering/ class="md-nav__link "> <span class=md-ellipsis> 7. K-Means Clustering </span> </a> <label class="md-nav__link " for=__nav_5_8 id=__nav_5_8_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_8_label aria-expanded=false> <label class=md-nav__title for=__nav_5_8> <span class="md-nav__icon md-icon"></span> 7. K-Means Clustering </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../07-k-means-clustering/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_9> <div class="md-nav__link md-nav__container"> <a href=../08-data-preprocessing/ class="md-nav__link "> <span class=md-ellipsis> 8. Data Preprocessing </span> </a> <label class="md-nav__link " for=__nav_5_9 id=__nav_5_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_9_label aria-expanded=false> <label class=md-nav__title for=__nav_5_9> <span class="md-nav__icon md-icon"></span> 8. Data Preprocessing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../08-data-preprocessing/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_10> <div class="md-nav__link md-nav__container"> <a href=../09-neural-networks/ class="md-nav__link "> <span class=md-ellipsis> 9. Neural Networks </span> </a> <label class="md-nav__link " for=__nav_5_10 id=__nav_5_10_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_10_label aria-expanded=false> <label class=md-nav__title for=__nav_5_10> <span class="md-nav__icon md-icon"></span> 9. Neural Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../09-neural-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_11> <div class="md-nav__link md-nav__container"> <a href=../10-convolutional-networks/ class="md-nav__link "> <span class=md-ellipsis> 10. Convolutional Networks </span> </a> <label class="md-nav__link " for=__nav_5_11 id=__nav_5_11_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_11_label aria-expanded=false> <label class=md-nav__title for=__nav_5_11> <span class="md-nav__icon md-icon"></span> 10. Convolutional Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../10-convolutional-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_12> <div class="md-nav__link md-nav__container"> <a href=../11-transfer-learning/ class="md-nav__link "> <span class=md-ellipsis> 11. Transfer Learning </span> </a> <label class="md-nav__link " for=__nav_5_12 id=__nav_5_12_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_12_label aria-expanded=false> <label class=md-nav__title for=__nav_5_12> <span class="md-nav__icon md-icon"></span> 11. Transfer Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../11-transfer-learning/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_13> <div class="md-nav__link md-nav__container"> <a href=../12-evaluation-optimization/ class="md-nav__link "> <span class=md-ellipsis> 12. Evaluation &amp; Optimization </span> </a> <label class="md-nav__link " for=__nav_5_13 id=__nav_5_13_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_13_label aria-expanded=false> <label class=md-nav__title for=__nav_5_13> <span class="md-nav__icon md-icon"></span> 12. Evaluation &amp; Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../12-evaluation-optimization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <div class="md-nav__link md-nav__container"> <a href=../../sims/ class="md-nav__link "> <span class=md-ellipsis> MicroSims </span> </a> <label class="md-nav__link " for=__nav_6 id=__nav_6_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> MicroSims </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../sims/activation-functions/ class=md-nav__link> <span class=md-ellipsis> Activation Functions </span> </a> </li> <li class=md-nav__item> <a href=../../sims/categorical-encoding-explorer/ class=md-nav__link> <span class=md-ellipsis> Categorical Encoding Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/cnn-architecture/ class=md-nav__link> <span class=md-ellipsis> CNN Architecture </span> </a> </li> <li class=md-nav__item> <a href=../../sims/confusion-matrix-explorer/ class=md-nav__link> <span class=md-ellipsis> Confusion Matrix Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/convolution-operation/ class=md-nav__link> <span class=md-ellipsis> Convolution Operation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/distance-metrics/ class=md-nav__link> <span class=md-ellipsis> Distance Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../sims/entropy-gini-comparison/ class=md-nav__link> <span class=md-ellipsis> Entropy-Gini Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/feature-scaling-visualizer/ class=md-nav__link> <span class=md-ellipsis> Feature Scaling Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/k-selection-simulator/ class=md-nav__link> <span class=md-ellipsis> K-Selection Simulator </span> </a> </li> <li class=md-nav__item> <a href=../../sims/kfold-cross-validation/ class=md-nav__link> <span class=md-ellipsis> K-Fold Cross Validation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/lasso-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Lasso Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/network-architecture-visualizer/ class=md-nav__link> <span class=md-ellipsis> Network Architecture Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/ridge-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Ridge Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/roc-curve-comparison/ class=md-nav__link> <span class=md-ellipsis> ROC Curve Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/sigmoid-explorer/ class=md-nav__link> <span class=md-ellipsis> Sigmoid Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/svm-margin-maximization/ class=md-nav__link> <span class=md-ellipsis> SVM Margin Maximization </span> </a> </li> <li class=md-nav__item> <a href=../../sims/training-validation-curves/ class=md-nav__link> <span class=md-ellipsis> Training Validation Curves </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <div class="md-nav__link md-nav__container"> <a href=../../learning-graph/ class="md-nav__link "> <span class=md-ellipsis> Learning Graph </span> </a> <label class="md-nav__link " for=__nav_7 id=__nav_7_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Learning Graph </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../sims/graph-viewer/ class=md-nav__link> <span class=md-ellipsis> Graph Viewer </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/course-description-assessment/ class=md-nav__link> <span class=md-ellipsis> Course Description Assessment </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-list/ class=md-nav__link> <span class=md-ellipsis> Concept List </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-taxonomy/ class=md-nav__link> <span class=md-ellipsis> Concept Taxonomy </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.csv class=md-nav__link> <span class=md-ellipsis> Learning Graph (CSV) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.json class=md-nav__link> <span class=md-ellipsis> Learning Graph (JSON) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/quality-metrics/ class=md-nav__link> <span class=md-ellipsis> Quality Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/taxonomy-distribution/ class=md-nav__link> <span class=md-ellipsis> Taxonomy Distribution </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/glossary-quality-report/ class=md-nav__link> <span class=md-ellipsis> Glossary Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-quality-report/ class=md-nav__link> <span class=md-ellipsis> FAQ Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-coverage-gaps/ class=md-nav__link> <span class=md-ellipsis> FAQ Coverage Gaps </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/book-metrics/ class=md-nav__link> <span class=md-ellipsis> Book Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/chapter-metrics/ class=md-nav__link> <span class=md-ellipsis> Chapter Metrics </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../about/ class=md-nav__link> <span class=md-ellipsis> About </span> </a> </li> <li class=md-nav__item> <a href=../../license/ class=md-nav__link> <span class=md-ellipsis> License </span> </a> </li> <li class=md-nav__item> <a href=../../contact/ class=md-nav__link> <span class=md-ellipsis> Contact </span> </a> </li> <li class=md-nav__item> <a href=../../feature-checklist/ class=md-nav__link> <span class=md-ellipsis> Feature Checklist </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#the-quest-for-the-best-decision-boundary class=md-nav__link> <span class=md-ellipsis> The Quest for the Best Decision Boundary </span> </a> <nav class=md-nav aria-label="The Quest for the Best Decision Boundary"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#linear-separability-and-hyperplanes class=md-nav__link> <span class=md-ellipsis> Linear Separability and Hyperplanes </span> </a> </li> <li class=md-nav__item> <a href=#the-margin class=md-nav__link> <span class=md-ellipsis> The Margin </span> </a> </li> <li class=md-nav__item> <a href=#support-vectors class=md-nav__link> <span class=md-ellipsis> Support Vectors </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hard-margin-svm class=md-nav__link> <span class=md-ellipsis> Hard Margin SVM </span> </a> <nav class=md-nav aria-label="Hard Margin SVM"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#limitations-of-hard-margin-svm class=md-nav__link> <span class=md-ellipsis> Limitations of Hard Margin SVM </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#soft-margin-svm class=md-nav__link> <span class=md-ellipsis> Soft Margin SVM </span> </a> </li> <li class=md-nav__item> <a href=#svm-in-practice-bank-loan-classification class=md-nav__link> <span class=md-ellipsis> SVM in Practice: Bank Loan Classification </span> </a> <nav class=md-nav aria-label="SVM in Practice: Bank Loan Classification"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#loading-and-exploring-the-data class=md-nav__link> <span class=md-ellipsis> Loading and Exploring the Data </span> </a> </li> <li class=md-nav__item> <a href=#data-preprocessing class=md-nav__link> <span class=md-ellipsis> Data Preprocessing </span> </a> </li> <li class=md-nav__item> <a href=#training-a-linear-svm class=md-nav__link> <span class=md-ellipsis> Training a Linear SVM </span> </a> </li> <li class=md-nav__item> <a href=#tuning-the-regularization-parameter class=md-nav__link> <span class=md-ellipsis> Tuning the Regularization Parameter </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#the-kernel-trick class=md-nav__link> <span class=md-ellipsis> The Kernel Trick </span> </a> <nav class=md-nav aria-label="The Kernel Trick"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-core-idea class=md-nav__link> <span class=md-ellipsis> The Core Idea </span> </a> </li> <li class=md-nav__item> <a href=#example-polynomial-transformation class=md-nav__link> <span class=md-ellipsis> Example: Polynomial Transformation </span> </a> </li> <li class=md-nav__item> <a href=#common-kernel-functions class=md-nav__link> <span class=md-ellipsis> Common Kernel Functions </span> </a> </li> <li class=md-nav__item> <a href=#applying-different-kernels class=md-nav__link> <span class=md-ellipsis> Applying Different Kernels </span> </a> </li> <li class=md-nav__item> <a href=#tuning-rbf-kernel-parameters class=md-nav__link> <span class=md-ellipsis> Tuning RBF Kernel Parameters </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#primal-and-dual-formulations class=md-nav__link> <span class=md-ellipsis> Primal and Dual Formulations </span> </a> <nav class=md-nav aria-label="Primal and Dual Formulations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#primal-formulation class=md-nav__link> <span class=md-ellipsis> Primal Formulation </span> </a> </li> <li class=md-nav__item> <a href=#dual-formulation class=md-nav__link> <span class=md-ellipsis> Dual Formulation </span> </a> </li> <li class=md-nav__item> <a href=#why-use-the-dual class=md-nav__link> <span class=md-ellipsis> Why Use the Dual? </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#interactive-visualization-maximum-margin-classification class=md-nav__link> <span class=md-ellipsis> Interactive Visualization: Maximum Margin Classification </span> </a> </li> <li class=md-nav__item> <a href=#interactive-visualization-kernel-trick-demonstration class=md-nav__link> <span class=md-ellipsis> Interactive Visualization: Kernel Trick Demonstration </span> </a> </li> <li class=md-nav__item> <a href=#practical-considerations class=md-nav__link> <span class=md-ellipsis> Practical Considerations </span> </a> <nav class=md-nav aria-label="Practical Considerations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#feature-scaling class=md-nav__link> <span class=md-ellipsis> Feature Scaling </span> </a> </li> <li class=md-nav__item> <a href=#computational-complexity class=md-nav__link> <span class=md-ellipsis> Computational Complexity </span> </a> </li> <li class=md-nav__item> <a href=#when-to-use-svms class=md-nav__link> <span class=md-ellipsis> When to Use SVMs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multiclass-classification-with-svms class=md-nav__link> <span class=md-ellipsis> Multiclass Classification with SVMs </span> </a> </li> <li class=md-nav__item> <a href=#summary_1 class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#key-takeaways class=md-nav__link> <span class=md-ellipsis> Key Takeaways </span> </a> </li> <li class=md-nav__item> <a href=#further-reading class=md-nav__link> <span class=md-ellipsis> Further Reading </span> </a> </li> <li class=md-nav__item> <a href=#exercises class=md-nav__link> <span class=md-ellipsis> Exercises </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <nav class=md-path aria-label=Navigation> <ol class=md-path__list> <li class=md-path__item> <a href=../.. class=md-path__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-path__item> <a href=../ class=md-path__link> <span class=md-ellipsis> Chapters </span> </a> </li> <li class=md-path__item> <a href=./ class=md-path__link> <span class=md-ellipsis> 6. Support Vector Machines </span> </a> </li> </ol> </nav> <article class="md-content__inner md-typeset"> <h1 id=support-vector-machines>Support Vector Machines<a class=headerlink href=#support-vector-machines title="Permanent link">¶</a></h1> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">¶</a></h2> <p>This chapter provides comprehensive coverage of Support Vector Machines (SVMs), powerful algorithms for both linear and nonlinear classification. Students will learn how SVMs find optimal decision boundaries by maximizing the margin between classes, understand the role of support vectors in defining these boundaries, and explore the difference between hard-margin and soft-margin formulations. The chapter introduces the kernel trick, a mathematical technique that enables SVMs to learn complex nonlinear decision boundaries by implicitly mapping data to higher-dimensional spaces. Students will explore various kernel functions (linear, polynomial, RBF/Gaussian) and understand the duality between primal and dual formulations.</p> <h2 id=concepts-covered>Concepts Covered<a class=headerlink href=#concepts-covered title="Permanent link">¶</a></h2> <p>This chapter covers the following 16 concepts from the learning graph:</p> <ol> <li>Support Vector Machine</li> <li>Hyperplane</li> <li>Margin</li> <li>Support Vectors</li> <li>Margin Maximization</li> <li>Hard Margin SVM</li> <li>Soft Margin SVM</li> <li>Slack Variables</li> <li>Kernel Trick</li> <li>Linear Kernel</li> <li>Polynomial Kernel</li> <li>Radial Basis Function</li> <li>Gaussian Kernel</li> <li>Dual Formulation</li> <li>Primal Formulation</li> <li>Kernel Size</li> </ol> <h2 id=prerequisites>Prerequisites<a class=headerlink href=#prerequisites title="Permanent link">¶</a></h2> <p>This chapter builds on concepts from:</p> <ul> <li><a href=../01-intro-to-ml-fundamentals/ >Chapter 1: Introduction to Machine Learning Fundamentals</a></li> <li><a href=../04-logistic-regression/ >Chapter 4: Logistic Regression and Classification</a></li> </ul> <hr> <h2 id=the-quest-for-the-best-decision-boundary>The Quest for the Best Decision Boundary<a class=headerlink href=#the-quest-for-the-best-decision-boundary title="Permanent link">¶</a></h2> <p>Classification algorithms must draw decision boundaries that separate classes in feature space. Logistic regression finds boundaries using probabilistic reasoning, decision trees partition space with axis-aligned splits, and k-nearest neighbors use local voting regions. But how do we define the "best" boundary?</p> <p><strong>Support Vector Machines</strong> (SVMs) provide an elegant answer: the best decision boundary is the one that maximizes the margin—the distance to the nearest training examples from each class. This principle of <strong>margin maximization</strong> leads to classifiers that generalize well and have strong theoretical guarantees.</p> <p>Consider a simple two-class problem where data points are linearly separable. Infinitely many lines (or hyperplanes in higher dimensions) can separate the classes perfectly. SVMs choose the unique hyperplane that lies exactly in the middle of the gap between the two classes, maximizing the minimum distance to any training point.</p> <h3 id=linear-separability-and-hyperplanes>Linear Separability and Hyperplanes<a class=headerlink href=#linear-separability-and-hyperplanes title="Permanent link">¶</a></h3> <p>A <strong>hyperplane</strong> in <span class=arithmatex>\(d\)</span>-dimensional space is a <span class=arithmatex>\((d-1)\)</span>-dimensional flat subspace defined by:</p> <div class=arithmatex>\[\mathbf{w}^T \mathbf{x} + b = 0\]</div> <p>where:</p> <ul> <li><span class=arithmatex>\(\mathbf{w}\)</span> is the <strong>weight vector</strong> (normal to the hyperplane)</li> <li><span class=arithmatex>\(b\)</span> is the <strong>bias</strong> term (controls hyperplane position)</li> <li><span class=arithmatex>\(\mathbf{x}\)</span> is a point in feature space</li> </ul> <p>For 2D data, a hyperplane is a line. For 3D data, it's a plane. In higher dimensions, we still call it a hyperplane.</p> <p>The hyperplane divides space into two half-spaces:</p> <ul> <li><strong>Positive side</strong>: <span class=arithmatex>\(\mathbf{w}^T \mathbf{x} + b &gt; 0\)</span></li> <li><strong>Negative side</strong>: <span class=arithmatex>\(\mathbf{w}^T \mathbf{x} + b &lt; 0\)</span></li> </ul> <p>We assign class labels based on which side a point falls:</p> <div class=arithmatex>\[\hat{y} = \begin{cases} +1 &amp; \text{if } \mathbf{w}^T \mathbf{x} + b \geq 0 \\ -1 &amp; \text{if } \mathbf{w}^T \mathbf{x} + b &lt; 0 \end{cases}\]</div> <h3 id=the-margin>The Margin<a class=headerlink href=#the-margin title="Permanent link">¶</a></h3> <p>The <strong>margin</strong> is the perpendicular distance from the decision boundary to the nearest data point from either class. For a hyperplane defined by <span class=arithmatex>\(\mathbf{w}\)</span> and <span class=arithmatex>\(b\)</span>, the distance from a point <span class=arithmatex>\(\mathbf{x}_i\)</span> to the hyperplane is:</p> <div class=arithmatex>\[\text{distance} = \frac{|{\mathbf{w}^T \mathbf{x}_i + b}|}{\|\mathbf{w}\|}\]</div> <p>The margin width is twice this minimum distance:</p> <div class=arithmatex>\[\text{margin} = \frac{2}{\|\mathbf{w}\|}\]</div> <p>SVMs seek the hyperplane that maximizes this margin. Geometrically, this means finding the "widest street" that separates the two classes.</p> <h3 id=support-vectors>Support Vectors<a class=headerlink href=#support-vectors title="Permanent link">¶</a></h3> <p><strong>Support vectors</strong> are the training points that lie exactly on the margin boundaries—the data points closest to the decision boundary. These critical points define the optimal hyperplane. Remarkably, the SVM solution depends only on support vectors; all other training points could be removed without changing the decision boundary.</p> <p>This sparsity property makes SVMs computationally efficient and resistant to outliers far from the boundary. Only points near the decision boundary influence the final classifier.</p> <h2 id=hard-margin-svm>Hard Margin SVM<a class=headerlink href=#hard-margin-svm title="Permanent link">¶</a></h2> <p>The <strong>hard margin SVM</strong> assumes the data is perfectly linearly separable and enforces that all training points be on the correct side of the margin. The optimization problem is:</p> <div class=arithmatex>\[\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2\]</div> <p>subject to:</p> <div class=arithmatex>\[y_i(\mathbf{w}^T \mathbf{x}_i + b) \geq 1 \quad \text{for all } i = 1, \ldots, n\]</div> <p>The constraints ensure that:</p> <ul> <li>Points with <span class=arithmatex>\(y_i = +1\)</span> satisfy <span class=arithmatex>\(\mathbf{w}^T \mathbf{x}_i + b \geq 1\)</span> (above the upper margin boundary)</li> <li>Points with <span class=arithmatex>\(y_i = -1\)</span> satisfy <span class=arithmatex>\(\mathbf{w}^T \mathbf{x}_i + b \leq -1\)</span> (below the lower margin boundary)</li> </ul> <p>Minimizing <span class=arithmatex>\(\frac{1}{2}\|\mathbf{w}\|^2\)</span> is equivalent to maximizing the margin <span class=arithmatex>\(\frac{2}{\|\mathbf{w}\|}\)</span>.</p> <h3 id=limitations-of-hard-margin-svm>Limitations of Hard Margin SVM<a class=headerlink href=#limitations-of-hard-margin-svm title="Permanent link">¶</a></h3> <p>Hard margin SVMs have serious limitations:</p> <ol> <li><strong>Requires perfect linear separability</strong>: If even one point cannot be correctly classified with a linear boundary, no solution exists</li> <li><strong>Sensitive to outliers</strong>: A single mislabeled or anomalous point can drastically change the optimal hyperplane</li> <li><strong>No flexibility</strong>: Cannot handle noisy data or overlapping class distributions</li> </ol> <p>Real-world datasets are rarely perfectly separable, necessitating a more flexible formulation.</p> <h2 id=soft-margin-svm>Soft Margin SVM<a class=headerlink href=#soft-margin-svm title="Permanent link">¶</a></h2> <p><strong>Soft margin SVMs</strong> relax the hard constraint by introducing <strong>slack variables</strong> <span class=arithmatex>\(\xi_i \geq 0\)</span> that allow some points to violate the margin or even be misclassified:</p> <div class=arithmatex>\[\min_{\mathbf{w}, b, \boldsymbol{\xi}} \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^{n} \xi_i\]</div> <p>subject to:</p> <div class=arithmatex>\[y_i(\mathbf{w}^T \mathbf{x}_i + b) \geq 1 - \xi_i \quad \text{and} \quad \xi_i \geq 0 \quad \text{for all } i\]</div> <p>The slack variable <span class=arithmatex>\(\xi_i\)</span> represents the degree of margin violation for point <span class=arithmatex>\(i\)</span>:</p> <ul> <li><span class=arithmatex>\(\xi_i = 0\)</span>: Point is on or outside the correct margin boundary (no violation)</li> <li><span class=arithmatex>\(0 &lt; \xi_i &lt; 1\)</span>: Point is inside the margin but correctly classified</li> <li><span class=arithmatex>\(\xi_i \geq 1\)</span>: Point is misclassified</li> </ul> <p>The parameter <span class=arithmatex>\(C &gt; 0\)</span> controls the trade-off between margin width and margin violations:</p> <ul> <li><strong>Large <span class=arithmatex>\(C\)</span></strong>: Heavily penalize violations, prioritize correct classification (risk overfitting)</li> <li><strong>Small <span class=arithmatex>\(C\)</span></strong>: Tolerate violations, prioritize large margin (risk underfitting)</li> </ul> <p>This formulation balances two competing objectives: maximize the margin (first term) while minimizing classification errors and margin violations (second term).</p> <div class="admonition note"> <p class=admonition-title>Regularization Connection</p> <p>The soft margin SVM objective is analogous to regularized models from Chapter 5. The <span class=arithmatex>\(\frac{1}{2}\|\mathbf{w}\|^2\)</span> term is an L2 penalty encouraging simpler models, while <span class=arithmatex>\(C\)</span> controls regularization strength (smaller <span class=arithmatex>\(C\)</span> = stronger regularization).</p> </div> <h2 id=svm-in-practice-bank-loan-classification>SVM in Practice: Bank Loan Classification<a class=headerlink href=#svm-in-practice-bank-loan-classification title="Permanent link">¶</a></h2> <p>Let's apply SVMs to a real-world problem: predicting whether a bank loan application will be approved based on applicant information.</p> <h3 id=loading-and-exploring-the-data>Loading and Exploring the Data<a class=headerlink href=#loading-and-exploring-the-data title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=kn>import</span><span class=w> </span><span class=nn>seaborn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>sns</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn</span><span class=w> </span><span class=kn>import</span> <span class=n>svm</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>confusion_matrix</span><span class=p>,</span> <span class=n>accuracy_score</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a><span class=c1># Load bank loan dataset</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=n>loan_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>'https://raw.githubusercontent.com/sziccardi/MLCamp2025_DataRepository/main/credit.csv'</span><span class=p>)</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a><span class=c1># Display first few rows</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a><span class=nb>print</span><span class=p>(</span><span class=n>loan_df</span><span class=o>.</span><span class=n>head</span><span class=p>())</span>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a><span class=c1># Check for missing values</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a><span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Missing values:"</span><span class=p>)</span>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a><span class=nb>print</span><span class=p>(</span><span class=n>loan_df</span><span class=o>.</span><span class=n>isnull</span><span class=p>()</span><span class=o>.</span><span class=n>sum</span><span class=p>())</span>
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a><span class=c1># Class distribution</span>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a><span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Loan approval distribution:"</span><span class=p>)</span>
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a><span class=nb>print</span><span class=p>(</span><span class=n>loan_df</span><span class=p>[</span><span class=s1>'Loan_Status'</span><span class=p>]</span><span class=o>.</span><span class=n>value_counts</span><span class=p>())</span>
</span></code></pre></div> <p>The dataset contains both categorical features (Gender, Married, Education) and quantitative features (ApplicantIncome, LoanAmount, Credit_History). For this example, we'll focus on quantitative features.</p> <p>The data shows class imbalance: 422 loans approved (Y) versus 192 rejected (N). This imbalance can affect classifier performance and should be considered during evaluation.</p> <h3 id=data-preprocessing>Data Preprocessing<a class=headerlink href=#data-preprocessing title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># Drop rows with missing values</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=n>new_loan_df</span> <span class=o>=</span> <span class=n>loan_df</span><span class=o>.</span><span class=n>dropna</span><span class=p>()</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Dataset size after removing missing values: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>new_loan_df</span><span class=p>)</span><span class=si>}</span><span class=s2> rows"</span><span class=p>)</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=c1># Select quantitative features</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a><span class=n>features</span> <span class=o>=</span> <span class=p>[</span><span class=s1>'ApplicantIncome'</span><span class=p>,</span> <span class=s1>'CoapplicantIncome'</span><span class=p>,</span> <span class=s1>'LoanAmount'</span><span class=p>,</span>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>            <span class=s1>'Loan_Amount_Term'</span><span class=p>,</span> <span class=s1>'Credit_History'</span><span class=p>]</span>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a><span class=n>X</span> <span class=o>=</span> <span class=n>new_loan_df</span><span class=p>[</span><span class=n>features</span><span class=p>]</span>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a><span class=n>y</span> <span class=o>=</span> <span class=n>new_loan_df</span><span class=p>[</span><span class=s1>'Loan_Status'</span><span class=p>]</span>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a><span class=c1># Split into training and test sets</span>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.25</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-1-15><a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a>
</span><span id=__span-1-16><a id=__codelineno-1-16 name=__codelineno-1-16 href=#__codelineno-1-16></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Training set: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span><span class=si>}</span><span class=s2> samples"</span><span class=p>)</span>
</span><span id=__span-1-17><a id=__codelineno-1-17 name=__codelineno-1-17 href=#__codelineno-1-17></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Test set: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span><span class=si>}</span><span class=s2> samples"</span><span class=p>)</span>
</span></code></pre></div> <p>After removing missing values, we have 480 loan records with complete data. We split this into 75% training (360 samples) and 25% testing (120 samples).</p> <h3 id=training-a-linear-svm>Training a Linear SVM<a class=headerlink href=#training-a-linear-svm title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># Train SVM with linear kernel</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>svc</span> <span class=o>=</span> <span class=n>svm</span><span class=o>.</span><span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>'linear'</span><span class=p>)</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=n>svc</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=c1># Make predictions on test set</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a><span class=n>y_pred</span> <span class=o>=</span> <span class=n>svc</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a><span class=c1># Evaluate performance</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a><span class=n>cm</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=n>accuracy</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Confusion Matrix:"</span><span class=p>)</span>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a><span class=nb>print</span><span class=p>(</span><span class=n>cm</span><span class=p>)</span>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Accuracy: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span></code></pre></div> <p>The linear SVM achieves approximately 78% accuracy on the test set. The confusion matrix reveals the model's performance:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a>[[12, 26],
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a> [ 0, 82]]
</span></code></pre></div> <p>This shows: - True Negatives: 12 (correctly rejected) - False Positives: 26 (incorrectly approved) - False Negatives: 0 (incorrectly rejected) - True Positives: 82 (correctly approved)</p> <p>The model tends to approve loans more readily, which aligns with the class imbalance in the training data.</p> <h3 id=tuning-the-regularization-parameter>Tuning the Regularization Parameter<a class=headerlink href=#tuning-the-regularization-parameter title="Permanent link">¶</a></h3> <p>The <code>C</code> parameter in scikit-learn controls the soft margin trade-off:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># Test different C values</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=n>C_values</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>,</span> <span class=mf>100.0</span><span class=p>]</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=k>for</span> <span class=n>C</span> <span class=ow>in</span> <span class=n>C_values</span><span class=p>:</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>    <span class=n>svc</span> <span class=o>=</span> <span class=n>svm</span><span class=o>.</span><span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>'linear'</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=n>C</span><span class=p>)</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>    <span class=n>svc</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a>    <span class=n>train_acc</span> <span class=o>=</span> <span class=n>svc</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>    <span class=n>test_acc</span> <span class=o>=</span> <span class=n>svc</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>    <span class=n>n_support</span> <span class=o>=</span> <span class=n>svc</span><span class=o>.</span><span class=n>n_support_</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a>    <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a>        <span class=s1>'C'</span><span class=p>:</span> <span class=n>C</span><span class=p>,</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a>        <span class=s1>'Train_Acc'</span><span class=p>:</span> <span class=n>train_acc</span><span class=p>,</span>
</span><span id=__span-4-16><a id=__codelineno-4-16 name=__codelineno-4-16 href=#__codelineno-4-16></a>        <span class=s1>'Test_Acc'</span><span class=p>:</span> <span class=n>test_acc</span><span class=p>,</span>
</span><span id=__span-4-17><a id=__codelineno-4-17 name=__codelineno-4-17 href=#__codelineno-4-17></a>        <span class=s1>'Support_Vectors'</span><span class=p>:</span> <span class=nb>sum</span><span class=p>(</span><span class=n>n_support</span><span class=p>)</span>
</span><span id=__span-4-18><a id=__codelineno-4-18 name=__codelineno-4-18 href=#__codelineno-4-18></a>    <span class=p>})</span>
</span><span id=__span-4-19><a id=__codelineno-4-19 name=__codelineno-4-19 href=#__codelineno-4-19></a>
</span><span id=__span-4-20><a id=__codelineno-4-20 name=__codelineno-4-20 href=#__codelineno-4-20></a><span class=c1># Display results</span>
</span><span id=__span-4-21><a id=__codelineno-4-21 name=__codelineno-4-21 href=#__codelineno-4-21></a><span class=n>results_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>results</span><span class=p>)</span>
</span><span id=__span-4-22><a id=__codelineno-4-22 name=__codelineno-4-22 href=#__codelineno-4-22></a><span class=nb>print</span><span class=p>(</span><span class=n>results_df</span><span class=p>)</span>
</span><span id=__span-4-23><a id=__codelineno-4-23 name=__codelineno-4-23 href=#__codelineno-4-23></a>
</span><span id=__span-4-24><a id=__codelineno-4-24 name=__codelineno-4-24 href=#__codelineno-4-24></a><span class=c1># Plot accuracy vs C</span>
</span><span id=__span-4-25><a id=__codelineno-4-25 name=__codelineno-4-25 href=#__codelineno-4-25></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-4-26><a id=__codelineno-4-26 name=__codelineno-4-26 href=#__codelineno-4-26></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>results_df</span><span class=p>[</span><span class=s1>'C'</span><span class=p>],</span> <span class=n>results_df</span><span class=p>[</span><span class=s1>'Train_Acc'</span><span class=p>],</span> <span class=s1>'b-o'</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>'Training'</span><span class=p>)</span>
</span><span id=__span-4-27><a id=__codelineno-4-27 name=__codelineno-4-27 href=#__codelineno-4-27></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>results_df</span><span class=p>[</span><span class=s1>'C'</span><span class=p>],</span> <span class=n>results_df</span><span class=p>[</span><span class=s1>'Test_Acc'</span><span class=p>],</span> <span class=s1>'r-s'</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>'Test'</span><span class=p>)</span>
</span><span id=__span-4-28><a id=__codelineno-4-28 name=__codelineno-4-28 href=#__codelineno-4-28></a><span class=n>plt</span><span class=o>.</span><span class=n>xscale</span><span class=p>(</span><span class=s1>'log'</span><span class=p>)</span>
</span><span id=__span-4-29><a id=__codelineno-4-29 name=__codelineno-4-29 href=#__codelineno-4-29></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>'C (Regularization Parameter)'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-4-30><a id=__codelineno-4-30 name=__codelineno-4-30 href=#__codelineno-4-30></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>'Accuracy'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-4-31><a id=__codelineno-4-31 name=__codelineno-4-31 href=#__codelineno-4-31></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>'SVM Performance vs Regularization Strength'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span><span id=__span-4-32><a id=__codelineno-4-32 name=__codelineno-4-32 href=#__codelineno-4-32></a><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span><span id=__span-4-33><a id=__codelineno-4-33 name=__codelineno-4-33 href=#__codelineno-4-33></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-4-34><a id=__codelineno-4-34 name=__codelineno-4-34 href=#__codelineno-4-34></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>The number of support vectors typically decreases as <span class=arithmatex>\(C\)</span> increases (fewer violations tolerated), while training accuracy increases. The optimal <span class=arithmatex>\(C\)</span> balances these to maximize test performance.</p> <h2 id=the-kernel-trick>The Kernel Trick<a class=headerlink href=#the-kernel-trick title="Permanent link">¶</a></h2> <p>Real-world data often cannot be separated by a linear boundary. Consider data arranged in concentric circles or XOR patterns—no straight line can classify these correctly. The <strong>kernel trick</strong> is SVM's elegant solution to this problem.</p> <h3 id=the-core-idea>The Core Idea<a class=headerlink href=#the-core-idea title="Permanent link">¶</a></h3> <p>Instead of finding a nonlinear boundary in the original feature space, the kernel trick:</p> <ol> <li><strong>Implicitly maps</strong> data to a higher-dimensional space where it becomes linearly separable</li> <li><strong>Computes only inner products</strong> in this high-dimensional space, avoiding explicit transformation</li> <li><strong>Uses kernel functions</strong> <span class=arithmatex>\(K(\mathbf{x}_i, \mathbf{x}_j)\)</span> that represent inner products in the transformed space</li> </ol> <p>Remarkably, we never need to compute the actual transformation <span class=arithmatex>\(\phi(\mathbf{x})\)</span>—the kernel function computes <span class=arithmatex>\(\phi(\mathbf{x}_i)^T \phi(\mathbf{x}_j)\)</span> directly.</p> <h3 id=example-polynomial-transformation>Example: Polynomial Transformation<a class=headerlink href=#example-polynomial-transformation title="Permanent link">¶</a></h3> <p>Consider 2D data <span class=arithmatex>\((x_1, x_2)\)</span> that needs a quadratic boundary. We could explicitly transform:</p> <div class=arithmatex>\[\phi(x_1, x_2) = (x_1^2, \sqrt{2}x_1 x_2, x_2^2, \sqrt{2}x_1, \sqrt{2}x_2, 1)\]</div> <p>This maps 2D data to 6D space. The inner product in this space is:</p> <div class=arithmatex>\[\phi(\mathbf{x})^T \phi(\mathbf{z}) = (x_1 z_1 + x_2 z_2 + 1)^2\]</div> <p>The <strong>polynomial kernel</strong> computes this directly without constructing the 6D vectors:</p> <div class=arithmatex>\[K(\mathbf{x}, \mathbf{z}) = (\mathbf{x}^T \mathbf{z} + 1)^2\]</div> <p>For higher dimensions and higher degrees, explicit transformation becomes computationally infeasible, but the kernel trick remains efficient.</p> <h3 id=common-kernel-functions>Common Kernel Functions<a class=headerlink href=#common-kernel-functions title="Permanent link">¶</a></h3> <p>SVMs support various kernel functions, each suitable for different data patterns:</p> <p><strong>1. Linear Kernel</strong></p> <div class=arithmatex>\[K(\mathbf{x}, \mathbf{z}) = \mathbf{x}^T \mathbf{z}\]</div> <p>The <strong>linear kernel</strong> is equivalent to the standard inner product—no transformation. Use when data is linearly separable or nearly so.</p> <p><strong>2. Polynomial Kernel</strong></p> <div class=arithmatex>\[K(\mathbf{x}, \mathbf{z}) = (\gamma \mathbf{x}^T \mathbf{z} + r)^d\]</div> <p>The <strong>polynomial kernel</strong> creates polynomial decision boundaries of degree <span class=arithmatex>\(d\)</span>. Parameters: - <span class=arithmatex>\(d\)</span>: degree (controls complexity) - <span class=arithmatex>\(\gamma\)</span>: scaling factor - <span class=arithmatex>\(r\)</span>: independent term (allows shifting)</p> <p>Degree 2 creates parabolic boundaries, degree 3 creates cubic boundaries, etc.</p> <p><strong>3. Radial Basis Function (RBF) / Gaussian Kernel</strong></p> <div class=arithmatex>\[K(\mathbf{x}, \mathbf{z}) = \exp\left(-\gamma \|\mathbf{x} - \mathbf{z}\|^2\right)\]</div> <p>The <strong>RBF kernel</strong> (also called <strong>Gaussian kernel</strong>) is the most popular nonlinear kernel. It creates smooth, flexible decision boundaries and implicitly maps to infinite-dimensional space.</p> <p>The parameter <span class=arithmatex>\(\gamma\)</span> (called <strong>kernel size</strong> or bandwidth) controls the influence of individual training points: - <strong>Large <span class=arithmatex>\(\gamma\)</span></strong>: Each point influences only nearby regions (high complexity, risk of overfitting) - <strong>Small <span class=arithmatex>\(\gamma\)</span></strong>: Each point influences broader regions (lower complexity, smoother boundaries)</p> <p><strong>4. Sigmoid Kernel</strong></p> <div class=arithmatex>\[K(\mathbf{x}, \mathbf{z}) = \tanh(\gamma \mathbf{x}^T \mathbf{z} + r)\]</div> <p>The sigmoid kernel resembles neural network activation functions. Less commonly used than polynomial or RBF kernels.</p> <h3 id=applying-different-kernels>Applying Different Kernels<a class=headerlink href=#applying-different-kernels title="Permanent link">¶</a></h3> <p>Let's test different kernels on the loan dataset:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=c1># Define kernels to test</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=n>kernels</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>    <span class=s1>'linear'</span><span class=p>:</span> <span class=n>svm</span><span class=o>.</span><span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>'linear'</span><span class=p>),</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>    <span class=s1>'poly'</span><span class=p>:</span> <span class=n>svm</span><span class=o>.</span><span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>'poly'</span><span class=p>,</span> <span class=n>degree</span><span class=o>=</span><span class=mi>3</span><span class=p>),</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>    <span class=s1>'rbf'</span><span class=p>:</span> <span class=n>svm</span><span class=o>.</span><span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>'rbf'</span><span class=p>),</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>    <span class=s1>'sigmoid'</span><span class=p>:</span> <span class=n>svm</span><span class=o>.</span><span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>'sigmoid'</span><span class=p>)</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=p>}</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=c1># Train and evaluate each kernel</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>model</span> <span class=ow>in</span> <span class=n>kernels</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a>    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a>    <span class=n>train_acc</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a>    <span class=n>test_acc</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span><span id=__span-5-15><a id=__codelineno-5-15 name=__codelineno-5-15 href=#__codelineno-5-15></a>
</span><span id=__span-5-16><a id=__codelineno-5-16 name=__codelineno-5-16 href=#__codelineno-5-16></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>name</span><span class=o>.</span><span class=n>capitalize</span><span class=p>()</span><span class=si>}</span><span class=s2> Kernel:"</span><span class=p>)</span>
</span><span id=__span-5-17><a id=__codelineno-5-17 name=__codelineno-5-17 href=#__codelineno-5-17></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  Training Accuracy: </span><span class=si>{</span><span class=n>train_acc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-5-18><a id=__codelineno-5-18 name=__codelineno-5-18 href=#__codelineno-5-18></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  Test Accuracy: </span><span class=si>{</span><span class=n>test_acc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-5-19><a id=__codelineno-5-19 name=__codelineno-5-19 href=#__codelineno-5-19></a>    <span class=nb>print</span><span class=p>()</span>
</span></code></pre></div> <p>For this particular dataset, the linear kernel performs best (78% test accuracy), while nonlinear kernels achieve lower accuracy (68-69%). This suggests the loan approval decision boundary is approximately linear in the feature space, and nonlinear kernels may be overfitting the training data.</p> <div class="admonition warning"> <p class=admonition-title>Kernel Selection</p> <p>More complex kernels don't always improve performance. Start with a linear kernel as a baseline. Use nonlinear kernels when: - Data has clear nonlinear patterns - Linear models underperform significantly - Domain knowledge suggests nonlinear relationships</p> <p>Always validate kernel choice using cross-validation on held-out data.</p> </div> <h3 id=tuning-rbf-kernel-parameters>Tuning RBF Kernel Parameters<a class=headerlink href=#tuning-rbf-kernel-parameters title="Permanent link">¶</a></h3> <p>The RBF kernel has two key hyperparameters to tune: <span class=arithmatex>\(C\)</span> (regularization) and <span class=arithmatex>\(\gamma\)</span> (kernel bandwidth):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>GridSearchCV</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=c1># Define parameter grid</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=n>param_grid</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>    <span class=s1>'C'</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>],</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>    <span class=s1>'gamma'</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.001</span><span class=p>,</span> <span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a><span class=p>}</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a><span class=c1># Grid search with cross-validation</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a><span class=n>grid_search</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span><span class=n>svm</span><span class=o>.</span><span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>'rbf'</span><span class=p>),</span> <span class=n>param_grid</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>'accuracy'</span><span class=p>)</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a><span class=n>grid_search</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Best parameters:"</span><span class=p>,</span> <span class=n>grid_search</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Best cross-validation score:"</span><span class=p>,</span> <span class=n>grid_search</span><span class=o>.</span><span class=n>best_score_</span><span class=p>)</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a><span class=c1># Evaluate on test set</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a><span class=n>best_model</span> <span class=o>=</span> <span class=n>grid_search</span><span class=o>.</span><span class=n>best_estimator_</span>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a><span class=n>test_acc</span> <span class=o>=</span> <span class=n>best_model</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test</span><span class=p>,</span> <span class=n>y_test</span><span class=p>)</span>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Test accuracy with best parameters: </span><span class=si>{</span><span class=n>test_acc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span></code></pre></div> <p>Grid search explores combinations of <span class=arithmatex>\(C\)</span> and <span class=arithmatex>\(\gamma\)</span> to find optimal values that maximize cross-validation performance.</p> <h2 id=primal-and-dual-formulations>Primal and Dual Formulations<a class=headerlink href=#primal-and-dual-formulations title="Permanent link">¶</a></h2> <p>SVMs can be formulated in two mathematically equivalent ways: the <strong>primal formulation</strong> and the <strong>dual formulation</strong>.</p> <h3 id=primal-formulation>Primal Formulation<a class=headerlink href=#primal-formulation title="Permanent link">¶</a></h3> <p>The primal formulation directly optimizes over the weights <span class=arithmatex>\(\mathbf{w}\)</span> and bias <span class=arithmatex>\(b\)</span>:</p> <div class=arithmatex>\[\min_{\mathbf{w}, b, \boldsymbol{\xi}} \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^{n} \xi_i\]</div> <p>subject to: <span class=arithmatex>\(y_i(\mathbf{w}^T \mathbf{x}_i + b) \geq 1 - \xi_i\)</span> and <span class=arithmatex>\(\xi_i \geq 0\)</span></p> <p>This formulation has <span class=arithmatex>\(d + 1 + n\)</span> variables (<span class=arithmatex>\(d\)</span> weights, 1 bias, <span class=arithmatex>\(n\)</span> slack variables) and <span class=arithmatex>\(2n\)</span> constraints.</p> <h3 id=dual-formulation>Dual Formulation<a class=headerlink href=#dual-formulation title="Permanent link">¶</a></h3> <p>Through Lagrangian duality, the problem can be rewritten to optimize over dual variables <span class=arithmatex>\(\boldsymbol{\alpha} = (\alpha_1, \ldots, \alpha_n)\)</span>:</p> <div class=arithmatex>\[\max_{\boldsymbol{\alpha}} \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j \mathbf{x}_i^T \mathbf{x}_j\]</div> <p>subject to: <span class=arithmatex>\(0 \leq \alpha_i \leq C\)</span> and <span class=arithmatex>\(\sum_{i=1}^{n} \alpha_i y_i = 0\)</span></p> <p>The dual formulation has <span class=arithmatex>\(n\)</span> variables and <span class=arithmatex>\(2n + 1\)</span> constraints. Key properties:</p> <ol> <li><strong>Depends only on inner products</strong> <span class=arithmatex>\(\mathbf{x}_i^T \mathbf{x}_j\)</span>: This is where the kernel trick applies!</li> <li><strong>Support vectors</strong> have <span class=arithmatex>\(\alpha_i &gt; 0\)</span>; all other points have <span class=arithmatex>\(\alpha_i = 0\)</span></li> <li><strong>Decision function</strong> becomes: <span class=arithmatex>\(f(\mathbf{x}) = \sum_{i=1}^{n} \alpha_i y_i K(\mathbf{x}_i, \mathbf{x}) + b\)</span></li> </ol> <h3 id=why-use-the-dual>Why Use the Dual?<a class=headerlink href=#why-use-the-dual title="Permanent link">¶</a></h3> <p>The dual formulation enables:</p> <ol> <li><strong>Kernel trick</strong>: Replace <span class=arithmatex>\(\mathbf{x}_i^T \mathbf{x}_j\)</span> with <span class=arithmatex>\(K(\mathbf{x}_i, \mathbf{x}_j)\)</span> for nonlinear boundaries</li> <li><strong>Sparsity</strong>: Most <span class=arithmatex>\(\alpha_i = 0\)</span>, only support vectors matter</li> <li><strong>High-dimensional efficiency</strong>: When <span class=arithmatex>\(n &lt; d\)</span>, dual has fewer variables than primal</li> </ol> <p>Most SVM software (including scikit-learn) solves the dual formulation using specialized optimization algorithms like Sequential Minimal Optimization (SMO).</p> <h2 id=interactive-visualization-maximum-margin-classification>Interactive Visualization: Maximum Margin Classification<a class=headerlink href=#interactive-visualization-maximum-margin-classification title="Permanent link">¶</a></h2> <iframe src=../../sims/svm-margin-maximization/main.html width=100% height=582 style="border: 1px solid #ccc; border-radius: 4px;"></iframe> <p><a class=md-button href=../../sims/svm-margin-maximization/main.html target=_blank>View Fullscreen</a> | <a href=../../sims/svm-margin-maximization/ >Documentation</a></p> <h2 id=interactive-visualization-kernel-trick-demonstration>Interactive Visualization: Kernel Trick Demonstration<a class=headerlink href=#interactive-visualization-kernel-trick-demonstration title="Permanent link">¶</a></h2> <h4 id=kernel-trick-transformation>Kernel Trick Transformation<a class=headerlink href=#kernel-trick-transformation title="Permanent link">¶</a></h4> <pre class=mermaid><code>graph TD
    Original["Original Space (2D)&lt;br/&gt;Non-linearly separable&lt;br/&gt;🔴🔵 mixed"]
    Kernel["Kernel Function&lt;br/&gt;φ(x): ℝ² → ℝⁿ"]
    Transform["Transformed Space&lt;br/&gt;(High-dimensional)&lt;br/&gt;Linearly separable"]
    Linear["Linear SVM&lt;br/&gt;in high-dim space"]
    Nonlinear["Nonlinear boundary&lt;br/&gt;in original space"]

    Original --&gt; Kernel
    Kernel --&gt; Transform
    Transform --&gt; Linear
    Linear --&gt;|Project back| Nonlinear

    classDef spaceNode fill:#e3f2fd,stroke:#2196F3,stroke-width:2px,color:#000,font-size:14px
    classDef kernelNode fill:#f3e5f5,stroke:#9c27b0,stroke-width:2px,color:#000,font-size:14px
    classDef resultNode fill:#e8f5e9,stroke:#4caf50,stroke-width:2px,color:#000,font-size:14px

    class Original,Transform spaceNode
    class Kernel kernelNode
    class Linear,Nonlinear resultNode

    linkStyle default stroke:#666,stroke-width:2px,font-size:12px</code></pre> <p><strong>Common Kernels:</strong></p> <table> <thead> <tr> <th>Kernel</th> <th>Formula</th> <th>Use Case</th> </tr> </thead> <tbody> <tr> <td><strong>Linear</strong></td> <td>K(x, x') = x · x'</td> <td>Already linearly separable</td> </tr> <tr> <td><strong>Polynomial</strong></td> <td>K(x, x') = (x · x' + c)^d</td> <td>Curved boundaries, degree d</td> </tr> <tr> <td><strong>RBF (Gaussian)</strong></td> <td>K(x, x') = exp(-γ\</td> <td>x - x'\</td> </tr> <tr> <td><strong>Sigmoid</strong></td> <td>K(x, x') = tanh(αx · x' + c)</td> <td>Neural network-like</td> </tr> </tbody> </table> <p><strong>Key Insight</strong>: The kernel trick computes inner products in high-dimensional space <strong>without explicitly transforming the data</strong>, making it computationally efficient.</p> <h2 id=practical-considerations>Practical Considerations<a class=headerlink href=#practical-considerations title="Permanent link">¶</a></h2> <h3 id=feature-scaling>Feature Scaling<a class=headerlink href=#feature-scaling title="Permanent link">¶</a></h3> <p>SVMs are sensitive to feature scales. The margin depends on distances in feature space, so features with larger scales dominate the optimization:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=c1># Always scale features before training SVM</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=n>X_train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=n>X_test_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=c1># Train SVM on scaled data</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a><span class=n>svc</span> <span class=o>=</span> <span class=n>svm</span><span class=o>.</span><span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>'rbf'</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=s1>'scale'</span><span class=p>)</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=n>svc</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Test accuracy with scaling:"</span><span class=p>,</span> <span class=n>svc</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>,</span> <span class=n>y_test</span><span class=p>))</span>
</span></code></pre></div> <p>Without scaling, features like "ApplicantIncome" (range: 150-81,000) would dominate features like "Credit_History" (range: 0-1).</p> <h3 id=computational-complexity>Computational Complexity<a class=headerlink href=#computational-complexity title="Permanent link">¶</a></h3> <p>Training SVMs requires solving a quadratic programming problem:</p> <ul> <li><strong>Linear SVM</strong>: <span class=arithmatex>\(O(nd)\)</span> to <span class=arithmatex>\(O(n^2 d)\)</span> depending on optimization method</li> <li><strong>Kernel SVM</strong>: <span class=arithmatex>\(O(n^2 d)\)</span> to <span class=arithmatex>\(O(n^3)\)</span></li> </ul> <p>where <span class=arithmatex>\(n\)</span> is the number of samples and <span class=arithmatex>\(d\)</span> is the number of features.</p> <p>For large datasets (<span class=arithmatex>\(n &gt; 10,000\)</span>), consider: - <strong>LinearSVC</strong>: Optimized for linear kernels, scales better than <code>SVC(kernel='linear')</code> - <strong>Stochastic methods</strong>: Approximate solutions with faster training - <strong>Subset selection</strong>: Train on representative subsets for very large datasets</p> <h3 id=when-to-use-svms>When to Use SVMs<a class=headerlink href=#when-to-use-svms title="Permanent link">¶</a></h3> <p><strong>Strengths:</strong></p> <ul> <li>Effective in high-dimensional spaces (works well even when <span class=arithmatex>\(d &gt; n\)</span>)</li> <li>Memory efficient (only stores support vectors)</li> <li>Versatile (different kernels for different data patterns)</li> <li>Strong theoretical foundations (margin maximization, VC theory)</li> <li>Works well with clear margins between classes</li> </ul> <p><strong>Limitations:</strong></p> <ul> <li>Requires careful feature scaling</li> <li>Sensitive to hyperparameter choices (<span class=arithmatex>\(C\)</span>, <span class=arithmatex>\(\gamma\)</span>)</li> <li>Does not directly provide probability estimates (requires calibration)</li> <li>Computationally expensive for large datasets</li> <li>Less interpretable than decision trees or linear models</li> <li>Choosing the right kernel requires domain knowledge and experimentation</li> </ul> <p><strong>Use SVMs when:</strong></p> <ul> <li>You have a moderate-sized dataset (<span class=arithmatex>\(n &lt; 10,000\)</span>)</li> <li>The problem is binary or multiclass classification</li> <li>Features are continuous and can be meaningfully scaled</li> <li>You need strong generalization performance</li> <li>High-dimensional data or need for nonlinear boundaries</li> </ul> <p><strong>Avoid SVMs when:</strong></p> <ul> <li>Working with very large datasets (consider linear models or neural networks)</li> <li>Features are predominantly categorical without natural ordering</li> <li>Interpretability is paramount (use decision trees or linear models)</li> <li>You need well-calibrated probability estimates (use logistic regression)</li> </ul> <h2 id=multiclass-classification-with-svms>Multiclass Classification with SVMs<a class=headerlink href=#multiclass-classification-with-svms title="Permanent link">¶</a></h2> <p>SVMs are inherently binary classifiers, but they can handle multiclass problems using two strategies:</p> <p><strong>One-vs-One (OvO):</strong> Train <span class=arithmatex>\(\binom{K}{2}\)</span> binary classifiers for each pair of classes. Prediction uses voting.</p> <p><strong>One-vs-Rest (OvR):</strong> Train <span class=arithmatex>\(K\)</span> binary classifiers, each separating one class from all others. Prediction selects the class with highest confidence.</p> <p>Scikit-learn's <code>SVC</code> uses One-vs-One by default for multiclass problems:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_iris</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=c1># Load iris dataset (3 classes)</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=n>iris</span> <span class=o>=</span> <span class=n>load_iris</span><span class=p>()</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a><span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>target</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=c1># Split and scale</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a><span class=n>X_train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a><span class=n>X_test_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a><span class=c1># Train multiclass SVM</span>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a><span class=n>svc_multi</span> <span class=o>=</span> <span class=n>svm</span><span class=o>.</span><span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>'rbf'</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=s1>'scale'</span><span class=p>)</span>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a><span class=n>svc_multi</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Test accuracy:"</span><span class=p>,</span> <span class=n>svc_multi</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>,</span> <span class=n>y_test</span><span class=p>))</span>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Number of support vectors per class:"</span><span class=p>,</span> <span class=n>svc_multi</span><span class=o>.</span><span class=n>n_support_</span><span class=p>)</span>
</span></code></pre></div> <h2 id=summary_1>Summary<a class=headerlink href=#summary_1 title="Permanent link">¶</a></h2> <p>Support Vector Machines provide a principled approach to classification through margin maximization. By finding the decision boundary that lies furthest from both classes, SVMs achieve strong generalization performance with theoretical guarantees.</p> <p>The <strong>hard margin SVM</strong> requires perfect linear separability and is sensitive to outliers. The <strong>soft margin SVM</strong> introduces slack variables to tolerate violations, controlled by the regularization parameter <span class=arithmatex>\(C\)</span>. This formulation balances margin width against classification errors.</p> <p>The <strong>kernel trick</strong> extends SVMs to handle nonlinear boundaries by implicitly mapping data to higher-dimensional spaces. Common kernels include the linear kernel (no transformation), polynomial kernel (polynomial boundaries), and RBF/Gaussian kernel (smooth, flexible boundaries). The choice of kernel and its parameters (<span class=arithmatex>\(\gamma\)</span> for RBF, degree for polynomial) critically affects performance.</p> <p>SVMs can be formulated in <strong>primal</strong> (optimizing weights directly) or <strong>dual</strong> (optimizing Lagrange multipliers) form. The dual formulation enables the kernel trick and reveals that only <strong>support vectors</strong>—points on or inside the margin boundaries—determine the decision boundary.</p> <p>While SVMs excel with moderate-sized datasets and high-dimensional features, they require careful preprocessing (feature scaling), hyperparameter tuning (<span class=arithmatex>\(C\)</span>, kernel parameters), and can be computationally expensive for large datasets.</p> <h2 id=key-takeaways>Key Takeaways<a class=headerlink href=#key-takeaways title="Permanent link">¶</a></h2> <ol> <li><strong>SVMs maximize the margin</strong> between classes, finding the decision boundary furthest from training points</li> <li><strong>Hyperplanes</strong> are <span class=arithmatex>\((d-1)\)</span>-dimensional surfaces that divide <span class=arithmatex>\(d\)</span>-dimensional space</li> <li><strong>Support vectors</strong> are the critical training points on the margin boundaries that define the optimal hyperplane</li> <li><strong>Hard margin SVMs</strong> require perfect separability; <strong>soft margin SVMs</strong> use slack variables to tolerate violations</li> <li>The <strong>regularization parameter <span class=arithmatex>\(C\)</span></strong> controls the margin-violation trade-off</li> <li>The <strong>kernel trick</strong> enables nonlinear boundaries by implicitly mapping to higher dimensions</li> <li><strong>Linear kernel</strong> uses no transformation; <strong>polynomial kernel</strong> creates polynomial boundaries; <strong>RBF kernel</strong> creates smooth, flexible boundaries</li> <li>The <strong>gamma parameter</strong> (<span class=arithmatex>\(\gamma\)</span>) controls kernel size/bandwidth in RBF and polynomial kernels</li> <li><strong>Dual formulation</strong> enables the kernel trick and reveals sparsity (only support vectors matter)</li> <li>SVMs require feature scaling and careful hyperparameter tuning for optimal performance</li> </ol> <h2 id=further-reading>Further Reading<a class=headerlink href=#further-reading title="Permanent link">¶</a></h2> <ul> <li>Cortes, C., &amp; Vapnik, V. (1995). "Support-vector networks." <em>Machine Learning</em>, 20(3), 273-297.</li> <li>Cristianini, N., &amp; Shawe-Taylor, J. (2000). <em>An Introduction to Support Vector Machines</em>. Cambridge University Press.</li> <li>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The Elements of Statistical Learning</em> (Chapter 12: Support Vector Machines)</li> <li>Schölkopf, B., &amp; Smola, A. J. (2002). <em>Learning with Kernels</em>. MIT Press.</li> <li>Scikit-learn documentation: <a href=https://scikit-learn.org/stable/modules/svm.html>Support Vector Machines</a></li> </ul> <h2 id=exercises>Exercises<a class=headerlink href=#exercises title="Permanent link">¶</a></h2> <ol> <li> <p><strong>Margin Geometry</strong>: Prove that the margin width for a hyperplane defined by <span class=arithmatex>\(\mathbf{w}\)</span> and <span class=arithmatex>\(b\)</span> is <span class=arithmatex>\(\frac{2}{\|\mathbf{w}\|}\)</span>. Show mathematically why minimizing <span class=arithmatex>\(\|\mathbf{w}\|^2\)</span> maximizes the margin.</p> </li> <li> <p><strong>Support Vector Identification</strong>: Train an SVM on a 2D dataset and plot the decision boundary, margins, and support vectors. Verify that removing non-support vectors and retraining produces the same decision boundary.</p> </li> <li> <p><strong>Kernel Comparison</strong>: Generate three synthetic datasets: (a) linearly separable, (b) concentric circles, © XOR pattern. Train SVMs with linear, polynomial, and RBF kernels on each. Which kernel works best for each dataset and why?</p> </li> <li> <p><strong>Hyperparameter Tuning</strong>: Use grid search with cross-validation to find optimal <span class=arithmatex>\((C, \gamma)\)</span> values for an RBF SVM on the iris dataset. Visualize the grid search results as a heatmap showing accuracy for each parameter combination.</p> </li> <li> <p><strong>Primal vs Dual</strong>: Implement a simple 2D linear SVM solver in both primal and dual formulations. Compare the solutions and verify they produce the same decision boundary. Time the implementations for different dataset sizes.</p> </li> <li> <p><strong>Kernel Implementation</strong>: Implement a custom kernel function (e.g., a string kernel for text data) and use it with scikit-learn's <code>SVC</code> class. Test on a text classification problem.</p> </li> </ol> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../05-regularization/quiz/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Quiz"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Quiz </div> </div> </a> <a href=quiz/ class="md-footer__link md-footer__link--next" aria-label="Next: Quiz"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Quiz </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright © 2025 | CC BY-NC-SA 4.0 DEED </div> </div> <div class=md-social> <a href=https://github.com/AnvithPothula target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </a> <a href=https://linkedin.com/in/anvith-pothula target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"></path></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.path", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>