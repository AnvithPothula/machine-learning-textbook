<!DOCTYPE html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Discovering natural groupings in unlabeled data through iterative centroid-based clustering"><meta name=author content="Anvith Pothula"><link href=https://example.com/chapters/07-k-means-clustering/ rel=canonical><link href=../06-support-vector-machines/quiz/ rel=prev><link href=quiz/ rel=next><link rel=icon href=../../img/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>K-Means Clustering and Unsupervised Learning - Machine Learning - Algorithms and Applications</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link href=../../assets/stylesheets/glightbox.min.css rel=stylesheet><script src=../../assets/javascripts/glightbox.min.js></script><style id=glightbox-style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#k-means-clustering-and-unsupervised-learning class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-header__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <img src=../../img/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Machine Learning - Algorithms and Applications </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> K-Means Clustering and Unsupervised Learning </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-nav__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <img src=../../img/logo.png alt=logo> </a> Machine Learning - Algorithms and Applications </label> <div class=md-nav__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-nav__item> <a href=../../course-description/ class=md-nav__link> <span class=md-ellipsis> Course Description </span> </a> </li> <li class=md-nav__item> <a href=../../faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> <li class=md-nav__item> <a href=../../glossary/ class=md-nav__link> <span class=md-ellipsis> Glossary </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> Chapters </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Chapters </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_2> <div class="md-nav__link md-nav__container"> <a href=../01-intro-to-ml-fundamentals/ class="md-nav__link "> <span class=md-ellipsis> 1. ML Fundamentals </span> </a> <label class="md-nav__link " for=__nav_5_2 id=__nav_5_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> 1. ML Fundamentals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_3> <div class="md-nav__link md-nav__container"> <a href=../02-k-nearest-neighbors/ class="md-nav__link "> <span class=md-ellipsis> 2. K-Nearest Neighbors </span> </a> <label class="md-nav__link " for=__nav_5_3 id=__nav_5_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_3_label aria-expanded=false> <label class=md-nav__title for=__nav_5_3> <span class="md-nav__icon md-icon"></span> 2. K-Nearest Neighbors </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../02-k-nearest-neighbors/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_4> <div class="md-nav__link md-nav__container"> <a href=../03-decision-trees/ class="md-nav__link "> <span class=md-ellipsis> 3. Decision Trees </span> </a> <label class="md-nav__link " for=__nav_5_4 id=__nav_5_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_4_label aria-expanded=false> <label class=md-nav__title for=__nav_5_4> <span class="md-nav__icon md-icon"></span> 3. Decision Trees </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../03-decision-trees/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_5> <div class="md-nav__link md-nav__container"> <a href=../04-logistic-regression/ class="md-nav__link "> <span class=md-ellipsis> 4. Logistic Regression </span> </a> <label class="md-nav__link " for=__nav_5_5 id=__nav_5_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5_5> <span class="md-nav__icon md-icon"></span> 4. Logistic Regression </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../04-logistic-regression/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_6> <div class="md-nav__link md-nav__container"> <a href=../05-regularization/ class="md-nav__link "> <span class=md-ellipsis> 5. Regularization </span> </a> <label class="md-nav__link " for=__nav_5_6 id=__nav_5_6_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_6_label aria-expanded=false> <label class=md-nav__title for=__nav_5_6> <span class="md-nav__icon md-icon"></span> 5. Regularization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../05-regularization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_7> <div class="md-nav__link md-nav__container"> <a href=../06-support-vector-machines/ class="md-nav__link "> <span class=md-ellipsis> 6. Support Vector Machines </span> </a> <label class="md-nav__link " for=__nav_5_7 id=__nav_5_7_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_7_label aria-expanded=false> <label class=md-nav__title for=__nav_5_7> <span class="md-nav__icon md-icon"></span> 6. Support Vector Machines </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../06-support-vector-machines/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_8 checked> <div class="md-nav__link md-nav__container"> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 7. K-Means Clustering </span> </a> <label class="md-nav__link md-nav__link--active" for=__nav_5_8 id=__nav_5_8_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_8_label aria-expanded=true> <label class=md-nav__title for=__nav_5_8> <span class="md-nav__icon md-icon"></span> 7. K-Means Clustering </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_9> <div class="md-nav__link md-nav__container"> <a href=../08-data-preprocessing/ class="md-nav__link "> <span class=md-ellipsis> 8. Data Preprocessing </span> </a> <label class="md-nav__link " for=__nav_5_9 id=__nav_5_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_9_label aria-expanded=false> <label class=md-nav__title for=__nav_5_9> <span class="md-nav__icon md-icon"></span> 8. Data Preprocessing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../08-data-preprocessing/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_10> <div class="md-nav__link md-nav__container"> <a href=../09-neural-networks/ class="md-nav__link "> <span class=md-ellipsis> 9. Neural Networks </span> </a> <label class="md-nav__link " for=__nav_5_10 id=__nav_5_10_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_10_label aria-expanded=false> <label class=md-nav__title for=__nav_5_10> <span class="md-nav__icon md-icon"></span> 9. Neural Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../09-neural-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_11> <div class="md-nav__link md-nav__container"> <a href=../10-convolutional-networks/ class="md-nav__link "> <span class=md-ellipsis> 10. Convolutional Networks </span> </a> <label class="md-nav__link " for=__nav_5_11 id=__nav_5_11_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_11_label aria-expanded=false> <label class=md-nav__title for=__nav_5_11> <span class="md-nav__icon md-icon"></span> 10. Convolutional Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../10-convolutional-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_12> <div class="md-nav__link md-nav__container"> <a href=../11-transfer-learning/ class="md-nav__link "> <span class=md-ellipsis> 11. Transfer Learning </span> </a> <label class="md-nav__link " for=__nav_5_12 id=__nav_5_12_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_12_label aria-expanded=false> <label class=md-nav__title for=__nav_5_12> <span class="md-nav__icon md-icon"></span> 11. Transfer Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../11-transfer-learning/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_13> <div class="md-nav__link md-nav__container"> <a href=../12-evaluation-optimization/ class="md-nav__link "> <span class=md-ellipsis> 12. Evaluation &amp; Optimization </span> </a> <label class="md-nav__link " for=__nav_5_13 id=__nav_5_13_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_13_label aria-expanded=false> <label class=md-nav__title for=__nav_5_13> <span class="md-nav__icon md-icon"></span> 12. Evaluation &amp; Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../12-evaluation-optimization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <div class="md-nav__link md-nav__container"> <a href=../../sims/ class="md-nav__link "> <span class=md-ellipsis> MicroSims </span> </a> <label class="md-nav__link " for=__nav_6 id=__nav_6_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> MicroSims </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../sims/activation-functions/ class=md-nav__link> <span class=md-ellipsis> Activation Functions </span> </a> </li> <li class=md-nav__item> <a href=../../sims/categorical-encoding-explorer/ class=md-nav__link> <span class=md-ellipsis> Categorical Encoding Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/cnn-architecture/ class=md-nav__link> <span class=md-ellipsis> CNN Architecture </span> </a> </li> <li class=md-nav__item> <a href=../../sims/confusion-matrix-explorer/ class=md-nav__link> <span class=md-ellipsis> Confusion Matrix Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/convolution-operation/ class=md-nav__link> <span class=md-ellipsis> Convolution Operation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/distance-metrics/ class=md-nav__link> <span class=md-ellipsis> Distance Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../sims/entropy-gini-comparison/ class=md-nav__link> <span class=md-ellipsis> Entropy-Gini Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/feature-scaling-visualizer/ class=md-nav__link> <span class=md-ellipsis> Feature Scaling Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/k-selection-simulator/ class=md-nav__link> <span class=md-ellipsis> K-Selection Simulator </span> </a> </li> <li class=md-nav__item> <a href=../../sims/kfold-cross-validation/ class=md-nav__link> <span class=md-ellipsis> K-Fold Cross Validation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/lasso-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Lasso Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/network-architecture-visualizer/ class=md-nav__link> <span class=md-ellipsis> Network Architecture Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/ridge-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Ridge Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/roc-curve-comparison/ class=md-nav__link> <span class=md-ellipsis> ROC Curve Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/sigmoid-explorer/ class=md-nav__link> <span class=md-ellipsis> Sigmoid Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/svm-margin-maximization/ class=md-nav__link> <span class=md-ellipsis> SVM Margin Maximization </span> </a> </li> <li class=md-nav__item> <a href=../../sims/training-validation-curves/ class=md-nav__link> <span class=md-ellipsis> Training Validation Curves </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <div class="md-nav__link md-nav__container"> <a href=../../learning-graph/ class="md-nav__link "> <span class=md-ellipsis> Learning Graph </span> </a> <label class="md-nav__link " for=__nav_7 id=__nav_7_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Learning Graph </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../sims/graph-viewer/ class=md-nav__link> <span class=md-ellipsis> Graph Viewer </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/course-description-assessment/ class=md-nav__link> <span class=md-ellipsis> Course Description Assessment </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-list/ class=md-nav__link> <span class=md-ellipsis> Concept List </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-taxonomy/ class=md-nav__link> <span class=md-ellipsis> Concept Taxonomy </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.csv class=md-nav__link> <span class=md-ellipsis> Learning Graph (CSV) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.json class=md-nav__link> <span class=md-ellipsis> Learning Graph (JSON) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/quality-metrics/ class=md-nav__link> <span class=md-ellipsis> Quality Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/taxonomy-distribution/ class=md-nav__link> <span class=md-ellipsis> Taxonomy Distribution </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/glossary-quality-report/ class=md-nav__link> <span class=md-ellipsis> Glossary Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-quality-report/ class=md-nav__link> <span class=md-ellipsis> FAQ Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-coverage-gaps/ class=md-nav__link> <span class=md-ellipsis> FAQ Coverage Gaps </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/book-metrics/ class=md-nav__link> <span class=md-ellipsis> Book Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/chapter-metrics/ class=md-nav__link> <span class=md-ellipsis> Chapter Metrics </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../about/ class=md-nav__link> <span class=md-ellipsis> About </span> </a> </li> <li class=md-nav__item> <a href=../../license/ class=md-nav__link> <span class=md-ellipsis> License </span> </a> </li> <li class=md-nav__item> <a href=../../contact/ class=md-nav__link> <span class=md-ellipsis> Contact </span> </a> </li> <li class=md-nav__item> <a href=../../feature-checklist/ class=md-nav__link> <span class=md-ellipsis> Feature Checklist </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#introduction-to-unsupervised-learning class=md-nav__link> <span class=md-ellipsis> Introduction to Unsupervised Learning </span> </a> </li> <li class=md-nav__item> <a href=#k-means-clustering-the-algorithm class=md-nav__link> <span class=md-ellipsis> K-Means Clustering: The Algorithm </span> </a> <nav class=md-nav aria-label="K-Means Clustering: The Algorithm"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-core-idea class=md-nav__link> <span class=md-ellipsis> The Core Idea </span> </a> </li> <li class=md-nav__item> <a href=#mathematical-formulation class=md-nav__link> <span class=md-ellipsis> Mathematical Formulation </span> </a> </li> <li class=md-nav__item> <a href=#the-k-means-algorithm class=md-nav__link> <span class=md-ellipsis> The K-Means Algorithm </span> </a> </li> <li class=md-nav__item> <a href=#convergence-criteria class=md-nav__link> <span class=md-ellipsis> Convergence Criteria </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#k-means-on-the-iris-dataset class=md-nav__link> <span class=md-ellipsis> K-Means on the Iris Dataset </span> </a> <nav class=md-nav aria-label="K-Means on the Iris Dataset"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#visualizing-the-data class=md-nav__link> <span class=md-ellipsis> Visualizing the Data </span> </a> </li> <li class=md-nav__item> <a href=#clustering-with-k2 class=md-nav__link> <span class=md-ellipsis> Clustering with k=2 </span> </a> </li> <li class=md-nav__item> <a href=#visualizing-clusters class=md-nav__link> <span class=md-ellipsis> Visualizing Clusters </span> </a> </li> <li class=md-nav__item> <a href=#clustering-with-k3 class=md-nav__link> <span class=md-ellipsis> Clustering with k=3 </span> </a> </li> <li class=md-nav__item> <a href=#comparing-clusters-to-true-labels class=md-nav__link> <span class=md-ellipsis> Comparing Clusters to True Labels </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#initialization-strategies class=md-nav__link> <span class=md-ellipsis> Initialization Strategies </span> </a> <nav class=md-nav aria-label="Initialization Strategies"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#random-initialization class=md-nav__link> <span class=md-ellipsis> Random Initialization </span> </a> </li> <li class=md-nav__item> <a href=#k-means-initialization class=md-nav__link> <span class=md-ellipsis> K-Means++ Initialization </span> </a> </li> <li class=md-nav__item> <a href=#comparing-initialization-methods class=md-nav__link> <span class=md-ellipsis> Comparing Initialization Methods </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#choosing-the-number-of-clusters class=md-nav__link> <span class=md-ellipsis> Choosing the Number of Clusters </span> </a> <nav class=md-nav aria-label="Choosing the Number of Clusters"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-elbow-method class=md-nav__link> <span class=md-ellipsis> The Elbow Method </span> </a> </li> <li class=md-nav__item> <a href=#silhouette-score class=md-nav__link> <span class=md-ellipsis> Silhouette Score </span> </a> </li> <li class=md-nav__item> <a href=#silhouette-plots class=md-nav__link> <span class=md-ellipsis> Silhouette Plots </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#within-cluster-variance-and-inertia class=md-nav__link> <span class=md-ellipsis> Within-Cluster Variance and Inertia </span> </a> <nav class=md-nav aria-label="Within-Cluster Variance and Inertia"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#accessing-inertia-in-scikit-learn class=md-nav__link> <span class=md-ellipsis> Accessing Inertia in Scikit-Learn </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#interactive-visualization-k-means-algorithm-steps class=md-nav__link> <span class=md-ellipsis> Interactive Visualization: K-Means Algorithm Steps </span> </a> </li> <li class=md-nav__item> <a href=#interactive-visualization-elbow-method-and-silhouette-analysis class=md-nav__link> <span class=md-ellipsis> Interactive Visualization: Elbow Method and Silhouette Analysis </span> </a> </li> <li class=md-nav__item> <a href=#limitations-and-considerations class=md-nav__link> <span class=md-ellipsis> Limitations and Considerations </span> </a> <nav class=md-nav aria-label="Limitations and Considerations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-requires-specifying-k class=md-nav__link> <span class=md-ellipsis> 1. Requires Specifying k </span> </a> </li> <li class=md-nav__item> <a href=#2-assumes-spherical-clusters class=md-nav__link> <span class=md-ellipsis> 2. Assumes Spherical Clusters </span> </a> </li> <li class=md-nav__item> <a href=#3-sensitive-to-outliers class=md-nav__link> <span class=md-ellipsis> 3. Sensitive to Outliers </span> </a> </li> <li class=md-nav__item> <a href=#4-local-optima class=md-nav__link> <span class=md-ellipsis> 4. Local Optima </span> </a> </li> <li class=md-nav__item> <a href=#5-scale-sensitivity class=md-nav__link> <span class=md-ellipsis> 5. Scale Sensitivity </span> </a> </li> <li class=md-nav__item> <a href=#6-only-works-with-numerical-data class=md-nav__link> <span class=md-ellipsis> 6. Only Works with Numerical Data </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#practical-applications class=md-nav__link> <span class=md-ellipsis> Practical Applications </span> </a> <nav class=md-nav aria-label="Practical Applications"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#customer-segmentation class=md-nav__link> <span class=md-ellipsis> Customer Segmentation </span> </a> </li> <li class=md-nav__item> <a href=#image-compression class=md-nav__link> <span class=md-ellipsis> Image Compression </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#summary_1 class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#key-takeaways class=md-nav__link> <span class=md-ellipsis> Key Takeaways </span> </a> </li> <li class=md-nav__item> <a href=#further-reading class=md-nav__link> <span class=md-ellipsis> Further Reading </span> </a> </li> <li class=md-nav__item> <a href=#exercises class=md-nav__link> <span class=md-ellipsis> Exercises </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <nav class=md-path aria-label=Navigation> <ol class=md-path__list> <li class=md-path__item> <a href=../.. class=md-path__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-path__item> <a href=../ class=md-path__link> <span class=md-ellipsis> Chapters </span> </a> </li> <li class=md-path__item> <a href=./ class=md-path__link> <span class=md-ellipsis> 7. K-Means Clustering </span> </a> </li> </ol> </nav> <article class="md-content__inner md-typeset"> <h1 id=k-means-clustering-and-unsupervised-learning>K-Means Clustering and Unsupervised Learning<a class=headerlink href=#k-means-clustering-and-unsupervised-learning title="Permanent link">¶</a></h1> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">¶</a></h2> <p>This chapter explores k-means clustering, the most popular unsupervised learning algorithm for discovering natural groupings in unlabeled data. Students will learn the iterative algorithm that alternates between assigning points to clusters and updating cluster centroids, understand the importance of initialization strategies (random initialization vs. k-means++), and explore methods for selecting the optimal number of clusters using the elbow method and silhouette scores. The chapter covers convergence criteria, within-cluster variance, and inertia as measures of clustering quality, providing students with practical skills for exploratory data analysis and pattern discovery.</p> <h2 id=concepts-covered>Concepts Covered<a class=headerlink href=#concepts-covered title="Permanent link">¶</a></h2> <p>This chapter covers the following 12 concepts from the learning graph:</p> <ol> <li>K-Means Clustering</li> <li>Centroid</li> <li>Cluster Assignment</li> <li>Cluster Update</li> <li>K-Means Initialization</li> <li>Random Initialization</li> <li>K-Means++ Initialization</li> <li>Elbow Method</li> <li>Silhouette Score</li> <li>Within-Cluster Variance</li> <li>Convergence Criteria</li> <li>Inertia</li> </ol> <h2 id=prerequisites>Prerequisites<a class=headerlink href=#prerequisites title="Permanent link">¶</a></h2> <p>This chapter builds on concepts from:</p> <ul> <li><a href=../01-intro-to-ml-fundamentals/ >Chapter 1: Introduction to Machine Learning Fundamentals</a></li> </ul> <hr> <h2 id=introduction-to-unsupervised-learning>Introduction to Unsupervised Learning<a class=headerlink href=#introduction-to-unsupervised-learning title="Permanent link">¶</a></h2> <p>In supervised learning, we train models to predict known labels or values—classification for discrete categories, regression for continuous outputs. Every training example includes both features and a target label that guides the learning process. But what happens when we have data without labels? What can we learn from unlabeled data alone?</p> <p><strong>Unsupervised learning</strong> addresses this question by discovering hidden patterns and structure in data without explicit target values. Instead of learning to predict labels, unsupervised algorithms identify natural groupings, detect anomalies, reduce dimensionality, or find associations within the data itself.</p> <p><strong>Clustering</strong> is a fundamental unsupervised learning task: partitioning data into groups (clusters) such that examples within each group are more similar to each other than to examples in other groups. Clustering has numerous applications:</p> <ul> <li><strong>Customer segmentation</strong>: Grouping customers by purchasing behavior for targeted marketing</li> <li><strong>Document organization</strong>: Clustering news articles by topic for automatic categorization</li> <li><strong>Image compression</strong>: Reducing colors by clustering similar pixels</li> <li><strong>Anomaly detection</strong>: Identifying unusual patterns that don't fit any cluster</li> <li><strong>Data exploration</strong>: Understanding structure in complex datasets before modeling</li> <li><strong>Gene expression analysis</strong>: Finding groups of genes with similar behavior</li> </ul> <p>Unlike classification, where class boundaries are learned from labeled examples, clustering must discover these boundaries from the data distribution alone.</p> <h2 id=k-means-clustering-the-algorithm>K-Means Clustering: The Algorithm<a class=headerlink href=#k-means-clustering-the-algorithm title="Permanent link">¶</a></h2> <p><strong>K-means clustering</strong> is the most widely used clustering algorithm due to its simplicity, efficiency, and effectiveness. Given a dataset and a desired number of clusters <span class=arithmatex>\(k\)</span>, k-means partitions the data into <span class=arithmatex>\(k\)</span> groups by iteratively refining cluster assignments.</p> <h3 id=the-core-idea>The Core Idea<a class=headerlink href=#the-core-idea title="Permanent link">¶</a></h3> <p>K-means represents each cluster by its <strong>centroid</strong>—the geometric center (mean) of all points assigned to that cluster. The algorithm alternates between two steps:</p> <ol> <li><strong>Cluster Assignment</strong>: Assign each data point to the cluster with the nearest centroid</li> <li><strong>Cluster Update</strong>: Recompute each centroid as the mean of all points assigned to that cluster</li> </ol> <p>These steps repeat until cluster assignments stabilize (convergence).</p> <h3 id=mathematical-formulation>Mathematical Formulation<a class=headerlink href=#mathematical-formulation title="Permanent link">¶</a></h3> <p>Given a dataset <span class=arithmatex>\(\{\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n\}\)</span> where each <span class=arithmatex>\(\mathbf{x}_i \in \mathbb{R}^d\)</span>, k-means seeks to minimize the <strong>within-cluster variance</strong> (also called <strong>inertia</strong>):</p> <div class=arithmatex>\[J = \sum_{i=1}^{n} \|\mathbf{x}_i - \boldsymbol{\mu}_{c_i}\|^2\]</div> <p>where:</p> <ul> <li><span class=arithmatex>\(c_i\)</span> is the cluster assignment for point <span class=arithmatex>\(i\)</span></li> <li><span class=arithmatex>\(\boldsymbol{\mu}_{c_i}\)</span> is the centroid of the cluster containing point <span class=arithmatex>\(i\)</span></li> <li><span class=arithmatex>\(\|\mathbf{x}_i - \boldsymbol{\mu}_{c_i}\|^2\)</span> is the squared Euclidean distance from point <span class=arithmatex>\(i\)</span> to its assigned centroid</li> </ul> <p>This objective function measures how tightly grouped the clusters are. Smaller values indicate more compact, well-separated clusters.</p> <h3 id=the-k-means-algorithm>The K-Means Algorithm<a class=headerlink href=#the-k-means-algorithm title="Permanent link">¶</a></h3> <p><strong>Input:</strong> - Dataset <span class=arithmatex>\(\mathcal{D} = \{\mathbf{x}_1, \ldots, \mathbf{x}_n\}\)</span> - Number of clusters <span class=arithmatex>\(k\)</span></p> <p><strong>Output:</strong> - Cluster assignments <span class=arithmatex>\(c_1, \ldots, c_n\)</span> - Cluster centroids <span class=arithmatex>\(\boldsymbol{\mu}_1, \ldots, \boldsymbol{\mu}_k\)</span></p> <p><strong>Algorithm:</strong></p> <ol> <li> <p><strong>Initialize</strong> <span class=arithmatex>\(k\)</span> centroids <span class=arithmatex>\(\boldsymbol{\mu}_1, \ldots, \boldsymbol{\mu}_k\)</span> (see initialization strategies below)</p> </li> <li> <p><strong>Repeat</strong> until convergence:</p> </li> </ol> <p>a. <strong>Cluster Assignment Step:</strong></p> <p>For each data point <span class=arithmatex>\(\mathbf{x}_i\)</span>: $<span class=arithmatex>\(c_i \leftarrow \arg\min_{j \in \{1,\ldots,k\}} \|\mathbf{x}_i - \boldsymbol{\mu}_j\|^2\)</span>$</p> <p>(Assign <span class=arithmatex>\(\mathbf{x}_i\)</span> to the nearest centroid)</p> <p>b. <strong>Cluster Update Step:</strong></p> <p>For each cluster <span class=arithmatex>\(j\)</span>: $<span class=arithmatex>\(\boldsymbol{\mu}_j \leftarrow \frac{1}{|C_j|} \sum_{\mathbf{x}_i \in C_j} \mathbf{x}_i\)</span>$</p> <p>where <span class=arithmatex>\(C_j = \{\mathbf{x}_i : c_i = j\}\)</span> is the set of points assigned to cluster <span class=arithmatex>\(j\)</span></p> <p>(Recompute centroids as the mean of assigned points)</p> <ol> <li><strong>Check convergence:</strong> Stop if assignments don't change or maximum iterations reached</li> </ol> <h3 id=convergence-criteria>Convergence Criteria<a class=headerlink href=#convergence-criteria title="Permanent link">¶</a></h3> <p>K-means converges when one of the following <strong>convergence criteria</strong> is met:</p> <ol> <li><strong>No reassignments</strong>: Cluster assignments don't change between iterations</li> <li><strong>Centroid stability</strong>: Centroids move less than a threshold distance</li> <li><strong>Objective improvement</strong>: Change in inertia is below a threshold</li> <li><strong>Maximum iterations</strong>: A predefined iteration limit is reached</li> </ol> <p>The algorithm is guaranteed to converge to a local minimum of the objective function (though not necessarily the global minimum). In practice, k-means typically converges within 10-50 iterations for most datasets.</p> <h2 id=k-means-on-the-iris-dataset>K-Means on the Iris Dataset<a class=headerlink href=#k-means-on-the-iris-dataset title="Permanent link">¶</a></h2> <p>Let's apply k-means to the classic Iris dataset to discover natural groupings in flower measurements:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=kn>import</span><span class=w> </span><span class=nn>seaborn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>sns</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.cluster</span><span class=w> </span><span class=kn>import</span> <span class=n>KMeans</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=c1># Load iris dataset</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a><span class=n>iris_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>'https://raw.githubusercontent.com/sziccardi/MLCamp2025_DataRepository/main/iris.csv'</span><span class=p>)</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=c1># Extract features (no labels for unsupervised learning!)</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a><span class=n>features</span> <span class=o>=</span> <span class=p>[</span><span class=s2>"sepal_length"</span><span class=p>,</span> <span class=s2>"sepal_width"</span><span class=p>,</span> <span class=s2>"petal_length"</span><span class=p>,</span> <span class=s2>"petal_width"</span><span class=p>]</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a><span class=n>X</span> <span class=o>=</span> <span class=n>iris_df</span><span class=p>[</span><span class=n>features</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Dataset shape:"</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a><span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Feature statistics:"</span><span class=p>)</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a><span class=nb>print</span><span class=p>(</span><span class=n>iris_df</span><span class=p>[</span><span class=n>features</span><span class=p>]</span><span class=o>.</span><span class=n>describe</span><span class=p>())</span>
</span></code></pre></div> <p>Unlike supervised learning, we use only the feature columns—no species labels. The goal is to discover groupings based solely on the flower measurements.</p> <h3 id=visualizing-the-data>Visualizing the Data<a class=headerlink href=#visualizing-the-data title="Permanent link">¶</a></h3> <p>Before clustering, let's explore the data distribution:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># Create pairplot to visualize feature relationships</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=n>cluster_df</span> <span class=o>=</span> <span class=n>iris_df</span><span class=p>[</span><span class=n>features</span><span class=p>]</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>()</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=n>sns</span><span class=o>.</span><span class=n>pairplot</span><span class=p>(</span><span class=n>cluster_df</span><span class=p>,</span> <span class=nb>vars</span><span class=o>=</span><span class=n>features</span><span class=p>)</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=n>plt</span><span class=o>.</span><span class=n>suptitle</span><span class=p>(</span><span class=s2>"Iris Dataset: Feature Relationships (Unlabeled)"</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=mf>1.01</span><span class=p>)</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>The pairplot reveals structure in the data—some features show clear separation between groups, while others overlap. This visual exploration helps us hypothesize how many natural clusters might exist.</p> <h3 id=clustering-with-k2>Clustering with k=2<a class=headerlink href=#clustering-with-k2 title="Permanent link">¶</a></h3> <p>Let's start with 2 clusters:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># Fit k-means with k=2</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>kmeans_2</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=n>kmeans_2</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=c1># Examine cluster centers (centroids)</span>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Cluster centroids:"</span><span class=p>)</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a><span class=nb>print</span><span class=p>(</span><span class=n>kmeans_2</span><span class=o>.</span><span class=n>cluster_centers_</span><span class=p>)</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a><span class=c1># Examine cluster assignments</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Cluster labels for first 10 points:"</span><span class=p>)</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a><span class=nb>print</span><span class=p>(</span><span class=n>kmeans_2</span><span class=o>.</span><span class=n>labels_</span><span class=p>[:</span><span class=mi>10</span><span class=p>])</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a>
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a><span class=c1># Count points in each cluster</span>
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a><span class=n>unique</span><span class=p>,</span> <span class=n>counts</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>kmeans_2</span><span class=o>.</span><span class=n>labels_</span><span class=p>,</span> <span class=n>return_counts</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a><span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Cluster sizes:"</span><span class=p>)</span>
</span><span id=__span-2-16><a id=__codelineno-2-16 name=__codelineno-2-16 href=#__codelineno-2-16></a><span class=k>for</span> <span class=n>cluster</span><span class=p>,</span> <span class=n>count</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>unique</span><span class=p>,</span> <span class=n>counts</span><span class=p>):</span>
</span><span id=__span-2-17><a id=__codelineno-2-17 name=__codelineno-2-17 href=#__codelineno-2-17></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  Cluster </span><span class=si>{</span><span class=n>cluster</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>count</span><span class=si>}</span><span class=s2> points"</span><span class=p>)</span>
</span></code></pre></div> <p>The centroids are 4-dimensional vectors (one value per feature) representing the center of each cluster. The labels array assigns each of the 150 data points to cluster 0 or 1.</p> <h3 id=visualizing-clusters>Visualizing Clusters<a class=headerlink href=#visualizing-clusters title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># Add cluster labels to dataframe</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=n>cluster_df_2</span> <span class=o>=</span> <span class=n>iris_df</span><span class=p>[</span><span class=n>features</span><span class=p>]</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=n>cluster_df_2</span><span class=p>[</span><span class=s1>'Cluster'</span><span class=p>]</span> <span class=o>=</span> <span class=n>kmeans_2</span><span class=o>.</span><span class=n>labels_</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=c1># Create pairplot colored by cluster</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>()</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=n>sns</span><span class=o>.</span><span class=n>pairplot</span><span class=p>(</span><span class=n>cluster_df_2</span><span class=p>,</span> <span class=nb>vars</span><span class=o>=</span><span class=n>features</span><span class=p>,</span> <span class=n>hue</span><span class=o>=</span><span class=s2>"Cluster"</span><span class=p>,</span> <span class=n>palette</span><span class=o>=</span><span class=s2>"Set1"</span><span class=p>)</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a><span class=n>plt</span><span class=o>.</span><span class=n>suptitle</span><span class=p>(</span><span class=s2>"K-Means Clustering with k=2"</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=mf>1.01</span><span class=p>)</span>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>The colored pairplot shows how k-means has partitioned the data. We can see clear separation in some feature combinations (e.g., petal length vs. petal width) and more overlap in others (sepal measurements).</p> <h3 id=clustering-with-k3>Clustering with k=3<a class=headerlink href=#clustering-with-k3 title="Permanent link">¶</a></h3> <p>Since the iris dataset actually contains three species, let's try k=3:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># Fit k-means with k=3</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=n>kmeans_3</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=n>kmeans_3</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Cluster centroids (k=3):"</span><span class=p>)</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a><span class=nb>print</span><span class=p>(</span><span class=n>kmeans_3</span><span class=o>.</span><span class=n>cluster_centers_</span><span class=p>)</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a><span class=c1># Visualize clusters</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a><span class=n>cluster_df_3</span> <span class=o>=</span> <span class=n>iris_df</span><span class=p>[</span><span class=n>features</span><span class=p>]</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a><span class=n>cluster_df_3</span><span class=p>[</span><span class=s1>'Cluster'</span><span class=p>]</span> <span class=o>=</span> <span class=n>kmeans_3</span><span class=o>.</span><span class=n>labels_</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>()</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a><span class=n>sns</span><span class=o>.</span><span class=n>pairplot</span><span class=p>(</span><span class=n>cluster_df_3</span><span class=p>,</span> <span class=nb>vars</span><span class=o>=</span><span class=n>features</span><span class=p>,</span> <span class=n>hue</span><span class=o>=</span><span class=s2>"Cluster"</span><span class=p>,</span> <span class=n>palette</span><span class=o>=</span><span class=s2>"Set2"</span><span class=p>)</span>
</span><span id=__span-4-14><a id=__codelineno-4-14 name=__codelineno-4-14 href=#__codelineno-4-14></a><span class=n>plt</span><span class=o>.</span><span class=n>suptitle</span><span class=p>(</span><span class=s2>"K-Means Clustering with k=3"</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=mf>1.01</span><span class=p>)</span>
</span><span id=__span-4-15><a id=__codelineno-4-15 name=__codelineno-4-15 href=#__codelineno-4-15></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>With three clusters, the separation looks more refined. But how well does unsupervised k-means recover the true species structure?</p> <h3 id=comparing-clusters-to-true-labels>Comparing Clusters to True Labels<a class=headerlink href=#comparing-clusters-to-true-labels title="Permanent link">¶</a></h3> <p>Although we didn't use species labels during clustering, we can compare the discovered clusters to the ground truth:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=c1># Create crosstab comparing clusters to actual species</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=n>actual_species</span> <span class=o>=</span> <span class=n>iris_df</span><span class=p>[</span><span class=s1>'species'</span><span class=p>]</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=n>cluster_labels</span> <span class=o>=</span> <span class=n>kmeans_3</span><span class=o>.</span><span class=n>labels_</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=n>comparison</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>crosstab</span><span class=p>(</span><span class=n>actual_species</span><span class=p>,</span> <span class=n>cluster_labels</span><span class=p>,</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>                         <span class=n>rownames</span><span class=o>=</span><span class=p>[</span><span class=s1>'Species'</span><span class=p>],</span> <span class=n>colnames</span><span class=o>=</span><span class=p>[</span><span class=s1>'Cluster'</span><span class=p>])</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Cluster vs Species comparison:"</span><span class=p>)</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class=nb>print</span><span class=p>(</span><span class=n>comparison</span><span class=p>)</span>
</span></code></pre></div> <p>The crosstab reveals how well k-means discovered the natural species groupings. Typically, one cluster perfectly captures setosa (which is well-separated), while versicolor and virginica show some mixing (they overlap more in feature space).</p> <div class="admonition note"> <p class=admonition-title>Cluster Labels are Arbitrary</p> <p>K-means assigns cluster numbers arbitrarily (0, 1, 2, etc.). There's no inherent ordering or meaning to these numbers. The algorithm might assign setosa to cluster 1 in one run and cluster 0 in another.</p> </div> <h2 id=initialization-strategies>Initialization Strategies<a class=headerlink href=#initialization-strategies title="Permanent link">¶</a></h2> <p>K-means' final solution depends heavily on the initial centroid positions. Poor initialization can lead to suboptimal clusters or slow convergence. Two main strategies address this:</p> <h3 id=random-initialization>Random Initialization<a class=headerlink href=#random-initialization title="Permanent link">¶</a></h3> <p><strong>Random initialization</strong> selects <span class=arithmatex>\(k\)</span> data points uniformly at random from the dataset as initial centroids:</p> <ol> <li>Choose <span class=arithmatex>\(k\)</span> points <span class=arithmatex>\(\{\mathbf{x}_{i_1}, \ldots, \mathbf{x}_{i_k}\}\)</span> randomly from the data</li> <li>Set <span class=arithmatex>\(\boldsymbol{\mu}_j = \mathbf{x}_{i_j}\)</span> for <span class=arithmatex>\(j = 1, \ldots, k\)</span></li> </ol> <p><strong>Advantages:</strong> - Simple to implement - Fast (no computation required)</p> <p><strong>Disadvantages:</strong> - Sensitive to outliers (might choose outlier as initial centroid) - May lead to poor local minima - Results vary across runs - Can converge slowly if initial centroids are all close together</p> <p>Because of random initialization's variability, it's common to run k-means multiple times with different random seeds and choose the run with lowest inertia.</p> <h3 id=k-means-initialization>K-Means++ Initialization<a class=headerlink href=#k-means-initialization title="Permanent link">¶</a></h3> <p><strong>K-means++</strong> improves upon random initialization by spreading initial centroids far apart, leading to better and more consistent results:</p> <p><strong>Algorithm:</strong></p> <ol> <li> <p>Choose the first centroid <span class=arithmatex>\(\boldsymbol{\mu}_1\)</span> uniformly at random from data points</p> </li> <li> <p>For each remaining centroid <span class=arithmatex>\(j = 2, \ldots, k\)</span>:</p> </li> </ol> <p>a. For each data point <span class=arithmatex>\(\mathbf{x}_i\)</span>, compute <span class=arithmatex>\(D(\mathbf{x}_i)\)</span> = distance to nearest already-chosen centroid</p> <p>b. Choose next centroid <span class=arithmatex>\(\boldsymbol{\mu}_j\)</span> from data points with probability proportional to <span class=arithmatex>\(D(\mathbf{x}_i)^2\)</span></p> <p>(Points far from existing centroids are more likely to be chosen)</p> <ol> <li>Proceed with standard k-means using these initial centroids</li> </ol> <p><strong>Advantages:</strong> - Provably better initialization (theoretically and empirically) - More consistent results across runs - Often converges faster - Reduces need for multiple random restarts</p> <p><strong>Disadvantages:</strong> - Slightly more complex to implement - Requires <span class=arithmatex>\(O(nk)\)</span> computation for initialization (vs. <span class=arithmatex>\(O(k)\)</span> for random)</p> <p>Scikit-learn uses k-means++ by default (<code>init='k-means++'</code>).</p> <h3 id=comparing-initialization-methods>Comparing Initialization Methods<a class=headerlink href=#comparing-initialization-methods title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1># Compare random vs k-means++ initialization</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=k>for</span> <span class=n>init_method</span> <span class=ow>in</span> <span class=p>[</span><span class=s1>'random'</span><span class=p>,</span> <span class=s1>'k-means++'</span><span class=p>]:</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>    <span class=k>for</span> <span class=n>trial</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>        <span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>init</span><span class=o>=</span><span class=n>init_method</span><span class=p>,</span> <span class=n>n_init</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=n>trial</span><span class=p>)</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>        <span class=n>kmeans</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>        <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>            <span class=s1>'Method'</span><span class=p>:</span> <span class=n>init_method</span><span class=p>,</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>            <span class=s1>'Trial'</span><span class=p>:</span> <span class=n>trial</span><span class=p>,</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>            <span class=s1>'Inertia'</span><span class=p>:</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>inertia_</span><span class=p>,</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>            <span class=s1>'Iterations'</span><span class=p>:</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>n_iter_</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a>        <span class=p>})</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a><span class=n>results_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>results</span><span class=p>)</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a><span class=c1># Compare statistics</span>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a><span class=nb>print</span><span class=p>(</span><span class=n>results_df</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span><span class=s1>'Method'</span><span class=p>)[[</span><span class=s1>'Inertia'</span><span class=p>,</span> <span class=s1>'Iterations'</span><span class=p>]]</span><span class=o>.</span><span class=n>describe</span><span class=p>())</span>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a>
</span><span id=__span-6-20><a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a><span class=c1># Plot distributions</span>
</span><span id=__span-6-21><a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>
</span><span id=__span-6-22><a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a>
</span><span id=__span-6-23><a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a><span class=n>results_df</span><span class=o>.</span><span class=n>boxplot</span><span class=p>(</span><span class=n>column</span><span class=o>=</span><span class=s1>'Inertia'</span><span class=p>,</span> <span class=n>by</span><span class=o>=</span><span class=s1>'Method'</span><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span><span id=__span-6-24><a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>'Inertia by Initialization Method'</span><span class=p>)</span>
</span><span id=__span-6-25><a id=__codelineno-6-25 name=__codelineno-6-25 href=#__codelineno-6-25></a><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>'Initialization Method'</span><span class=p>)</span>
</span><span id=__span-6-26><a id=__codelineno-6-26 name=__codelineno-6-26 href=#__codelineno-6-26></a>
</span><span id=__span-6-27><a id=__codelineno-6-27 name=__codelineno-6-27 href=#__codelineno-6-27></a><span class=n>results_df</span><span class=o>.</span><span class=n>boxplot</span><span class=p>(</span><span class=n>column</span><span class=o>=</span><span class=s1>'Iterations'</span><span class=p>,</span> <span class=n>by</span><span class=o>=</span><span class=s1>'Method'</span><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span><span id=__span-6-28><a id=__codelineno-6-28 name=__codelineno-6-28 href=#__codelineno-6-28></a><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>'Iterations to Convergence'</span><span class=p>)</span>
</span><span id=__span-6-29><a id=__codelineno-6-29 name=__codelineno-6-29 href=#__codelineno-6-29></a><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>'Initialization Method'</span><span class=p>)</span>
</span><span id=__span-6-30><a id=__codelineno-6-30 name=__codelineno-6-30 href=#__codelineno-6-30></a>
</span><span id=__span-6-31><a id=__codelineno-6-31 name=__codelineno-6-31 href=#__codelineno-6-31></a><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span><span id=__span-6-32><a id=__codelineno-6-32 name=__codelineno-6-32 href=#__codelineno-6-32></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>K-means++ typically produces lower inertia values and more consistent results across trials.</p> <h2 id=choosing-the-number-of-clusters>Choosing the Number of Clusters<a class=headerlink href=#choosing-the-number-of-clusters title="Permanent link">¶</a></h2> <p>A fundamental challenge in k-means is selecting the appropriate value of <span class=arithmatex>\(k\)</span>. Too few clusters oversimplify the data structure; too many create artificial divisions. Two popular methods help choose <span class=arithmatex>\(k\)</span>:</p> <h3 id=the-elbow-method>The Elbow Method<a class=headerlink href=#the-elbow-method title="Permanent link">¶</a></h3> <p>The <strong>elbow method</strong> plots inertia (within-cluster sum of squares) as a function of <span class=arithmatex>\(k\)</span> and looks for an "elbow"—a point where adding more clusters yields diminishing returns.</p> <p><strong>Procedure:</strong></p> <ol> <li>Run k-means for a range of <span class=arithmatex>\(k\)</span> values (e.g., <span class=arithmatex>\(k = 1, 2, \ldots, 10\)</span>)</li> <li>Compute inertia for each <span class=arithmatex>\(k\)</span></li> <li>Plot inertia vs. <span class=arithmatex>\(k\)</span></li> <li>Identify the "elbow" where the curve bends sharply</li> </ol> <p><strong>Interpretation:</strong></p> <ul> <li>Inertia always decreases as <span class=arithmatex>\(k\)</span> increases (more clusters = tighter fit)</li> <li>The elbow represents the <span class=arithmatex>\(k\)</span> value beyond which additional clusters provide marginal improvement</li> <li>Choose <span class=arithmatex>\(k\)</span> at the elbow for good trade-off between simplicity and fit quality</li> </ul> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=c1># Compute inertia for different k values</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=n>k_values</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>)</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=n>inertias</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>k_values</span><span class=p>:</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>    <span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>k</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>    <span class=n>kmeans</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>    <span class=n>inertias</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>kmeans</span><span class=o>.</span><span class=n>inertia_</span><span class=p>)</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=c1># Plot elbow curve</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>k_values</span><span class=p>,</span> <span class=n>inertias</span><span class=p>,</span> <span class=s1>'bo-'</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>'Number of Clusters (k)'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>'Inertia (Within-Cluster Sum of Squares)'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>'Elbow Method for Optimal k'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a><span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>k_values</span><span class=p>)</span>
</span><span id=__span-7-18><a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>For the Iris dataset, the elbow typically appears around <span class=arithmatex>\(k = 3\)</span>, suggesting three natural clusters (matching the three species).</p> <div class="admonition warning"> <p class=admonition-title>Elbow Ambiguity</p> <p>The elbow isn't always clear or unique. Some datasets show gradual curves without obvious elbows, making visual interpretation subjective. In such cases, combine the elbow method with other criteria like silhouette scores.</p> </div> <h3 id=silhouette-score>Silhouette Score<a class=headerlink href=#silhouette-score title="Permanent link">¶</a></h3> <p>The <strong>silhouette score</strong> measures how well-separated clusters are by comparing within-cluster distances to nearest-cluster distances for each point.</p> <p><strong>For a single point <span class=arithmatex>\(i\)</span>:</strong></p> <ol> <li>Compute <span class=arithmatex>\(a(i)\)</span> = average distance to other points in the same cluster (cohesion)</li> <li>Compute <span class=arithmatex>\(b(i)\)</span> = average distance to points in the nearest other cluster (separation)</li> <li>Calculate silhouette coefficient:</li> </ol> <div class=arithmatex>\[s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}\]</div> <p><strong>Interpretation:</strong></p> <ul> <li><span class=arithmatex>\(s(i) \approx 1\)</span>: Point is well-clustered (far from other clusters, close to own cluster)</li> <li><span class=arithmatex>\(s(i) \approx 0\)</span>: Point is on the border between clusters</li> <li><span class=arithmatex>\(s(i) &lt; 0\)</span>: Point might be assigned to the wrong cluster</li> </ul> <p><strong>Overall silhouette score</strong> = average <span class=arithmatex>\(s(i)\)</span> across all points</p> <p><strong>Procedure:</strong></p> <ol> <li>Run k-means for a range of <span class=arithmatex>\(k\)</span> values</li> <li>Compute average silhouette score for each <span class=arithmatex>\(k\)</span></li> <li>Choose <span class=arithmatex>\(k\)</span> with highest silhouette score</li> </ol> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>silhouette_score</span><span class=p>,</span> <span class=n>silhouette_samples</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=c1># Compute silhouette scores for different k</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=n>k_values</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>11</span><span class=p>)</span>  <span class=c1># Silhouette requires k &gt;= 2</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a><span class=n>silhouette_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>k_values</span><span class=p>:</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>    <span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>k</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>    <span class=n>labels</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>fit_predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>    <span class=n>score</span> <span class=o>=</span> <span class=n>silhouette_score</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>    <span class=n>silhouette_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>score</span><span class=p>)</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a><span class=c1># Plot silhouette scores</span>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>k_values</span><span class=p>,</span> <span class=n>silhouette_scores</span><span class=p>,</span> <span class=s1>'go-'</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>'Number of Clusters (k)'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>'Average Silhouette Score'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>'Silhouette Analysis for Optimal k'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span><span id=__span-8-19><a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
</span><span id=__span-8-20><a id=__codelineno-8-20 name=__codelineno-8-20 href=#__codelineno-8-20></a><span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>k_values</span><span class=p>)</span>
</span><span id=__span-8-21><a id=__codelineno-8-21 name=__codelineno-8-21 href=#__codelineno-8-21></a><span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>'r'</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>'--'</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span><span id=__span-8-22><a id=__codelineno-8-22 name=__codelineno-8-22 href=#__codelineno-8-22></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span><span id=__span-8-23><a id=__codelineno-8-23 name=__codelineno-8-23 href=#__codelineno-8-23></a>
</span><span id=__span-8-24><a id=__codelineno-8-24 name=__codelineno-8-24 href=#__codelineno-8-24></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Silhouette scores by k:"</span><span class=p>)</span>
</span><span id=__span-8-25><a id=__codelineno-8-25 name=__codelineno-8-25 href=#__codelineno-8-25></a><span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>score</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>k_values</span><span class=p>,</span> <span class=n>silhouette_scores</span><span class=p>):</span>
</span><span id=__span-8-26><a id=__codelineno-8-26 name=__codelineno-8-26 href=#__codelineno-8-26></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  k=</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>score</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span></code></pre></div> <p>Higher silhouette scores indicate better-defined, well-separated clusters.</p> <h3 id=silhouette-plots>Silhouette Plots<a class=headerlink href=#silhouette-plots title="Permanent link">¶</a></h3> <p>A <strong>silhouette plot</strong> visualizes the silhouette coefficient for each point, organized by cluster:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=kn>from</span><span class=w> </span><span class=nn>matplotlib</span><span class=w> </span><span class=kn>import</span> <span class=n>cm</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=c1># Create silhouette plot for k=3</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=n>k</span> <span class=o>=</span> <span class=mi>3</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>k</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a><span class=n>labels</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>fit_predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a><span class=n>silhouette_vals</span> <span class=o>=</span> <span class=n>silhouette_samples</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a><span class=n>y_lower</span> <span class=o>=</span> <span class=mi>10</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>k</span><span class=p>):</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a>    <span class=c1># Get silhouette values for cluster i</span>
</span><span id=__span-9-14><a id=__codelineno-9-14 name=__codelineno-9-14 href=#__codelineno-9-14></a>    <span class=n>cluster_silhouette_vals</span> <span class=o>=</span> <span class=n>silhouette_vals</span><span class=p>[</span><span class=n>labels</span> <span class=o>==</span> <span class=n>i</span><span class=p>]</span>
</span><span id=__span-9-15><a id=__codelineno-9-15 name=__codelineno-9-15 href=#__codelineno-9-15></a>    <span class=n>cluster_silhouette_vals</span><span class=o>.</span><span class=n>sort</span><span class=p>()</span>
</span><span id=__span-9-16><a id=__codelineno-9-16 name=__codelineno-9-16 href=#__codelineno-9-16></a>
</span><span id=__span-9-17><a id=__codelineno-9-17 name=__codelineno-9-17 href=#__codelineno-9-17></a>    <span class=n>size_cluster_i</span> <span class=o>=</span> <span class=n>cluster_silhouette_vals</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span><span id=__span-9-18><a id=__codelineno-9-18 name=__codelineno-9-18 href=#__codelineno-9-18></a>    <span class=n>y_upper</span> <span class=o>=</span> <span class=n>y_lower</span> <span class=o>+</span> <span class=n>size_cluster_i</span>
</span><span id=__span-9-19><a id=__codelineno-9-19 name=__codelineno-9-19 href=#__codelineno-9-19></a>
</span><span id=__span-9-20><a id=__codelineno-9-20 name=__codelineno-9-20 href=#__codelineno-9-20></a>    <span class=n>color</span> <span class=o>=</span> <span class=n>cm</span><span class=o>.</span><span class=n>nipy_spectral</span><span class=p>(</span><span class=nb>float</span><span class=p>(</span><span class=n>i</span><span class=p>)</span> <span class=o>/</span> <span class=n>k</span><span class=p>)</span>
</span><span id=__span-9-21><a id=__codelineno-9-21 name=__codelineno-9-21 href=#__codelineno-9-21></a>    <span class=n>ax</span><span class=o>.</span><span class=n>fill_betweenx</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>y_lower</span><span class=p>,</span> <span class=n>y_upper</span><span class=p>),</span>
</span><span id=__span-9-22><a id=__codelineno-9-22 name=__codelineno-9-22 href=#__codelineno-9-22></a>                     <span class=mi>0</span><span class=p>,</span> <span class=n>cluster_silhouette_vals</span><span class=p>,</span>
</span><span id=__span-9-23><a id=__codelineno-9-23 name=__codelineno-9-23 href=#__codelineno-9-23></a>                     <span class=n>facecolor</span><span class=o>=</span><span class=n>color</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=n>color</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
</span><span id=__span-9-24><a id=__codelineno-9-24 name=__codelineno-9-24 href=#__codelineno-9-24></a>
</span><span id=__span-9-25><a id=__codelineno-9-25 name=__codelineno-9-25 href=#__codelineno-9-25></a>    <span class=c1># Label cluster</span>
</span><span id=__span-9-26><a id=__codelineno-9-26 name=__codelineno-9-26 href=#__codelineno-9-26></a>    <span class=n>ax</span><span class=o>.</span><span class=n>text</span><span class=p>(</span><span class=o>-</span><span class=mf>0.05</span><span class=p>,</span> <span class=n>y_lower</span> <span class=o>+</span> <span class=mf>0.5</span> <span class=o>*</span> <span class=n>size_cluster_i</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=n>i</span><span class=p>))</span>
</span><span id=__span-9-27><a id=__codelineno-9-27 name=__codelineno-9-27 href=#__codelineno-9-27></a>
</span><span id=__span-9-28><a id=__codelineno-9-28 name=__codelineno-9-28 href=#__codelineno-9-28></a>    <span class=n>y_lower</span> <span class=o>=</span> <span class=n>y_upper</span> <span class=o>+</span> <span class=mi>10</span>
</span><span id=__span-9-29><a id=__codelineno-9-29 name=__codelineno-9-29 href=#__codelineno-9-29></a>
</span><span id=__span-9-30><a id=__codelineno-9-30 name=__codelineno-9-30 href=#__codelineno-9-30></a><span class=n>ax</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>'Silhouette Coefficient'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-9-31><a id=__codelineno-9-31 name=__codelineno-9-31 href=#__codelineno-9-31></a><span class=n>ax</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>'Cluster'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span><span id=__span-9-32><a id=__codelineno-9-32 name=__codelineno-9-32 href=#__codelineno-9-32></a><span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=sa>f</span><span class=s1>'Silhouette Plot for k=</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s1>'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>14</span><span class=p>)</span>
</span><span id=__span-9-33><a id=__codelineno-9-33 name=__codelineno-9-33 href=#__codelineno-9-33></a>
</span><span id=__span-9-34><a id=__codelineno-9-34 name=__codelineno-9-34 href=#__codelineno-9-34></a><span class=c1># Add average silhouette score line</span>
</span><span id=__span-9-35><a id=__codelineno-9-35 name=__codelineno-9-35 href=#__codelineno-9-35></a><span class=n>avg_score</span> <span class=o>=</span> <span class=n>silhouette_score</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span><span id=__span-9-36><a id=__codelineno-9-36 name=__codelineno-9-36 href=#__codelineno-9-36></a><span class=n>ax</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=n>avg_score</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>"red"</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s2>"--"</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>'Average: </span><span class=si>{</span><span class=n>avg_score</span><span class=si>:</span><span class=s1>.3f</span><span class=si>}</span><span class=s1>'</span><span class=p>)</span>
</span><span id=__span-9-37><a id=__codelineno-9-37 name=__codelineno-9-37 href=#__codelineno-9-37></a><span class=n>ax</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span><span id=__span-9-38><a id=__codelineno-9-38 name=__codelineno-9-38 href=#__codelineno-9-38></a>
</span><span id=__span-9-39><a id=__codelineno-9-39 name=__codelineno-9-39 href=#__codelineno-9-39></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>In a good silhouette plot: - All clusters have widths extending well past the average line - Clusters have similar widths (balanced sizes) - Few or no negative values (misassigned points)</p> <h2 id=within-cluster-variance-and-inertia>Within-Cluster Variance and Inertia<a class=headerlink href=#within-cluster-variance-and-inertia title="Permanent link">¶</a></h2> <p><strong>Within-cluster variance</strong> quantifies the compactness of clusters by measuring how spread out points are around their centroids.</p> <p>For cluster <span class=arithmatex>\(j\)</span>, the within-cluster variance is:</p> <div class=arithmatex>\[\text{Var}_j = \frac{1}{|C_j|} \sum_{\mathbf{x}_i \in C_j} \|\mathbf{x}_i - \boldsymbol{\mu}_j\|^2\]</div> <p><strong>Inertia</strong> (also called <strong>within-cluster sum of squares</strong> or WCSS) is the sum of squared distances across all clusters:</p> <div class=arithmatex>\[\text{Inertia} = \sum_{j=1}^{k} \sum_{\mathbf{x}_i \in C_j} \|\mathbf{x}_i - \boldsymbol{\mu}_j\|^2\]</div> <p>This is exactly the objective function that k-means minimizes.</p> <h3 id=accessing-inertia-in-scikit-learn>Accessing Inertia in Scikit-Learn<a class=headerlink href=#accessing-inertia-in-scikit-learn title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># Fit k-means</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a><span class=n>kmeans</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a><span class=c1># Access inertia</span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Inertia: </span><span class=si>{</span><span class=n>kmeans</span><span class=o>.</span><span class=n>inertia_</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a><span class=c1># Manually compute to verify</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a><span class=n>manual_inertia</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>X</span><span class=p>)):</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>    <span class=n>cluster_idx</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>labels_</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>    <span class=n>centroid</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>cluster_centers_</span><span class=p>[</span><span class=n>cluster_idx</span><span class=p>]</span>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>    <span class=n>distance_sq</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>((</span><span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>centroid</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span><span class=p>)</span>
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>    <span class=n>manual_inertia</span> <span class=o>+=</span> <span class=n>distance_sq</span>
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Manually computed inertia: </span><span class=si>{</span><span class=n>manual_inertia</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span></code></pre></div> <p>Lower inertia indicates tighter, more cohesive clusters. However, inertia alone shouldn't determine the number of clusters—it always decreases with increasing <span class=arithmatex>\(k\)</span>, reaching zero when <span class=arithmatex>\(k = n\)</span> (each point is its own cluster).</p> <h2 id=interactive-visualization-k-means-algorithm-steps>Interactive Visualization: K-Means Algorithm Steps<a class=headerlink href=#interactive-visualization-k-means-algorithm-steps title="Permanent link">¶</a></h2> <h4 id=k-means-iteration-visualization>K-Means Iteration Visualization<a class=headerlink href=#k-means-iteration-visualization title="Permanent link">¶</a></h4> <pre class=mermaid><code>flowchart TD
    Start(("Initialize k centroids&lt;br/&gt;(random or k-means++)"))
    Assign["ASSIGNMENT STEP&lt;br/&gt;Assign each point to&lt;br/&gt;nearest centroid"]
    Update["UPDATE STEP&lt;br/&gt;Move centroids to&lt;br/&gt;mean of assigned points"]
    Check{"Centroids&lt;br/&gt;moved?"}
    Converged(("Converged!&lt;br/&gt;Final clusters"))

    Start --&gt; Assign
    Assign --&gt; Update
    Update --&gt; Check
    Check --&gt;|Yes| Assign
    Check --&gt;|No| Converged

    classDef initNode fill:#667eea,stroke:#764ba2,stroke-width:2px,color:#fff,font-size:14px
    classDef stepNode fill:#4299e1,stroke:#2c5282,stroke-width:2px,color:#fff,font-size:14px
    classDef decisionNode fill:#ecc94b,stroke:#b7791f,stroke-width:2px,color:#333,font-size:14px
    classDef endNode fill:#48bb78,stroke:#2f855a,stroke-width:2px,color:#fff,font-size:14px

    class Start initNode
    class Assign,Update stepNode
    class Check decisionNode
    class Converged endNode

    linkStyle default stroke:#666,stroke-width:2px,font-size:12px</code></pre> <p><strong>Algorithm Steps:</strong> 1. <strong>Initialize</strong>: Place k centroids randomly (or using k-means++) 2. <strong>Assign</strong>: Each point joins the cluster of its nearest centroid 3. <strong>Update</strong>: Move each centroid to the mean position of all points in its cluster 4. <strong>Repeat</strong>: Steps 2-3 until centroids stop moving (convergence)</p> <p><strong>Key Insight</strong>: K-means minimizes within-cluster variance (inertia) through iterative refinement.</p> <h2 id=interactive-visualization-elbow-method-and-silhouette-analysis>Interactive Visualization: Elbow Method and Silhouette Analysis<a class=headerlink href=#interactive-visualization-elbow-method-and-silhouette-analysis title="Permanent link">¶</a></h2> <h4 id=cluster-evaluation-metrics>Cluster Evaluation Metrics<a class=headerlink href=#cluster-evaluation-metrics title="Permanent link">¶</a></h4> <p><strong>Determining Optimal k:</strong></p> <table> <thead> <tr> <th>Metric</th> <th>Formula</th> <th>Interpretation</th> <th>Optimal k</th> </tr> </thead> <tbody> <tr> <td><strong>Inertia (SSE)</strong></td> <td>Σ \</td> <td>x - μ\</td> <td>²</td> </tr> <tr> <td><strong>Silhouette Score</strong></td> <td>(b - a) / max(a, b)</td> <td>How similar point is to own cluster vs others</td> <td>Maximum value (range: -1 to 1)</td> </tr> <tr> <td><strong>Davies-Bouldin Index</strong></td> <td>Avg similarity of each cluster with most similar one</td> <td>Lower is better</td> <td>Minimum value</td> </tr> <tr> <td><strong>Calinski-Harabasz</strong></td> <td>Between-cluster / within-cluster variance ratio</td> <td>Higher is better</td> <td>Maximum value</td> </tr> </tbody> </table> <p><strong>Elbow Method:</strong> - Plot inertia vs k - Look for "elbow" where adding clusters provides diminishing returns - Trade-off between fit and complexity - k value selector (slider or buttons for k = 2 to 10) - Dataset dropdown (Iris, synthetic blobs, custom upload) - Number of features slider (for synthetic data) - Cluster separation slider (for synthetic data) - Reset button</p> <ul> <li><strong>Metrics Display:</strong></li> <li>Current k value</li> <li>Inertia for current k</li> <li>Average silhouette score</li> <li>Number of iterations to convergence</li> <li>Cluster size distribution (histogram)</li> </ul> <p><strong>Interactions:</strong></p> <ul> <li>Click on elbow curve to set k and update visualization</li> <li>Click on silhouette plot to set k</li> <li>Hover over any plot to see detailed tooltips</li> <li>Synchronized highlighting: hover over a cluster in visualization highlights corresponding bar in silhouette plot</li> <li>Toggle between 2D views (first two features, PCA, t-SNE)</li> <li>Generate new synthetic data with adjustable parameters</li> <li>Export metrics as CSV</li> </ul> <p><strong>Default Parameters:</strong></p> <ul> <li>Dataset: Iris (4 features, 150 samples)</li> <li>k range: 2-10</li> <li>Initialization: k-means++</li> <li>Display: All three panels visible</li> </ul> <p><strong>Implementation:</strong> p5.js for all visualizations. Implement k-means and PCA in JavaScript for real-time computation. Use Chart.js or custom p5.js plotting for line and bar charts. Compute silhouette scores efficiently using vectorized distance calculations. Include smooth transitions when changing k. Responsive three-panel layout adapting to window size.</p> <p><strong>Canvas:</strong> Three panels, each ~400px × 300px (responsive, stacked on mobile) </p> <h2 id=limitations-and-considerations>Limitations and Considerations<a class=headerlink href=#limitations-and-considerations title="Permanent link">¶</a></h2> <p>While k-means is powerful and widely used, it has important limitations:</p> <h3 id=1-requires-specifying-k>1. Requires Specifying k<a class=headerlink href=#1-requires-specifying-k title="Permanent link">¶</a></h3> <p>You must choose the number of clusters in advance. For exploratory analysis where cluster count is unknown, this creates a chicken-and-egg problem requiring iterative experimentation.</p> <h3 id=2-assumes-spherical-clusters>2. Assumes Spherical Clusters<a class=headerlink href=#2-assumes-spherical-clusters title="Permanent link">¶</a></h3> <p>K-means uses Euclidean distance, implicitly assuming clusters are roughly spherical and equally sized. It struggles with: - Elongated or irregular cluster shapes - Clusters of very different sizes - Nested or hierarchical structures</p> <h3 id=3-sensitive-to-outliers>3. Sensitive to Outliers<a class=headerlink href=#3-sensitive-to-outliers title="Permanent link">¶</a></h3> <p>Since centroids are means, a few extreme outliers can pull centroids far from the true cluster center, distorting cluster boundaries.</p> <h3 id=4-local-optima>4. Local Optima<a class=headerlink href=#4-local-optima title="Permanent link">¶</a></h3> <p>K-means is not guaranteed to find the global minimum. Different initializations can produce different solutions. Always run multiple times or use k-means++ initialization.</p> <h3 id=5-scale-sensitivity>5. Scale Sensitivity<a class=headerlink href=#5-scale-sensitivity title="Permanent link">¶</a></h3> <p>Features with larger scales dominate distance calculations. Always standardize features before clustering:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a><span class=c1># Standardize features</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a><span class=n>X_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a><span class=c1># Cluster on scaled data</span>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a><span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a><span class=n>kmeans</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_scaled</span><span class=p>)</span>
</span></code></pre></div> <h3 id=6-only-works-with-numerical-data>6. Only Works with Numerical Data<a class=headerlink href=#6-only-works-with-numerical-data title="Permanent link">¶</a></h3> <p>K-means requires computing distances and means, which aren't well-defined for categorical variables. Use specialized algorithms (k-modes, k-prototypes) for categorical or mixed data.</p> <h2 id=practical-applications>Practical Applications<a class=headerlink href=#practical-applications title="Permanent link">¶</a></h2> <h3 id=customer-segmentation>Customer Segmentation<a class=headerlink href=#customer-segmentation title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=c1># Example: Segment customers by purchasing behavior</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=c1># Features: total_spent, num_purchases, avg_purchase_value, days_since_last_purchase</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a><span class=n>customer_data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>'customer_data.csv'</span><span class=p>)</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a><span class=n>features</span> <span class=o>=</span> <span class=p>[</span><span class=s1>'total_spent'</span><span class=p>,</span> <span class=s1>'num_purchases'</span><span class=p>,</span> <span class=s1>'avg_purchase_value'</span><span class=p>,</span> <span class=s1>'days_since_last_purchase'</span><span class=p>]</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a><span class=c1># Standardize</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span><span id=__span-12-9><a id=__codelineno-12-9 name=__codelineno-12-9 href=#__codelineno-12-9></a><span class=n>X_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>customer_data</span><span class=p>[</span><span class=n>features</span><span class=p>])</span>
</span><span id=__span-12-10><a id=__codelineno-12-10 name=__codelineno-12-10 href=#__codelineno-12-10></a>
</span><span id=__span-12-11><a id=__codelineno-12-11 name=__codelineno-12-11 href=#__codelineno-12-11></a><span class=c1># Find optimal k using elbow method</span>
</span><span id=__span-12-12><a id=__codelineno-12-12 name=__codelineno-12-12 href=#__codelineno-12-12></a><span class=n>inertias</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-12-13><a id=__codelineno-12-13 name=__codelineno-12-13 href=#__codelineno-12-13></a><span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>11</span><span class=p>):</span>
</span><span id=__span-12-14><a id=__codelineno-12-14 name=__codelineno-12-14 href=#__codelineno-12-14></a>    <span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>k</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-12-15><a id=__codelineno-12-15 name=__codelineno-12-15 href=#__codelineno-12-15></a>    <span class=n>kmeans</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_scaled</span><span class=p>)</span>
</span><span id=__span-12-16><a id=__codelineno-12-16 name=__codelineno-12-16 href=#__codelineno-12-16></a>    <span class=n>inertias</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>kmeans</span><span class=o>.</span><span class=n>inertia_</span><span class=p>)</span>
</span><span id=__span-12-17><a id=__codelineno-12-17 name=__codelineno-12-17 href=#__codelineno-12-17></a>
</span><span id=__span-12-18><a id=__codelineno-12-18 name=__codelineno-12-18 href=#__codelineno-12-18></a><span class=c1># Choose k=4 based on elbow</span>
</span><span id=__span-12-19><a id=__codelineno-12-19 name=__codelineno-12-19 href=#__codelineno-12-19></a><span class=n>kmeans_final</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-12-20><a id=__codelineno-12-20 name=__codelineno-12-20 href=#__codelineno-12-20></a><span class=n>customer_data</span><span class=p>[</span><span class=s1>'Segment'</span><span class=p>]</span> <span class=o>=</span> <span class=n>kmeans_final</span><span class=o>.</span><span class=n>fit_predict</span><span class=p>(</span><span class=n>X_scaled</span><span class=p>)</span>
</span><span id=__span-12-21><a id=__codelineno-12-21 name=__codelineno-12-21 href=#__codelineno-12-21></a>
</span><span id=__span-12-22><a id=__codelineno-12-22 name=__codelineno-12-22 href=#__codelineno-12-22></a><span class=c1># Analyze segments</span>
</span><span id=__span-12-23><a id=__codelineno-12-23 name=__codelineno-12-23 href=#__codelineno-12-23></a><span class=nb>print</span><span class=p>(</span><span class=n>customer_data</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span><span class=s1>'Segment'</span><span class=p>)[</span><span class=n>features</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>
</span></code></pre></div> <p>This reveals customer groups like "high-value frequent buyers," "occasional big spenders," "regular small purchasers," and "inactive accounts."</p> <h3 id=image-compression>Image Compression<a class=headerlink href=#image-compression title="Permanent link">¶</a></h3> <p>K-means can reduce the number of colors in an image:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.cluster</span><span class=w> </span><span class=kn>import</span> <span class=n>KMeans</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a><span class=kn>from</span><span class=w> </span><span class=nn>PIL</span><span class=w> </span><span class=kn>import</span> <span class=n>Image</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=c1># Load image and reshape to (num_pixels, 3) for RGB</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a><span class=n>img</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=s1>'photo.jpg'</span><span class=p>))</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>,</span> <span class=n>d</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a><span class=n>img_flat</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a><span class=c1># Cluster colors into k representative colors</span>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a><span class=n>k</span> <span class=o>=</span> <span class=mi>16</span>  <span class=c1># Reduce to 16 colors</span>
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a><span class=n>kmeans</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=n>k</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a><span class=n>kmeans</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>img_flat</span><span class=p>)</span>
</span><span id=__span-13-14><a id=__codelineno-13-14 name=__codelineno-13-14 href=#__codelineno-13-14></a>
</span><span id=__span-13-15><a id=__codelineno-13-15 name=__codelineno-13-15 href=#__codelineno-13-15></a><span class=c1># Replace each pixel with its cluster centroid</span>
</span><span id=__span-13-16><a id=__codelineno-13-16 name=__codelineno-13-16 href=#__codelineno-13-16></a><span class=n>compressed</span> <span class=o>=</span> <span class=n>kmeans</span><span class=o>.</span><span class=n>cluster_centers_</span><span class=p>[</span><span class=n>kmeans</span><span class=o>.</span><span class=n>labels_</span><span class=p>]</span>
</span><span id=__span-13-17><a id=__codelineno-13-17 name=__codelineno-13-17 href=#__codelineno-13-17></a><span class=n>compressed_img</span> <span class=o>=</span> <span class=n>compressed</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>,</span> <span class=n>d</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s1>'uint8'</span><span class=p>)</span>
</span><span id=__span-13-18><a id=__codelineno-13-18 name=__codelineno-13-18 href=#__codelineno-13-18></a>
</span><span id=__span-13-19><a id=__codelineno-13-19 name=__codelineno-13-19 href=#__codelineno-13-19></a><span class=c1># Display original vs compressed</span>
</span><span id=__span-13-20><a id=__codelineno-13-20 name=__codelineno-13-20 href=#__codelineno-13-20></a><span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span><span id=__span-13-21><a id=__codelineno-13-21 name=__codelineno-13-21 href=#__codelineno-13-21></a><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span><span id=__span-13-22><a id=__codelineno-13-22 name=__codelineno-13-22 href=#__codelineno-13-22></a><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>'Original'</span><span class=p>)</span>
</span><span id=__span-13-23><a id=__codelineno-13-23 name=__codelineno-13-23 href=#__codelineno-13-23></a><span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>'off'</span><span class=p>)</span>
</span><span id=__span-13-24><a id=__codelineno-13-24 name=__codelineno-13-24 href=#__codelineno-13-24></a>
</span><span id=__span-13-25><a id=__codelineno-13-25 name=__codelineno-13-25 href=#__codelineno-13-25></a><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>compressed_img</span><span class=p>)</span>
</span><span id=__span-13-26><a id=__codelineno-13-26 name=__codelineno-13-26 href=#__codelineno-13-26></a><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=sa>f</span><span class=s1>'Compressed (</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s1> colors)'</span><span class=p>)</span>
</span><span id=__span-13-27><a id=__codelineno-13-27 name=__codelineno-13-27 href=#__codelineno-13-27></a><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>'off'</span><span class=p>)</span>
</span><span id=__span-13-28><a id=__codelineno-13-28 name=__codelineno-13-28 href=#__codelineno-13-28></a>
</span><span id=__span-13-29><a id=__codelineno-13-29 name=__codelineno-13-29 href=#__codelineno-13-29></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <h2 id=summary_1>Summary<a class=headerlink href=#summary_1 title="Permanent link">¶</a></h2> <p>K-means clustering discovers natural groupings in unlabeled data through an iterative refinement process. By alternating between assigning points to the nearest centroid and recomputing centroids as cluster means, the algorithm minimizes within-cluster variance.</p> <p>The <strong>cluster assignment</strong> step assigns each point to its nearest centroid, while the <strong>cluster update</strong> step recomputes each centroid as the mean of its assigned points. This process continues until <strong>convergence criteria</strong> are met—typically when assignments stabilize or centroids move minimally.</p> <p><strong>Initialization</strong> critically affects k-means performance. <strong>K-means++</strong> initialization spreads initial centroids apart, leading to better and more consistent results than <strong>random initialization</strong>. Running k-means multiple times with different initializations helps avoid poor local minima.</p> <p>Choosing the number of clusters <span class=arithmatex>\(k\)</span> requires evaluation metrics. The <strong>elbow method</strong> identifies <span class=arithmatex>\(k\)</span> where adding more clusters yields diminishing returns in <strong>inertia</strong> (within-cluster sum of squares). <strong>Silhouette scores</strong> measure cluster separation quality, with higher scores indicating well-defined clusters.</p> <p>While k-means is efficient and effective for many tasks, it assumes spherical clusters of similar sizes, requires specifying <span class=arithmatex>\(k\)</span> in advance, and is sensitive to outliers and feature scales. Despite these limitations, k-means remains the most widely used clustering algorithm for exploratory data analysis, customer segmentation, image compression, and pattern discovery.</p> <h2 id=key-takeaways>Key Takeaways<a class=headerlink href=#key-takeaways title="Permanent link">¶</a></h2> <ol> <li><strong>K-means clustering</strong> partitions unlabeled data into <span class=arithmatex>\(k\)</span> groups by iteratively refining cluster assignments</li> <li><strong>Centroids</strong> represent cluster centers as the geometric mean of assigned points</li> <li><strong>Cluster assignment</strong> assigns each point to the nearest centroid</li> <li><strong>Cluster update</strong> recomputes centroids as the mean of assigned points</li> <li><strong>K-means++ initialization</strong> spreads initial centroids to improve convergence</li> <li><strong>Random initialization</strong> can lead to suboptimal solutions; multiple runs recommended</li> <li>The <strong>elbow method</strong> identifies optimal <span class=arithmatex>\(k\)</span> by finding diminishing returns in inertia reduction</li> <li><strong>Silhouette scores</strong> measure cluster quality by comparing within-cluster cohesion to between-cluster separation</li> <li><strong>Within-cluster variance</strong> and <strong>inertia</strong> quantify cluster compactness</li> <li><strong>Convergence criteria</strong> stop iteration when assignments stabilize or maximum iterations are reached</li> <li>Always standardize features before k-means clustering</li> <li>K-means assumes spherical clusters and is sensitive to initialization and outliers</li> </ol> <h2 id=further-reading>Further Reading<a class=headerlink href=#further-reading title="Permanent link">¶</a></h2> <ul> <li>MacQueen, J. (1967). "Some methods for classification and analysis of multivariate observations." <em>Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</em>, 1, 281-297.</li> <li>Arthur, D., &amp; Vassilvitskii, S. (2007). "k-means++: The advantages of careful seeding." <em>Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms</em>, 1027-1035.</li> <li>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The Elements of Statistical Learning</em> (Chapter 14: Unsupervised Learning)</li> <li>Scikit-learn documentation: <a href=https://scikit-learn.org/stable/modules/clustering.html>Clustering</a></li> </ul> <h2 id=exercises>Exercises<a class=headerlink href=#exercises title="Permanent link">¶</a></h2> <ol> <li> <p><strong>Algorithm Trace</strong>: Manually execute k-means on a small 2D dataset (10 points) for 3 iterations with k=2. Show cluster assignments and centroid positions at each step.</p> </li> <li> <p><strong>Initialization Impact</strong>: Generate a dataset with 4 well-separated Gaussian blobs. Run k-means 20 times with random initialization and 20 times with k-means++. Compare the distribution of final inertia values and number of iterations.</p> </li> <li> <p><strong>Elbow Ambiguity</strong>: Create a dataset where the elbow method gives an ambiguous result (no clear elbow). Use silhouette scores to determine the optimal k. Explain why the methods disagree.</p> </li> <li> <p><strong>Feature Scaling</strong>: Generate a dataset with features on vastly different scales (e.g., one feature ranges 0-1, another 0-10000). Cluster with and without standardization. Visualize and explain the differences.</p> </li> <li> <p><strong>Non-Spherical Clusters</strong>: Create a dataset with concentric circles or moons (scikit-learn provides <code>make_circles</code> and <code>make_moons</code>). Apply k-means and observe its limitations. Research and apply an alternative clustering algorithm (DBSCAN or spectral clustering) that handles non-spherical shapes.</p> </li> <li> <p><strong>Image Segmentation</strong>: Load a color image and use k-means to segment it into regions. Experiment with different k values and visualize the resulting segmentations. Compute silhouette scores to find optimal segmentation.</p> </li> </ol> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../06-support-vector-machines/quiz/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Quiz"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Quiz </div> </div> </a> <a href=quiz/ class="md-footer__link md-footer__link--next" aria-label="Next: Quiz"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Quiz </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright © 2025 | CC BY-NC-SA 4.0 DEED </div> </div> <div class=md-social> <a href=https://github.com/AnvithPothula target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </a> <a href=https://linkedin.com/in/anvith-pothula target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"></path></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.path", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>