<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Master evaluation metrics, cross-validation, optimization algorithms, and hyperparameter tuning for building robust machine learning systems"><meta name=author content="Anvith Pothula"><link href=https://example.com/chapters/12-evaluation-optimization/ rel=canonical><link href=../11-transfer-learning/quiz/ rel=prev><link href=quiz/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Model Evaluation, Optimization, and Advanced Topics - Machine Learning - Algorithms and Applications</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#model-evaluation-optimization-and-advanced-topics class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-header__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Machine Learning - Algorithms and Applications </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Model Evaluation, Optimization, and Advanced Topics </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=blue aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../course-description/ class=md-tabs__link> Course Description </a> </li> <li class=md-tabs__item> <a href=../../faq/ class=md-tabs__link> FAQ </a> </li> <li class=md-tabs__item> <a href=../../glossary/ class=md-tabs__link> Glossary </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> Chapters </a> </li> <li class=md-tabs__item> <a href=../../sims/ class=md-tabs__link> MicroSims </a> </li> <li class=md-tabs__item> <a href=../../learning-graph/ class=md-tabs__link> Learning Graph </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Machine Learning - Algorithms and Applications" class="md-nav__button md-logo" aria-label="Machine Learning - Algorithms and Applications" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Machine Learning - Algorithms and Applications </label> <div class=md-nav__source> <a href=https://github.com/AnvithPothula/machine-learning-textbook title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> machine-learning-textbook </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-nav__item> <a href=../../course-description/ class=md-nav__link> <span class=md-ellipsis> Course Description </span> </a> </li> <li class=md-nav__item> <a href=../../faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> <li class=md-nav__item> <a href=../../glossary/ class=md-nav__link> <span class=md-ellipsis> Glossary </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> Chapters </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Chapters </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_2> <label class=md-nav__link for=__nav_5_2 id=__nav_5_2_label tabindex> <span class=md-ellipsis> 1. ML Fundamentals </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> 1. ML Fundamentals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../01-intro-to-ml-fundamentals/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_3> <label class=md-nav__link for=__nav_5_3 id=__nav_5_3_label tabindex> <span class=md-ellipsis> 2. K-Nearest Neighbors </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_3_label aria-expanded=false> <label class=md-nav__title for=__nav_5_3> <span class="md-nav__icon md-icon"></span> 2. K-Nearest Neighbors </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../02-k-nearest-neighbors/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../02-k-nearest-neighbors/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_4> <label class=md-nav__link for=__nav_5_4 id=__nav_5_4_label tabindex> <span class=md-ellipsis> 3. Decision Trees </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_4_label aria-expanded=false> <label class=md-nav__title for=__nav_5_4> <span class="md-nav__icon md-icon"></span> 3. Decision Trees </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../03-decision-trees/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../03-decision-trees/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_5> <label class=md-nav__link for=__nav_5_5 id=__nav_5_5_label tabindex> <span class=md-ellipsis> 4. Logistic Regression </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5_5> <span class="md-nav__icon md-icon"></span> 4. Logistic Regression </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../04-logistic-regression/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../04-logistic-regression/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_6> <label class=md-nav__link for=__nav_5_6 id=__nav_5_6_label tabindex> <span class=md-ellipsis> 5. Regularization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_6_label aria-expanded=false> <label class=md-nav__title for=__nav_5_6> <span class="md-nav__icon md-icon"></span> 5. Regularization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../05-regularization/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../05-regularization/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_7> <label class=md-nav__link for=__nav_5_7 id=__nav_5_7_label tabindex> <span class=md-ellipsis> 6. Support Vector Machines </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_7_label aria-expanded=false> <label class=md-nav__title for=__nav_5_7> <span class="md-nav__icon md-icon"></span> 6. Support Vector Machines </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../06-support-vector-machines/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../06-support-vector-machines/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_8> <label class=md-nav__link for=__nav_5_8 id=__nav_5_8_label tabindex> <span class=md-ellipsis> 7. K-Means Clustering </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_8_label aria-expanded=false> <label class=md-nav__title for=__nav_5_8> <span class="md-nav__icon md-icon"></span> 7. K-Means Clustering </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../07-k-means-clustering/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../07-k-means-clustering/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_9> <label class=md-nav__link for=__nav_5_9 id=__nav_5_9_label tabindex> <span class=md-ellipsis> 8. Data Preprocessing </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_9_label aria-expanded=false> <label class=md-nav__title for=__nav_5_9> <span class="md-nav__icon md-icon"></span> 8. Data Preprocessing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../08-data-preprocessing/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../08-data-preprocessing/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_10> <label class=md-nav__link for=__nav_5_10 id=__nav_5_10_label tabindex> <span class=md-ellipsis> 9. Neural Networks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_10_label aria-expanded=false> <label class=md-nav__title for=__nav_5_10> <span class="md-nav__icon md-icon"></span> 9. Neural Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../09-neural-networks/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../09-neural-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_11> <label class=md-nav__link for=__nav_5_11 id=__nav_5_11_label tabindex> <span class=md-ellipsis> 10. Convolutional Networks </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_11_label aria-expanded=false> <label class=md-nav__title for=__nav_5_11> <span class="md-nav__icon md-icon"></span> 10. Convolutional Networks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../10-convolutional-networks/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../10-convolutional-networks/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5_12> <label class=md-nav__link for=__nav_5_12 id=__nav_5_12_label tabindex> <span class=md-ellipsis> 11. Transfer Learning </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_12_label aria-expanded=false> <label class=md-nav__title for=__nav_5_12> <span class="md-nav__icon md-icon"></span> 11. Transfer Learning </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../11-transfer-learning/ class=md-nav__link> <span class=md-ellipsis> Content </span> </a> </li> <li class=md-nav__item> <a href=../11-transfer-learning/quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_13 checked> <label class=md-nav__link for=__nav_5_13 id=__nav_5_13_label tabindex> <span class=md-ellipsis> 12. Evaluation & Optimization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_13_label aria-expanded=true> <label class=md-nav__title for=__nav_5_13> <span class="md-nav__icon md-icon"></span> 12. Evaluation & Optimization </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Content </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Content </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#introduction-why-model-evaluation-matters class=md-nav__link> <span class=md-ellipsis> Introduction: Why Model Evaluation Matters </span> </a> </li> <li class=md-nav__item> <a href=#training-error-vs-test-error class=md-nav__link> <span class=md-ellipsis> Training Error vs. Test Error </span> </a> </li> <li class=md-nav__item> <a href=#generalization-and-the-bias-variance-tradeoff class=md-nav__link> <span class=md-ellipsis> Generalization and the Bias-Variance Tradeoff </span> </a> </li> <li class=md-nav__item> <a href=#the-holdout-method-and-data-splitting class=md-nav__link> <span class=md-ellipsis> The Holdout Method and Data Splitting </span> </a> <nav class=md-nav aria-label="The Holdout Method and Data Splitting"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#stratified-sampling class=md-nav__link> <span class=md-ellipsis> Stratified Sampling </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cross-validation-a-more-robust-approach class=md-nav__link> <span class=md-ellipsis> Cross-Validation: A More Robust Approach </span> </a> <nav class=md-nav aria-label="Cross-Validation: A More Robust Approach"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#k-fold-cross-validation class=md-nav__link> <span class=md-ellipsis> K-Fold Cross-Validation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#the-confusion-matrix class=md-nav__link> <span class=md-ellipsis> The Confusion Matrix </span> </a> </li> <li class=md-nav__item> <a href=#classification-metrics-beyond-accuracy class=md-nav__link> <span class=md-ellipsis> Classification Metrics: Beyond Accuracy </span> </a> <nav class=md-nav aria-label="Classification Metrics: Beyond Accuracy"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#precision-and-recall class=md-nav__link> <span class=md-ellipsis> Precision and Recall </span> </a> </li> <li class=md-nav__item> <a href=#specificity class=md-nav__link> <span class=md-ellipsis> Specificity </span> </a> </li> <li class=md-nav__item> <a href=#f1-score class=md-nav__link> <span class=md-ellipsis> F1 Score </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#roc-curves-and-auc class=md-nav__link> <span class=md-ellipsis> ROC Curves and AUC </span> </a> <nav class=md-nav aria-label="ROC Curves and AUC"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#understanding-roc-curves class=md-nav__link> <span class=md-ellipsis> Understanding ROC Curves </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#advanced-optimization-algorithms class=md-nav__link> <span class=md-ellipsis> Advanced Optimization Algorithms </span> </a> <nav class=md-nav aria-label="Advanced Optimization Algorithms"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#adam-optimizer class=md-nav__link> <span class=md-ellipsis> Adam Optimizer </span> </a> </li> <li class=md-nav__item> <a href=#rmsprop class=md-nav__link> <span class=md-ellipsis> RMSprop </span> </a> </li> <li class=md-nav__item> <a href=#nesterov-momentum class=md-nav__link> <span class=md-ellipsis> Nesterov Momentum </span> </a> </li> <li class=md-nav__item> <a href=#gradient-clipping class=md-nav__link> <span class=md-ellipsis> Gradient Clipping </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hyperparameter-tuning class=md-nav__link> <span class=md-ellipsis> Hyperparameter Tuning </span> </a> <nav class=md-nav aria-label="Hyperparameter Tuning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#grid-search class=md-nav__link> <span class=md-ellipsis> Grid Search </span> </a> </li> <li class=md-nav__item> <a href=#random-search class=md-nav__link> <span class=md-ellipsis> Random Search </span> </a> </li> <li class=md-nav__item> <a href=#bayesian-optimization class=md-nav__link> <span class=md-ellipsis> Bayesian Optimization </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#model-selection-choosing-the-right-algorithm class=md-nav__link> <span class=md-ellipsis> Model Selection: Choosing the Right Algorithm </span> </a> </li> <li class=md-nav__item> <a href=#putting-it-all-together-a-complete-evaluation-pipeline class=md-nav__link> <span class=md-ellipsis> Putting It All Together: A Complete Evaluation Pipeline </span> </a> </li> <li class=md-nav__item> <a href=#common-pitfalls-and-how-to-avoid-them class=md-nav__link> <span class=md-ellipsis> Common Pitfalls and How to Avoid Them </span> </a> </li> <li class=md-nav__item> <a href=#summary-and-key-takeaways class=md-nav__link> <span class=md-ellipsis> Summary and Key Takeaways </span> </a> </li> <li class=md-nav__item> <a href=#further-reading class=md-nav__link> <span class=md-ellipsis> Further Reading </span> </a> </li> <li class=md-nav__item> <a href=#exercises class=md-nav__link> <span class=md-ellipsis> Exercises </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=quiz/ class=md-nav__link> <span class=md-ellipsis> Quiz </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> MicroSims </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> MicroSims </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../sims/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../../sims/activation-functions/ class=md-nav__link> <span class=md-ellipsis> Activation Functions </span> </a> </li> <li class=md-nav__item> <a href=../../sims/categorical-encoding-explorer/ class=md-nav__link> <span class=md-ellipsis> Categorical Encoding Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/cnn-architecture/ class=md-nav__link> <span class=md-ellipsis> CNN Architecture </span> </a> </li> <li class=md-nav__item> <a href=../../sims/confusion-matrix-explorer/ class=md-nav__link> <span class=md-ellipsis> Confusion Matrix Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/convolution-operation/ class=md-nav__link> <span class=md-ellipsis> Convolution Operation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/distance-metrics/ class=md-nav__link> <span class=md-ellipsis> Distance Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../sims/entropy-gini-comparison/ class=md-nav__link> <span class=md-ellipsis> Entropy-Gini Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/feature-scaling-visualizer/ class=md-nav__link> <span class=md-ellipsis> Feature Scaling Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/k-selection-simulator/ class=md-nav__link> <span class=md-ellipsis> K-Selection Simulator </span> </a> </li> <li class=md-nav__item> <a href=../../sims/kfold-cross-validation/ class=md-nav__link> <span class=md-ellipsis> K-Fold Cross Validation </span> </a> </li> <li class=md-nav__item> <a href=../../sims/lasso-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Lasso Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/network-architecture-visualizer/ class=md-nav__link> <span class=md-ellipsis> Network Architecture Visualizer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/ridge-regression-geometry/ class=md-nav__link> <span class=md-ellipsis> Ridge Regression Geometry </span> </a> </li> <li class=md-nav__item> <a href=../../sims/roc-curve-comparison/ class=md-nav__link> <span class=md-ellipsis> ROC Curve Comparison </span> </a> </li> <li class=md-nav__item> <a href=../../sims/sigmoid-explorer/ class=md-nav__link> <span class=md-ellipsis> Sigmoid Explorer </span> </a> </li> <li class=md-nav__item> <a href=../../sims/svm-margin-maximization/ class=md-nav__link> <span class=md-ellipsis> SVM Margin Maximization </span> </a> </li> <li class=md-nav__item> <a href=../../sims/training-validation-curves/ class=md-nav__link> <span class=md-ellipsis> Training Validation Curves </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex=0> <span class=md-ellipsis> Learning Graph </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Learning Graph </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../learning-graph/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../sims/graph-viewer/ class=md-nav__link> <span class=md-ellipsis> Graph Viewer </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/course-description-assessment/ class=md-nav__link> <span class=md-ellipsis> Course Description Assessment </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-list/ class=md-nav__link> <span class=md-ellipsis> Concept List </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/concept-taxonomy/ class=md-nav__link> <span class=md-ellipsis> Concept Taxonomy </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.csv class=md-nav__link> <span class=md-ellipsis> Learning Graph (CSV) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/learning-graph.json class=md-nav__link> <span class=md-ellipsis> Learning Graph (JSON) </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/quality-metrics/ class=md-nav__link> <span class=md-ellipsis> Quality Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/taxonomy-distribution/ class=md-nav__link> <span class=md-ellipsis> Taxonomy Distribution </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/glossary-quality-report/ class=md-nav__link> <span class=md-ellipsis> Glossary Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-quality-report/ class=md-nav__link> <span class=md-ellipsis> FAQ Quality Report </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/faq-coverage-gaps/ class=md-nav__link> <span class=md-ellipsis> FAQ Coverage Gaps </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/book-metrics/ class=md-nav__link> <span class=md-ellipsis> Book Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../learning-graph/chapter-metrics/ class=md-nav__link> <span class=md-ellipsis> Chapter Metrics </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#concepts-covered class=md-nav__link> <span class=md-ellipsis> Concepts Covered </span> </a> </li> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> <li class=md-nav__item> <a href=#introduction-why-model-evaluation-matters class=md-nav__link> <span class=md-ellipsis> Introduction: Why Model Evaluation Matters </span> </a> </li> <li class=md-nav__item> <a href=#training-error-vs-test-error class=md-nav__link> <span class=md-ellipsis> Training Error vs. Test Error </span> </a> </li> <li class=md-nav__item> <a href=#generalization-and-the-bias-variance-tradeoff class=md-nav__link> <span class=md-ellipsis> Generalization and the Bias-Variance Tradeoff </span> </a> </li> <li class=md-nav__item> <a href=#the-holdout-method-and-data-splitting class=md-nav__link> <span class=md-ellipsis> The Holdout Method and Data Splitting </span> </a> <nav class=md-nav aria-label="The Holdout Method and Data Splitting"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#stratified-sampling class=md-nav__link> <span class=md-ellipsis> Stratified Sampling </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cross-validation-a-more-robust-approach class=md-nav__link> <span class=md-ellipsis> Cross-Validation: A More Robust Approach </span> </a> <nav class=md-nav aria-label="Cross-Validation: A More Robust Approach"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#k-fold-cross-validation class=md-nav__link> <span class=md-ellipsis> K-Fold Cross-Validation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#the-confusion-matrix class=md-nav__link> <span class=md-ellipsis> The Confusion Matrix </span> </a> </li> <li class=md-nav__item> <a href=#classification-metrics-beyond-accuracy class=md-nav__link> <span class=md-ellipsis> Classification Metrics: Beyond Accuracy </span> </a> <nav class=md-nav aria-label="Classification Metrics: Beyond Accuracy"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#precision-and-recall class=md-nav__link> <span class=md-ellipsis> Precision and Recall </span> </a> </li> <li class=md-nav__item> <a href=#specificity class=md-nav__link> <span class=md-ellipsis> Specificity </span> </a> </li> <li class=md-nav__item> <a href=#f1-score class=md-nav__link> <span class=md-ellipsis> F1 Score </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#roc-curves-and-auc class=md-nav__link> <span class=md-ellipsis> ROC Curves and AUC </span> </a> <nav class=md-nav aria-label="ROC Curves and AUC"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#understanding-roc-curves class=md-nav__link> <span class=md-ellipsis> Understanding ROC Curves </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#advanced-optimization-algorithms class=md-nav__link> <span class=md-ellipsis> Advanced Optimization Algorithms </span> </a> <nav class=md-nav aria-label="Advanced Optimization Algorithms"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#adam-optimizer class=md-nav__link> <span class=md-ellipsis> Adam Optimizer </span> </a> </li> <li class=md-nav__item> <a href=#rmsprop class=md-nav__link> <span class=md-ellipsis> RMSprop </span> </a> </li> <li class=md-nav__item> <a href=#nesterov-momentum class=md-nav__link> <span class=md-ellipsis> Nesterov Momentum </span> </a> </li> <li class=md-nav__item> <a href=#gradient-clipping class=md-nav__link> <span class=md-ellipsis> Gradient Clipping </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hyperparameter-tuning class=md-nav__link> <span class=md-ellipsis> Hyperparameter Tuning </span> </a> <nav class=md-nav aria-label="Hyperparameter Tuning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#grid-search class=md-nav__link> <span class=md-ellipsis> Grid Search </span> </a> </li> <li class=md-nav__item> <a href=#random-search class=md-nav__link> <span class=md-ellipsis> Random Search </span> </a> </li> <li class=md-nav__item> <a href=#bayesian-optimization class=md-nav__link> <span class=md-ellipsis> Bayesian Optimization </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#model-selection-choosing-the-right-algorithm class=md-nav__link> <span class=md-ellipsis> Model Selection: Choosing the Right Algorithm </span> </a> </li> <li class=md-nav__item> <a href=#putting-it-all-together-a-complete-evaluation-pipeline class=md-nav__link> <span class=md-ellipsis> Putting It All Together: A Complete Evaluation Pipeline </span> </a> </li> <li class=md-nav__item> <a href=#common-pitfalls-and-how-to-avoid-them class=md-nav__link> <span class=md-ellipsis> Common Pitfalls and How to Avoid Them </span> </a> </li> <li class=md-nav__item> <a href=#summary-and-key-takeaways class=md-nav__link> <span class=md-ellipsis> Summary and Key Takeaways </span> </a> </li> <li class=md-nav__item> <a href=#further-reading class=md-nav__link> <span class=md-ellipsis> Further Reading </span> </a> </li> <li class=md-nav__item> <a href=#exercises class=md-nav__link> <span class=md-ellipsis> Exercises </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=model-evaluation-optimization-and-advanced-topics>Model Evaluation, Optimization, and Advanced Topics<a class=headerlink href=#model-evaluation-optimization-and-advanced-topics title="Permanent link">&para;</a></h1> <h2 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">&para;</a></h2> <p>This comprehensive final chapter brings together essential techniques for evaluating, optimizing, and deploying machine learning models. Students will master evaluation metrics including confusion matrices, accuracy, precision, recall, F1 score, ROC curves, and AUC, learning when to apply each metric based on problem characteristics. The chapter covers cross-validation strategies, the bias-variance tradeoff, generalization, and methods for diagnosing overfitting and underfitting through training and validation error analysis. Students will explore advanced optimization algorithms (Adam, RMSprop, Nesterov momentum) and regularization techniques (dropout, early stopping, gradient clipping), and learn systematic approaches to hyperparameter tuning through grid search, random search, and Bayesian optimization. This chapter synthesizes knowledge from the entire course, preparing students to tackle real-world machine learning projects.</p> <h2 id=concepts-covered>Concepts Covered<a class=headerlink href=#concepts-covered title="Permanent link">&para;</a></h2> <p>This chapter covers the following 28 concepts from the learning graph:</p> <ol> <li>Training Error</li> <li>Test Error</li> <li>Generalization</li> <li>Stratified Sampling</li> <li>Holdout Method</li> <li>Confusion Matrix</li> <li>True Positive</li> <li>False Positive</li> <li>True Negative</li> <li>False Negative</li> <li>Accuracy</li> <li>Precision</li> <li>Recall</li> <li>F1 Score</li> <li>ROC Curve</li> <li>AUC</li> <li>Sensitivity</li> <li>Specificity</li> <li>Adam Optimizer</li> <li>RMSprop</li> <li>Nesterov Momentum</li> <li>Gradient Clipping</li> <li>Model Evaluation</li> <li>Model Selection</li> <li>Hyperparameter Tuning</li> <li>Grid Search</li> <li>Random Search</li> <li>Bayesian Optimization</li> </ol> <h2 id=prerequisites>Prerequisites<a class=headerlink href=#prerequisites title="Permanent link">&para;</a></h2> <p>This chapter builds on concepts from:</p> <ul> <li><a href=../01-intro-to-ml-fundamentals/ >Chapter 1: Introduction to Machine Learning Fundamentals</a></li> <li><a href=../03-decision-trees/ >Chapter 3: Decision Trees and Tree-Based Learning</a></li> <li><a href=../05-regularization/ >Chapter 5: Regularization Techniques</a></li> <li><a href=../08-data-preprocessing/ >Chapter 8: Data Preprocessing and Feature Engineering</a></li> <li><a href=../09-neural-networks/ >Chapter 9: Neural Networks Fundamentals</a></li> </ul> <hr> <h2 id=introduction-why-model-evaluation-matters>Introduction: Why Model Evaluation Matters<a class=headerlink href=#introduction-why-model-evaluation-matters title="Permanent link">&para;</a></h2> <p>Imagine you've trained a machine learning model that predicts whether a medical patient has a rare disease. Your model achieves 99% accuracy—impressive, right? But what if only 1% of patients actually have the disease? A naive model that always predicts "no disease" would also achieve 99% accuracy while being completely useless for diagnosis. This example illustrates a fundamental truth: <strong>choosing the right evaluation metric is as important as building a good model</strong>.</p> <p>Throughout this course, we've built classifiers, regressors, clustering algorithms, and neural networks. But how do we know if these models are actually good? How do we compare different approaches? How do we ensure our models will perform well on new, unseen data? These questions lie at the heart of machine learning practice.</p> <p>This chapter synthesizes the evaluation, optimization, and tuning techniques that separate research prototypes from production-ready systems. We'll explore how to measure model performance accurately, diagnose common problems like overfitting and underfitting, select optimal hyperparameters, and deploy models that generalize well to real-world scenarios.</p> <h2 id=training-error-vs-test-error>Training Error vs. Test Error<a class=headerlink href=#training-error-vs-test-error title="Permanent link">&para;</a></h2> <p>The most fundamental concept in model evaluation is the distinction between <strong>training error</strong> and <strong>test error</strong>.</p> <p><strong>Training error</strong> measures how well your model fits the data it was trained on. It's computed by evaluating the model's predictions on the same dataset used for training. While low training error might seem desirable, it can be misleading—a model that memorizes the training data will have zero training error but fail completely on new examples.</p> <p><strong>Test error</strong> measures how well your model performs on data it has never seen before. This is the metric we truly care about, as it reflects real-world performance. The gap between training and test error reveals whether your model has learned genuine patterns or simply memorized noise.</p> <p>Let's implement a simple example to illustrate this distinction:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.neighbors</span><span class=w> </span><span class=kn>import</span> <span class=n>KNeighborsClassifier</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>accuracy_score</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=c1># Load iris dataset</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=n>iris_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s1>&#39;https://raw.githubusercontent.com/sziccardi/MLCamp2025_DataRepository/main/iris.csv&#39;</span><span class=p>)</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a><span class=c1># Prepare features and target</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=n>feature_names</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;sepal_length&quot;</span><span class=p>,</span> <span class=s2>&quot;sepal_width&quot;</span><span class=p>,</span> <span class=s2>&quot;petal_length&quot;</span><span class=p>,</span> <span class=s2>&quot;petal_width&quot;</span><span class=p>]</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a><span class=n>X</span> <span class=o>=</span> <span class=n>iris_df</span><span class=p>[</span><span class=n>feature_names</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a><span class=n>y</span> <span class=o>=</span> <span class=n>iris_df</span><span class=p>[</span><span class=s2>&quot;species&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>values</span>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a><span class=c1># Split data into training and testing sets</span>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>    <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>0</span>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a><span class=p>)</span>
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a><span class=c1># Train a 3-nearest neighbors classifier</span>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a><span class=n>classifier</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a><span class=n>classifier</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a>
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a><span class=c1># Compute training error</span>
</span><span id=__span-0-24><a id=__codelineno-0-24 name=__codelineno-0-24 href=#__codelineno-0-24></a><span class=n>y_train_pred</span> <span class=o>=</span> <span class=n>classifier</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span><span id=__span-0-25><a id=__codelineno-0-25 name=__codelineno-0-25 href=#__codelineno-0-25></a><span class=n>train_accuracy</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_train</span><span class=p>,</span> <span class=n>y_train_pred</span><span class=p>)</span>
</span><span id=__span-0-26><a id=__codelineno-0-26 name=__codelineno-0-26 href=#__codelineno-0-26></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Training Accuracy: </span><span class=si>{</span><span class=n>train_accuracy</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-0-27><a id=__codelineno-0-27 name=__codelineno-0-27 href=#__codelineno-0-27></a>
</span><span id=__span-0-28><a id=__codelineno-0-28 name=__codelineno-0-28 href=#__codelineno-0-28></a><span class=c1># Compute test error</span>
</span><span id=__span-0-29><a id=__codelineno-0-29 name=__codelineno-0-29 href=#__codelineno-0-29></a><span class=n>y_test_pred</span> <span class=o>=</span> <span class=n>classifier</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-0-30><a id=__codelineno-0-30 name=__codelineno-0-30 href=#__codelineno-0-30></a><span class=n>test_accuracy</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_test_pred</span><span class=p>)</span>
</span><span id=__span-0-31><a id=__codelineno-0-31 name=__codelineno-0-31 href=#__codelineno-0-31></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test Accuracy: </span><span class=si>{</span><span class=n>test_accuracy</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>Typical output: <div class="language-text highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>Training Accuracy: 0.9667
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>Test Accuracy: 0.9667
</span></code></pre></div></p> <p>In this example, training and test accuracy are similar, suggesting good <strong>generalization</strong>. However, with more complex models or smaller datasets, we often see training accuracy significantly higher than test accuracy—a clear sign of overfitting.</p> <h2 id=generalization-and-the-bias-variance-tradeoff>Generalization and the Bias-Variance Tradeoff<a class=headerlink href=#generalization-and-the-bias-variance-tradeoff title="Permanent link">&para;</a></h2> <p><strong>Generalization</strong> refers to a model's ability to perform well on new, unseen data. A model that generalizes well has learned the underlying patterns in the data rather than memorizing specific training examples.</p> <p>The <strong>bias-variance tradeoff</strong> is a fundamental framework for understanding generalization:</p> <ul> <li> <p><strong>High bias</strong> models are too simple and underfit the data. They make strong assumptions about the data's structure, leading to systematic errors on both training and test sets. Examples: linear regression on non-linear data, decision stumps (depth-1 trees).</p> </li> <li> <p><strong>High variance</strong> models are too complex and overfit the data. They capture noise in the training set, performing well on training data but poorly on test data. Examples: very deep decision trees, k-NN with k=1, neural networks with too many parameters.</p> </li> </ul> <p>The relationship between model complexity, bias, and variance can be visualized:</p> <table> <thead> <tr> <th>Model Complexity</th> <th>Bias</th> <th>Variance</th> <th>Training Error</th> <th>Test Error</th> <th>Generalization</th> </tr> </thead> <tbody> <tr> <td>Too Simple</td> <td>High</td> <td>Low</td> <td>High</td> <td>High</td> <td>Poor (underfitting)</td> </tr> <tr> <td>Optimal</td> <td>Moderate</td> <td>Moderate</td> <td>Moderate</td> <td>Moderate</td> <td>Good</td> </tr> <tr> <td>Too Complex</td> <td>Low</td> <td>High</td> <td>Low</td> <td>High</td> <td>Poor (overfitting)</td> </tr> </tbody> </table> <p>The goal of machine learning is to find the "sweet spot" where the sum of bias and variance is minimized, achieving the best generalization performance.</p> <div class="admonition tip"> <p class=admonition-title>Detecting Underfitting vs. Overfitting</p> <ul> <li><strong>Underfitting</strong>: Both training and test errors are high, and similar to each other</li> <li><strong>Overfitting</strong>: Training error is low, but test error is much higher</li> <li><strong>Good fit</strong>: Both training and test errors are low and similar to each other</li> </ul> </div> <h2 id=the-holdout-method-and-data-splitting>The Holdout Method and Data Splitting<a class=headerlink href=#the-holdout-method-and-data-splitting title="Permanent link">&para;</a></h2> <p>The <strong>holdout method</strong> is the simplest approach to estimating test error: split your dataset into a training set and a test set, train on the former, and evaluate on the latter.</p> <p>Common split ratios include:</p> <ul> <li><strong>80/20 split</strong>: 80% training, 20% testing (common for medium to large datasets)</li> <li><strong>70/30 split</strong>: 70% training, 30% testing (provides more test data for evaluation)</li> <li><strong>60/20/20 split</strong>: 60% training, 20% validation (for hyperparameter tuning), 20% testing (for final evaluation)</li> </ul> <p>The code from our earlier example demonstrates the holdout method:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>    <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>0</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=p>)</span>
</span></code></pre></div> <p>The <code>test_size=0.2</code> parameter allocates 20% of data for testing. The <code>random_state=0</code> ensures reproducibility—the same random seed produces the same split every time.</p> <h3 id=stratified-sampling>Stratified Sampling<a class=headerlink href=#stratified-sampling title="Permanent link">&para;</a></h3> <p>When working with imbalanced datasets (where some classes are much more frequent than others), standard random splitting can produce unrepresentative train/test sets. <strong>Stratified sampling</strong> solves this by ensuring each split has approximately the same proportion of each class as the original dataset.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=c1># Standard split (may not preserve class proportions)</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>    <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a><span class=p>)</span>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a><span class=c1># Stratified split (preserves class proportions)</span>
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>    <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a><span class=p>)</span>
</span></code></pre></div> <p>The <code>stratify=y</code> parameter instructs <code>train_test_split</code> to maintain the class distribution. If your dataset has 60% class A and 40% class B, stratified sampling ensures both training and test sets maintain this 60/40 ratio.</p> <h2 id=cross-validation-a-more-robust-approach>Cross-Validation: A More Robust Approach<a class=headerlink href=#cross-validation-a-more-robust-approach title="Permanent link">&para;</a></h2> <p>The holdout method has a significant limitation: the train/test split is random, so performance estimates can vary significantly depending on which examples end up in the test set. <strong>Cross-validation</strong> addresses this by averaging performance over multiple train/test splits.</p> <h3 id=k-fold-cross-validation>K-Fold Cross-Validation<a class=headerlink href=#k-fold-cross-validation title="Permanent link">&para;</a></h3> <p>The most common form is <strong>k-fold cross-validation</strong>:</p> <ol> <li>Divide the dataset into k equal-sized folds</li> <li>For each fold i (i = 1, ..., k):</li> <li>Use fold i as the test set</li> <li>Use the remaining k-1 folds as the training set</li> <li>Train the model and compute test error</li> <li>Average the k test errors to get the final performance estimate</li> </ol> <p>Here's how to implement k-fold cross-validation:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>cross_val_score</span><span class=p>,</span> <span class=n>StratifiedKFold</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=c1># Perform 10-fold cross-validation</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=n>knn</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>    <span class=n>knn</span><span class=p>,</span> <span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>    <span class=n>cv</span><span class=o>=</span><span class=n>StratifiedKFold</span><span class=p>(</span><span class=n>n_splits</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>    <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a><span class=p>)</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Cross-validation scores: </span><span class=si>{</span><span class=n>scores</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Mean accuracy: </span><span class=si>{</span><span class=n>scores</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2> (+/- </span><span class=si>{</span><span class=n>scores</span><span class=o>.</span><span class=n>std</span><span class=p>()</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>2</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>The <code>StratifiedKFold</code> ensures each fold maintains the class distribution. Common choices for k are 5 or 10, balancing computational cost with reliable estimation.</p> <p><strong>Advantages of cross-validation:</strong></p> <ul> <li>More reliable performance estimates than a single train/test split</li> <li>Uses all data for both training and testing (at different times)</li> <li>Provides confidence intervals via standard deviation of scores</li> </ul> <p><strong>Disadvantages:</strong></p> <ul> <li>Computationally expensive (k times slower than holdout method)</li> <li>Not suitable for time-series data (where temporal order matters)</li> </ul> <h2 id=the-confusion-matrix>The Confusion Matrix<a class=headerlink href=#the-confusion-matrix title="Permanent link">&para;</a></h2> <p>For classification tasks, accuracy alone is often insufficient to understand model performance. The <strong>confusion matrix</strong> provides a complete picture by showing exactly which predictions were correct and which were incorrect.</p> <p>For binary classification, the confusion matrix is a 2×2 table:</p> <table> <thead> <tr> <th></th> <th>Predicted Negative</th> <th>Predicted Positive</th> </tr> </thead> <tbody> <tr> <td><strong>Actual Negative</strong></td> <td>True Negative (TN)</td> <td>False Positive (FP)</td> </tr> <tr> <td><strong>Actual Positive</strong></td> <td>False Negative (FN)</td> <td>True Positive (TP)</td> </tr> </tbody> </table> <p>Let's compute a confusion matrix for our k-NN classifier:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>confusion_matrix</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=c1># Make predictions on test set</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=n>y_pred</span> <span class=o>=</span> <span class=n>classifier</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a><span class=c1># Compute confusion matrix</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=n>cm</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Confusion Matrix:&quot;</span><span class=p>)</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=nb>print</span><span class=p>(</span><span class=n>cm</span><span class=p>)</span>
</span></code></pre></div> <p>Output: <div class="language-text highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a>[[11  0  0]
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a> [ 0 12  1]
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a> [ 0  0  6]]
</span></code></pre></div></p> <p>For the iris dataset (3 classes), we get a 3×3 matrix. The diagonal entries represent correct classifications, while off-diagonal entries show misclassifications. Here, we see only 1 misclassification: a versicolor flower (row 2) classified as virginica (column 3).</p> <p>The four basic components of a binary confusion matrix have specific names:</p> <ul> <li><strong>True Positive (TP)</strong>: Correctly predicted positive class</li> <li><strong>True Negative (TN)</strong>: Correctly predicted negative class</li> <li><strong>False Positive (FP)</strong>: Incorrectly predicted positive (Type I error)</li> <li><strong>False Negative (FN)</strong>: Incorrectly predicted negative (Type II error)</li> </ul> <p>Understanding these components is crucial for computing derived metrics like precision and recall.</p> <p>Explore the relationship between confusion matrix values and classification metrics:</p> <iframe src=../../sims/confusion-matrix-explorer/confusion-matrix.html width=100% height=950 frameborder=0></iframe> <h2 id=classification-metrics-beyond-accuracy>Classification Metrics: Beyond Accuracy<a class=headerlink href=#classification-metrics-beyond-accuracy title="Permanent link">&para;</a></h2> <p>While accuracy measures the overall proportion of correct predictions, it can be misleading in many real-world scenarios. Consider our disease detection example: with 99% of patients healthy, a model that always predicts "healthy" achieves 99% accuracy despite never detecting the 1% with the disease.</p> <h3 id=precision-and-recall>Precision and Recall<a class=headerlink href=#precision-and-recall title="Permanent link">&para;</a></h3> <p>Two fundamental metrics address this limitation:</p> <p><strong>Precision</strong> answers: "Of all examples predicted as positive, how many were actually positive?"</p> <h4 id=precision-formula>Precision Formula<a class=headerlink href=#precision-formula title="Permanent link">&para;</a></h4> <p><span class=arithmatex>\(\text{Precision} = \frac{TP}{TP + FP}\)</span></p> <p>where:</p> <ul> <li><span class=arithmatex>\(TP\)</span> is the number of true positives</li> <li><span class=arithmatex>\(FP\)</span> is the number of false positives</li> </ul> <p>Precision is critical when false positives are costly. For example, in spam detection, marking legitimate emails as spam (false positives) frustrates users, so we want high precision.</p> <p><strong>Recall</strong> (also called <strong>sensitivity</strong> or <strong>true positive rate</strong>) answers: "Of all actual positive examples, how many did we correctly identify?"</p> <h4 id=recall-formula>Recall Formula<a class=headerlink href=#recall-formula title="Permanent link">&para;</a></h4> <p><span class=arithmatex>\(\text{Recall} = \frac{TP}{TP + FN}\)</span></p> <p>where:</p> <ul> <li><span class=arithmatex>\(TP\)</span> is the number of true positives</li> <li><span class=arithmatex>\(FN\)</span> is the number of false negatives</li> </ul> <p>Recall is critical when false negatives are costly. For disease detection, missing actual cases (false negatives) could be fatal, so we want high recall.</p> <p>There's typically a tradeoff between precision and recall. Predicting positive more aggressively increases recall but decreases precision (more false positives). Being conservative increases precision but decreases recall (more false negatives).</p> <h3 id=specificity>Specificity<a class=headerlink href=#specificity title="Permanent link">&para;</a></h3> <p><strong>Specificity</strong> (also called <strong>true negative rate</strong>) measures how well the model identifies negative examples:</p> <h4 id=specificity-formula>Specificity Formula<a class=headerlink href=#specificity-formula title="Permanent link">&para;</a></h4> <p><span class=arithmatex>\(\text{Specificity} = \frac{TN}{TN + FP}\)</span></p> <p>where:</p> <ul> <li><span class=arithmatex>\(TN\)</span> is the number of true negatives</li> <li><span class=arithmatex>\(FP\)</span> is the number of false positives</li> </ul> <p>Specificity is the negative-class analog of recall. It's particularly important in screening tests where you want to avoid alarming healthy patients with false positives.</p> <h3 id=f1-score>F1 Score<a class=headerlink href=#f1-score title="Permanent link">&para;</a></h3> <p>The <strong>F1 score</strong> provides a single metric that balances precision and recall through their harmonic mean:</p> <h4 id=f1-score-formula>F1 Score Formula<a class=headerlink href=#f1-score-formula title="Permanent link">&para;</a></h4> <p><span class=arithmatex>\(F_1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} = \frac{2 \times TP}{2 \times TP + FP + FN}\)</span></p> <p>The F1 score ranges from 0 (worst) to 1 (best). It's particularly useful when you need a single metric that accounts for both precision and recall, and when classes are imbalanced.</p> <p>Let's compute these metrics in Python:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>precision_score</span><span class=p>,</span> <span class=n>recall_score</span><span class=p>,</span> <span class=n>f1_score</span><span class=p>,</span> <span class=n>classification_report</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=c1># Compute metrics</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=n>precision</span> <span class=o>=</span> <span class=n>precision_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;weighted&#39;</span><span class=p>)</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=n>recall</span> <span class=o>=</span> <span class=n>recall_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;weighted&#39;</span><span class=p>)</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=n>f1</span> <span class=o>=</span> <span class=n>f1_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;weighted&#39;</span><span class=p>)</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Precision: </span><span class=si>{</span><span class=n>precision</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Recall: </span><span class=si>{</span><span class=n>recall</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;F1 Score: </span><span class=si>{</span><span class=n>f1</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a><span class=c1># Or get a comprehensive report</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Classification Report:&quot;</span><span class=p>)</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a><span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>))</span>
</span></code></pre></div> <p>The <code>average='weighted'</code> parameter computes metrics for each class separately, then averages them weighted by class frequency—appropriate for multi-class problems with imbalanced classes.</p> <h2 id=roc-curves-and-auc>ROC Curves and AUC<a class=headerlink href=#roc-curves-and-auc title="Permanent link">&para;</a></h2> <p>While precision, recall, and F1 score are valuable, they depend on choosing a classification threshold (typically 0.5 for probability-based classifiers). The <strong>Receiver Operating Characteristic (ROC) curve</strong> provides a threshold-independent evaluation by plotting the true positive rate (recall) against the false positive rate at various thresholds.</p> <h3 id=understanding-roc-curves>Understanding ROC Curves<a class=headerlink href=#understanding-roc-curves title="Permanent link">&para;</a></h3> <p>The <strong>false positive rate</strong> is defined as:</p> <h4 id=false-positive-rate-formula>False Positive Rate Formula<a class=headerlink href=#false-positive-rate-formula title="Permanent link">&para;</a></h4> <p><span class=arithmatex>\(\text{FPR} = \frac{FP}{FP + TN} = 1 - \text{Specificity}\)</span></p> <p>An ROC curve plots: - <strong>Y-axis</strong>: True Positive Rate (Recall/Sensitivity) - <strong>X-axis</strong>: False Positive Rate (1 - Specificity)</p> <p>Each point on the curve represents the (FPR, TPR) pair at a specific classification threshold. A perfect classifier would have a point at (0, 1)—no false positives, all true positives captured.</p> <p>The <strong>Area Under the Curve (AUC)</strong> summarizes the ROC curve with a single number between 0 and 1:</p> <ul> <li><strong>AUC = 1.0</strong>: Perfect classifier (ideal case)</li> <li><strong>AUC = 0.5</strong>: Random classifier (diagonal line, no better than coin flipping)</li> <li><strong>AUC &lt; 0.5</strong>: Worse than random (predictions are anticorrelated with truth)</li> </ul> <p>AUC can be interpreted as the probability that the model ranks a random positive example higher than a random negative example.</p> <p>Here's how to compute and plot ROC curves:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>roc_curve</span><span class=p>,</span> <span class=n>roc_auc_score</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>label_binarize</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=c1># For binary classification</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=c1># Get probability predictions instead of hard classifications</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a><span class=n>y_proba</span> <span class=o>=</span> <span class=n>classifier</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a><span class=c1># Compute ROC curve and AUC for each class (one-vs-rest)</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a><span class=n>n_classes</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>y</span><span class=p>))</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a><span class=n>y_test_bin</span> <span class=o>=</span> <span class=n>label_binarize</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>classes</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>y</span><span class=p>))</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a><span class=c1># Plot ROC curve for each class</span>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_classes</span><span class=p>):</span>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a>    <span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>,</span> <span class=n>thresholds</span> <span class=o>=</span> <span class=n>roc_curve</span><span class=p>(</span><span class=n>y_test_bin</span><span class=p>[:,</span> <span class=n>i</span><span class=p>],</span> <span class=n>y_proba</span><span class=p>[:,</span> <span class=n>i</span><span class=p>])</span>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a>    <span class=n>auc</span> <span class=o>=</span> <span class=n>roc_auc_score</span><span class=p>(</span><span class=n>y_test_bin</span><span class=p>[:,</span> <span class=n>i</span><span class=p>],</span> <span class=n>y_proba</span><span class=p>[:,</span> <span class=n>i</span><span class=p>])</span>
</span><span id=__span-8-19><a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a>    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Class </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s1> (AUC = </span><span class=si>{</span><span class=n>auc</span><span class=si>:</span><span class=s1>.3f</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
</span><span id=__span-8-20><a id=__codelineno-8-20 name=__codelineno-8-20 href=#__codelineno-8-20></a>
</span><span id=__span-8-21><a id=__codelineno-8-21 name=__codelineno-8-21 href=#__codelineno-8-21></a><span class=c1># Plot diagonal (random classifier)</span>
</span><span id=__span-8-22><a id=__codelineno-8-22 name=__codelineno-8-22 href=#__codelineno-8-22></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=s1>&#39;k--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Random Classifier&#39;</span><span class=p>)</span>
</span><span id=__span-8-23><a id=__codelineno-8-23 name=__codelineno-8-23 href=#__codelineno-8-23></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;False Positive Rate&#39;</span><span class=p>)</span>
</span><span id=__span-8-24><a id=__codelineno-8-24 name=__codelineno-8-24 href=#__codelineno-8-24></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True Positive Rate (Recall)&#39;</span><span class=p>)</span>
</span><span id=__span-8-25><a id=__codelineno-8-25 name=__codelineno-8-25 href=#__codelineno-8-25></a><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;ROC Curves for Multi-Class Classification&#39;</span><span class=p>)</span>
</span><span id=__span-8-26><a id=__codelineno-8-26 name=__codelineno-8-26 href=#__codelineno-8-26></a><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
</span><span id=__span-8-27><a id=__codelineno-8-27 name=__codelineno-8-27 href=#__codelineno-8-27></a><span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-8-28><a id=__codelineno-8-28 name=__codelineno-8-28 href=#__codelineno-8-28></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <div class="admonition note"> <p class=admonition-title>When to Use ROC/AUC vs. Precision/Recall</p> <ul> <li>Use <strong>ROC/AUC</strong> when classes are balanced and you care equally about both classes</li> <li>Use <strong>Precision/Recall</strong> when classes are imbalanced or when one type of error is more costly than the other</li> <li>In highly imbalanced problems (e.g., fraud detection with 0.1% fraud rate), precision-recall curves are often more informative than ROC curves</li> </ul> </div> <p>Compare ROC curves for different classifier performance levels:</p> <iframe src=../../sims/roc-curve-comparison/roc-curve.html width=100% height=950 frameborder=0></iframe> <h2 id=advanced-optimization-algorithms>Advanced Optimization Algorithms<a class=headerlink href=#advanced-optimization-algorithms title="Permanent link">&para;</a></h2> <p>In Chapter 11, we introduced Stochastic Gradient Descent (SGD) with momentum. While SGD with momentum works well for many problems, modern deep learning relies on more sophisticated optimization algorithms that adapt learning rates during training.</p> <h3 id=adam-optimizer>Adam Optimizer<a class=headerlink href=#adam-optimizer title="Permanent link">&para;</a></h3> <p><strong>Adam</strong> (Adaptive Moment Estimation) is currently the most popular optimizer for deep learning. It combines ideas from momentum and RMSprop, maintaining both:</p> <ol> <li><strong>First moment</strong> (mean) of gradients (like momentum)</li> <li><strong>Second moment</strong> (uncentered variance) of gradients (like RMSprop)</li> </ol> <p>The Adam update rules are:</p> <h4 id=adam-update-equations>Adam Update Equations<a class=headerlink href=#adam-update-equations title="Permanent link">&para;</a></h4> <p><span class=arithmatex>\(m_t = \beta_1 m_{t-1} + (1 - \beta_1) \nabla L(\theta_{t-1})\)</span></p> <p><span class=arithmatex>\(v_t = \beta_2 v_{t-1} + (1 - \beta_2) [\nabla L(\theta_{t-1})]^2\)</span></p> <p><span class=arithmatex>\(\hat{m}_t = \frac{m_t}{1 - \beta_1^t}\)</span></p> <p><span class=arithmatex>\(\hat{v}_t = \frac{v_t}{1 - \beta_2^t}\)</span></p> <p><span class=arithmatex>\(\theta_t = \theta_{t-1} - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}\)</span></p> <p>where:</p> <ul> <li><span class=arithmatex>\(m_t\)</span> is the first moment estimate (exponential moving average of gradients)</li> <li><span class=arithmatex>\(v_t\)</span> is the second moment estimate (exponential moving average of squared gradients)</li> <li><span class=arithmatex>\(\beta_1\)</span> is the decay rate for first moment (typically 0.9)</li> <li><span class=arithmatex>\(\beta_2\)</span> is the decay rate for second moment (typically 0.999)</li> <li><span class=arithmatex>\(\hat{m}_t\)</span> and <span class=arithmatex>\(\hat{v}_t\)</span> are bias-corrected moment estimates</li> <li><span class=arithmatex>\(\eta\)</span> is the learning rate (typically 0.001)</li> <li><span class=arithmatex>\(\epsilon\)</span> is a small constant for numerical stability (typically <span class=arithmatex>\(10^{-8}\)</span>)</li> </ul> <p>Adam's key advantages:</p> <ul> <li><strong>Adaptive learning rates</strong>: Each parameter gets its own learning rate based on gradient history</li> <li><strong>Momentum</strong>: Accelerates convergence like SGD with momentum</li> <li><strong>Robust to hyperparameters</strong>: Works well with default settings across many problems</li> <li><strong>Efficient</strong>: Low memory requirements, computationally efficient</li> </ul> <p>In PyTorch, Adam is the default choice for most applications:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.optim</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>optim</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=c1># Create Adam optimizer</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>,</span> <span class=n>betas</span><span class=o>=</span><span class=p>(</span><span class=mf>0.9</span><span class=p>,</span> <span class=mf>0.999</span><span class=p>))</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a><span class=c1># Training loop</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a><span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>dataloader</span><span class=p>:</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a>    <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a>    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></code></pre></div> <h3 id=rmsprop>RMSprop<a class=headerlink href=#rmsprop title="Permanent link">&para;</a></h3> <p><strong>RMSprop</strong> (Root Mean Square Propagation) adapts learning rates by dividing by a running average of recent gradient magnitudes:</p> <h4 id=rmsprop-update-equations>RMSprop Update Equations<a class=headerlink href=#rmsprop-update-equations title="Permanent link">&para;</a></h4> <p><span class=arithmatex>\(v_t = \beta v_{t-1} + (1 - \beta) [\nabla L(\theta_{t-1})]^2\)</span></p> <p><span class=arithmatex>\(\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{v_t} + \epsilon} \nabla L(\theta_{t-1})\)</span></p> <p>where:</p> <ul> <li><span class=arithmatex>\(v_t\)</span> is the moving average of squared gradients</li> <li><span class=arithmatex>\(\beta\)</span> is the decay rate (typically 0.9)</li> <li><span class=arithmatex>\(\eta\)</span> is the learning rate</li> <li><span class=arithmatex>\(\epsilon\)</span> is a small constant for numerical stability</li> </ul> <p>RMSprop addresses the problem of rapidly diminishing learning rates in Adagrad by using an exponentially decaying average of squared gradients instead of accumulating all past gradients. It works particularly well for recurrent neural networks.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># Create RMSprop optimizer in PyTorch</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>RMSprop</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span>
</span></code></pre></div> <h3 id=nesterov-momentum>Nesterov Momentum<a class=headerlink href=#nesterov-momentum title="Permanent link">&para;</a></h3> <p><strong>Nesterov Accelerated Gradient (NAG)</strong> or <strong>Nesterov momentum</strong> is a variant of standard momentum that often converges faster. The key idea: instead of computing the gradient at the current position, compute it at an approximate future position.</p> <p>Standard momentum update: 1. Compute gradient at current position: <span class=arithmatex>\(\nabla L(\theta_t)\)</span> 2. Update velocity: <span class=arithmatex>\(v_{t+1} = \beta v_t + \nabla L(\theta_t)\)</span> 3. Update parameters: <span class=arithmatex>\(\theta_{t+1} = \theta_t - \eta v_{t+1}\)</span></p> <p>Nesterov momentum update: 1. Look ahead: <span class=arithmatex>\(\theta_{\text{ahead}} = \theta_t - \eta \beta v_t\)</span> 2. Compute gradient at look-ahead position: <span class=arithmatex>\(\nabla L(\theta_{\text{ahead}})\)</span> 3. Update velocity: <span class=arithmatex>\(v_{t+1} = \beta v_t + \nabla L(\theta_{\text{ahead}})\)</span> 4. Update parameters: <span class=arithmatex>\(\theta_{t+1} = \theta_t - \eta v_{t+1}\)</span></p> <p>This "look ahead" often provides better convergence because it corrects course earlier when overshooting:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=c1># SGD with Nesterov momentum in PyTorch</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span> <span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>,</span> <span class=n>nesterov</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></code></pre></div> <h3 id=gradient-clipping>Gradient Clipping<a class=headerlink href=#gradient-clipping title="Permanent link">&para;</a></h3> <p><strong>Gradient clipping</strong> is a technique to prevent exploding gradients, particularly common in recurrent neural networks. When gradients become very large, they can cause numerical instability and make training diverge.</p> <p>Gradient clipping limits gradient magnitude before the optimization step:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a><span class=c1># During training loop, after loss.backward() but before optimizer.step()</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a><span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a><span class=c1># Clip gradients to maximum norm of 1.0</span>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>max_norm</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a>
</span><span id=__span-12-9><a id=__codelineno-12-9 name=__codelineno-12-9 href=#__codelineno-12-9></a><span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></code></pre></div> <p>Two common clipping strategies:</p> <ol> <li><strong>Clip by norm</strong>: Scale gradients so their L2 norm doesn't exceed a threshold</li> <li><strong>Clip by value</strong>: Clamp individual gradient values to a range like [-1, 1]</li> </ol> <p>Gradient clipping is essential for training LSTMs and other recurrent architectures, where gradients can explode exponentially during backpropagation through time.</p> <h2 id=hyperparameter-tuning>Hyperparameter Tuning<a class=headerlink href=#hyperparameter-tuning title="Permanent link">&para;</a></h2> <p><strong>Hyperparameters</strong> are configuration settings that aren't learned from data—learning rate, number of layers, regularization strength, etc. Choosing optimal hyperparameters often makes the difference between mediocre and state-of-the-art performance.</p> <h3 id=grid-search>Grid Search<a class=headerlink href=#grid-search title="Permanent link">&para;</a></h3> <p><strong>Grid search</strong> exhaustively tries all combinations of specified hyperparameter values:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>GridSearchCV</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.svm</span><span class=w> </span><span class=kn>import</span> <span class=n>SVC</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=c1># Define hyperparameter grid</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=n>param_grid</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a>    <span class=s1>&#39;C&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>],</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a>    <span class=s1>&#39;gamma&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.001</span><span class=p>,</span> <span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a>    <span class=s1>&#39;kernel&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=s1>&#39;poly&#39;</span><span class=p>,</span> <span class=s1>&#39;sigmoid&#39;</span><span class=p>]</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a><span class=p>}</span>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a><span class=c1># Create grid search with cross-validation</span>
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a><span class=n>grid_search</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span>
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a>    <span class=n>SVC</span><span class=p>(),</span>
</span><span id=__span-13-14><a id=__codelineno-13-14 name=__codelineno-13-14 href=#__codelineno-13-14></a>    <span class=n>param_grid</span><span class=p>,</span>
</span><span id=__span-13-15><a id=__codelineno-13-15 name=__codelineno-13-15 href=#__codelineno-13-15></a>    <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
</span><span id=__span-13-16><a id=__codelineno-13-16 name=__codelineno-13-16 href=#__codelineno-13-16></a>    <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>,</span>
</span><span id=__span-13-17><a id=__codelineno-13-17 name=__codelineno-13-17 href=#__codelineno-13-17></a>    <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>  <span class=c1># Use all CPU cores</span>
</span><span id=__span-13-18><a id=__codelineno-13-18 name=__codelineno-13-18 href=#__codelineno-13-18></a>    <span class=n>verbose</span><span class=o>=</span><span class=mi>2</span>
</span><span id=__span-13-19><a id=__codelineno-13-19 name=__codelineno-13-19 href=#__codelineno-13-19></a><span class=p>)</span>
</span><span id=__span-13-20><a id=__codelineno-13-20 name=__codelineno-13-20 href=#__codelineno-13-20></a>
</span><span id=__span-13-21><a id=__codelineno-13-21 name=__codelineno-13-21 href=#__codelineno-13-21></a><span class=c1># Fit on training data</span>
</span><span id=__span-13-22><a id=__codelineno-13-22 name=__codelineno-13-22 href=#__codelineno-13-22></a><span class=n>grid_search</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-13-23><a id=__codelineno-13-23 name=__codelineno-13-23 href=#__codelineno-13-23></a>
</span><span id=__span-13-24><a id=__codelineno-13-24 name=__codelineno-13-24 href=#__codelineno-13-24></a><span class=c1># Best parameters and score</span>
</span><span id=__span-13-25><a id=__codelineno-13-25 name=__codelineno-13-25 href=#__codelineno-13-25></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best parameters: </span><span class=si>{</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_params_</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-13-26><a id=__codelineno-13-26 name=__codelineno-13-26 href=#__codelineno-13-26></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best cross-validation score: </span><span class=si>{</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_score_</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-13-27><a id=__codelineno-13-27 name=__codelineno-13-27 href=#__codelineno-13-27></a>
</span><span id=__span-13-28><a id=__codelineno-13-28 name=__codelineno-13-28 href=#__codelineno-13-28></a><span class=c1># Use best model</span>
</span><span id=__span-13-29><a id=__codelineno-13-29 name=__codelineno-13-29 href=#__codelineno-13-29></a><span class=n>best_model</span> <span class=o>=</span> <span class=n>grid_search</span><span class=o>.</span><span class=n>best_estimator_</span>
</span></code></pre></div> <p>In this example, grid search evaluates 4 × 4 × 3 = 48 hyperparameter combinations, using 5-fold cross-validation for each—a total of 240 model training runs! The <code>n_jobs=-1</code> parameter parallelizes these runs across all CPU cores.</p> <p><strong>Advantages of grid search:</strong> - Guaranteed to find the best combination within the specified grid - Simple and easy to understand - Embarrassingly parallel (each combination can be evaluated independently)</p> <p><strong>Disadvantages:</strong> - Computationally expensive (exponential in number of hyperparameters) - Wastes computation on unlikely combinations - Requires prior knowledge to define reasonable ranges</p> <h3 id=random-search>Random Search<a class=headerlink href=#random-search title="Permanent link">&para;</a></h3> <p><strong>Random search</strong> samples hyperparameter combinations randomly from specified distributions:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>RandomizedSearchCV</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>uniform</span><span class=p>,</span> <span class=n>randint</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a><span class=c1># Define hyperparameter distributions</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a><span class=n>param_distributions</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a>    <span class=s1>&#39;C&#39;</span><span class=p>:</span> <span class=n>uniform</span><span class=p>(</span><span class=mf>0.1</span><span class=p>,</span> <span class=mi>100</span><span class=p>),</span>  <span class=c1># Uniform distribution from 0.1 to 100.1</span>
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a>    <span class=s1>&#39;gamma&#39;</span><span class=p>:</span> <span class=n>uniform</span><span class=p>(</span><span class=mf>0.001</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>  <span class=c1># Uniform distribution from 0.001 to 1.001</span>
</span><span id=__span-14-8><a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a>    <span class=s1>&#39;kernel&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=s1>&#39;poly&#39;</span><span class=p>,</span> <span class=s1>&#39;sigmoid&#39;</span><span class=p>]</span>
</span><span id=__span-14-9><a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a><span class=p>}</span>
</span><span id=__span-14-10><a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a>
</span><span id=__span-14-11><a id=__codelineno-14-11 name=__codelineno-14-11 href=#__codelineno-14-11></a><span class=c1># Create random search</span>
</span><span id=__span-14-12><a id=__codelineno-14-12 name=__codelineno-14-12 href=#__codelineno-14-12></a><span class=n>random_search</span> <span class=o>=</span> <span class=n>RandomizedSearchCV</span><span class=p>(</span>
</span><span id=__span-14-13><a id=__codelineno-14-13 name=__codelineno-14-13 href=#__codelineno-14-13></a>    <span class=n>SVC</span><span class=p>(),</span>
</span><span id=__span-14-14><a id=__codelineno-14-14 name=__codelineno-14-14 href=#__codelineno-14-14></a>    <span class=n>param_distributions</span><span class=p>,</span>
</span><span id=__span-14-15><a id=__codelineno-14-15 name=__codelineno-14-15 href=#__codelineno-14-15></a>    <span class=n>n_iter</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span>  <span class=c1># Number of random combinations to try</span>
</span><span id=__span-14-16><a id=__codelineno-14-16 name=__codelineno-14-16 href=#__codelineno-14-16></a>    <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
</span><span id=__span-14-17><a id=__codelineno-14-17 name=__codelineno-14-17 href=#__codelineno-14-17></a>    <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>,</span>
</span><span id=__span-14-18><a id=__codelineno-14-18 name=__codelineno-14-18 href=#__codelineno-14-18></a>    <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>
</span><span id=__span-14-19><a id=__codelineno-14-19 name=__codelineno-14-19 href=#__codelineno-14-19></a>    <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span>
</span><span id=__span-14-20><a id=__codelineno-14-20 name=__codelineno-14-20 href=#__codelineno-14-20></a>    <span class=n>verbose</span><span class=o>=</span><span class=mi>2</span>
</span><span id=__span-14-21><a id=__codelineno-14-21 name=__codelineno-14-21 href=#__codelineno-14-21></a><span class=p>)</span>
</span><span id=__span-14-22><a id=__codelineno-14-22 name=__codelineno-14-22 href=#__codelineno-14-22></a>
</span><span id=__span-14-23><a id=__codelineno-14-23 name=__codelineno-14-23 href=#__codelineno-14-23></a><span class=c1># Fit on training data</span>
</span><span id=__span-14-24><a id=__codelineno-14-24 name=__codelineno-14-24 href=#__codelineno-14-24></a><span class=n>random_search</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-14-25><a id=__codelineno-14-25 name=__codelineno-14-25 href=#__codelineno-14-25></a>
</span><span id=__span-14-26><a id=__codelineno-14-26 name=__codelineno-14-26 href=#__codelineno-14-26></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best parameters: </span><span class=si>{</span><span class=n>random_search</span><span class=o>.</span><span class=n>best_params_</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-14-27><a id=__codelineno-14-27 name=__codelineno-14-27 href=#__codelineno-14-27></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best score: </span><span class=si>{</span><span class=n>random_search</span><span class=o>.</span><span class=n>best_score_</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>Random search tries 50 random combinations instead of all 48 systematic combinations from grid search. Surprisingly, research shows random search often performs as well as or better than grid search with far fewer evaluations.</p> <p><strong>Why does random search work?</strong></p> <ul> <li>Not all hyperparameters matter equally; random search explores important dimensions more densely</li> <li>Can explore a wider range without exponential cost</li> <li>Better at finding global optima when search space is large</li> </ul> <p><strong>Advantages:</strong> - More efficient than grid search for high-dimensional spaces - Can specify continuous distributions instead of discrete values - Easy to parallelize</p> <p><strong>Disadvantages:</strong> - No guarantee of finding the absolute best combination - Results vary with random seed (though this also helps explore the space)</p> <h3 id=bayesian-optimization>Bayesian Optimization<a class=headerlink href=#bayesian-optimization title="Permanent link">&para;</a></h3> <p><strong>Bayesian optimization</strong> is a more sophisticated approach that builds a probabilistic model of the objective function (e.g., validation accuracy as a function of hyperparameters) and uses it to select the most promising hyperparameters to evaluate next.</p> <p>The algorithm works as follows:</p> <ol> <li>Evaluate a few random hyperparameter configurations</li> <li>Fit a probabilistic model (typically a Gaussian Process) to observed results</li> <li>Use an <strong>acquisition function</strong> to select the next hyperparameter configuration that balances:</li> <li><strong>Exploitation</strong>: Try hyperparameters expected to perform well based on the model</li> <li><strong>Exploration</strong>: Try hyperparameters in unexplored regions with high uncertainty</li> <li>Evaluate the selected configuration and update the model</li> <li>Repeat steps 3-4 until budget exhausted</li> </ol> <p>Popular libraries for Bayesian optimization include Optuna, Hyperopt, and Scikit-Optimize. Here's an example with Optuna:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=kn>import</span><span class=w> </span><span class=nn>optuna</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.svm</span><span class=w> </span><span class=kn>import</span> <span class=n>SVC</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>cross_val_score</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a><span class=k>def</span><span class=w> </span><span class=nf>objective</span><span class=p>(</span><span class=n>trial</span><span class=p>):</span>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a>    <span class=c1># Suggest hyperparameters</span>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a>    <span class=n>C</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_float</span><span class=p>(</span><span class=s1>&#39;C&#39;</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=n>log</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-15-8><a id=__codelineno-15-8 name=__codelineno-15-8 href=#__codelineno-15-8></a>    <span class=n>gamma</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_float</span><span class=p>(</span><span class=s1>&#39;gamma&#39;</span><span class=p>,</span> <span class=mf>0.001</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>log</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-15-9><a id=__codelineno-15-9 name=__codelineno-15-9 href=#__codelineno-15-9></a>    <span class=n>kernel</span> <span class=o>=</span> <span class=n>trial</span><span class=o>.</span><span class=n>suggest_categorical</span><span class=p>(</span><span class=s1>&#39;kernel&#39;</span><span class=p>,</span> <span class=p>[</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=s1>&#39;poly&#39;</span><span class=p>,</span> <span class=s1>&#39;sigmoid&#39;</span><span class=p>])</span>
</span><span id=__span-15-10><a id=__codelineno-15-10 name=__codelineno-15-10 href=#__codelineno-15-10></a>
</span><span id=__span-15-11><a id=__codelineno-15-11 name=__codelineno-15-11 href=#__codelineno-15-11></a>    <span class=c1># Create and evaluate model</span>
</span><span id=__span-15-12><a id=__codelineno-15-12 name=__codelineno-15-12 href=#__codelineno-15-12></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>SVC</span><span class=p>(</span><span class=n>C</span><span class=o>=</span><span class=n>C</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=n>gamma</span><span class=p>,</span> <span class=n>kernel</span><span class=o>=</span><span class=n>kernel</span><span class=p>)</span>
</span><span id=__span-15-13><a id=__codelineno-15-13 name=__codelineno-15-13 href=#__codelineno-15-13></a>    <span class=n>score</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span><span id=__span-15-14><a id=__codelineno-15-14 name=__codelineno-15-14 href=#__codelineno-15-14></a>
</span><span id=__span-15-15><a id=__codelineno-15-15 name=__codelineno-15-15 href=#__codelineno-15-15></a>    <span class=k>return</span> <span class=n>score</span>
</span><span id=__span-15-16><a id=__codelineno-15-16 name=__codelineno-15-16 href=#__codelineno-15-16></a>
</span><span id=__span-15-17><a id=__codelineno-15-17 name=__codelineno-15-17 href=#__codelineno-15-17></a><span class=c1># Create study and optimize</span>
</span><span id=__span-15-18><a id=__codelineno-15-18 name=__codelineno-15-18 href=#__codelineno-15-18></a><span class=n>study</span> <span class=o>=</span> <span class=n>optuna</span><span class=o>.</span><span class=n>create_study</span><span class=p>(</span><span class=n>direction</span><span class=o>=</span><span class=s1>&#39;maximize&#39;</span><span class=p>)</span>
</span><span id=__span-15-19><a id=__codelineno-15-19 name=__codelineno-15-19 href=#__codelineno-15-19></a><span class=n>study</span><span class=o>.</span><span class=n>optimize</span><span class=p>(</span><span class=n>objective</span><span class=p>,</span> <span class=n>n_trials</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span><span id=__span-15-20><a id=__codelineno-15-20 name=__codelineno-15-20 href=#__codelineno-15-20></a>
</span><span id=__span-15-21><a id=__codelineno-15-21 name=__codelineno-15-21 href=#__codelineno-15-21></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best parameters: </span><span class=si>{</span><span class=n>study</span><span class=o>.</span><span class=n>best_params</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-15-22><a id=__codelineno-15-22 name=__codelineno-15-22 href=#__codelineno-15-22></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best score: </span><span class=si>{</span><span class=n>study</span><span class=o>.</span><span class=n>best_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Advantages of Bayesian optimization:</strong> - More sample-efficient than random or grid search - Principled approach to exploration-exploitation tradeoff - Can handle expensive black-box functions (e.g., training deep neural networks) - Often finds better hyperparameters with fewer evaluations</p> <p><strong>Disadvantages:</strong> - More complex to implement and understand - Computational overhead of fitting probabilistic models - Less parallelizable than grid/random search (next evaluation depends on previous results)</p> <h2 id=model-selection-choosing-the-right-algorithm>Model Selection: Choosing the Right Algorithm<a class=headerlink href=#model-selection-choosing-the-right-algorithm title="Permanent link">&para;</a></h2> <p><strong>Model selection</strong> involves choosing not just hyperparameters, but the entire class of model (linear regression vs. neural network vs. decision tree, etc.). This decision should be based on:</p> <p><strong>Problem characteristics:</strong></p> <ul> <li><strong>Data size</strong>: Deep learning requires large datasets; linear models work with smaller data</li> <li><strong>Feature relationships</strong>: Non-linear models for complex relationships, linear for simple patterns</li> <li><strong>Interpretability requirements</strong>: Decision trees and linear models are more interpretable than neural networks</li> <li><strong>Computational constraints</strong>: Simple models train faster; complex models may need GPU acceleration</li> </ul> <p><strong>Systematic model selection process:</strong></p> <ol> <li><strong>Establish baseline</strong>: Start with a simple model (e.g., logistic regression, decision tree)</li> <li><strong>Iterate</strong>: Try progressively more complex models (random forests, gradient boosting, neural networks)</li> <li><strong>Compare rigorously</strong>: Use same train/test splits and evaluation metrics across all models</li> <li><strong>Consider ensembles</strong>: Combine multiple models for better performance</li> <li><strong>Validate on held-out test set</strong>: Only evaluate final model on test set (avoid overfitting to validation set)</li> </ol> <p>Let's compare multiple algorithms systematically:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>LogisticRegression</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.tree</span><span class=w> </span><span class=kn>import</span> <span class=n>DecisionTreeClassifier</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.ensemble</span><span class=w> </span><span class=kn>import</span> <span class=n>RandomForestClassifier</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.svm</span><span class=w> </span><span class=kn>import</span> <span class=n>SVC</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.neighbors</span><span class=w> </span><span class=kn>import</span> <span class=n>KNeighborsClassifier</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>cross_val_score</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a><span class=c1># Define models to compare</span>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a><span class=n>models</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a>    <span class=s1>&#39;Logistic Regression&#39;</span><span class=p>:</span> <span class=n>LogisticRegression</span><span class=p>(</span><span class=n>max_iter</span><span class=o>=</span><span class=mi>1000</span><span class=p>),</span>
</span><span id=__span-16-11><a id=__codelineno-16-11 name=__codelineno-16-11 href=#__codelineno-16-11></a>    <span class=s1>&#39;Decision Tree&#39;</span><span class=p>:</span> <span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>max_depth</span><span class=o>=</span><span class=mi>5</span><span class=p>),</span>
</span><span id=__span-16-12><a id=__codelineno-16-12 name=__codelineno-16-12 href=#__codelineno-16-12></a>    <span class=s1>&#39;Random Forest&#39;</span><span class=p>:</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>n_estimators</span><span class=o>=</span><span class=mi>100</span><span class=p>),</span>
</span><span id=__span-16-13><a id=__codelineno-16-13 name=__codelineno-16-13 href=#__codelineno-16-13></a>    <span class=s1>&#39;SVM (RBF)&#39;</span><span class=p>:</span> <span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=s1>&#39;scale&#39;</span><span class=p>),</span>
</span><span id=__span-16-14><a id=__codelineno-16-14 name=__codelineno-16-14 href=#__codelineno-16-14></a>    <span class=s1>&#39;K-Nearest Neighbors&#39;</span><span class=p>:</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span><span id=__span-16-15><a id=__codelineno-16-15 name=__codelineno-16-15 href=#__codelineno-16-15></a><span class=p>}</span>
</span><span id=__span-16-16><a id=__codelineno-16-16 name=__codelineno-16-16 href=#__codelineno-16-16></a>
</span><span id=__span-16-17><a id=__codelineno-16-17 name=__codelineno-16-17 href=#__codelineno-16-17></a><span class=c1># Evaluate each model with cross-validation</span>
</span><span id=__span-16-18><a id=__codelineno-16-18 name=__codelineno-16-18 href=#__codelineno-16-18></a><span class=n>results</span> <span class=o>=</span> <span class=p>{}</span>
</span><span id=__span-16-19><a id=__codelineno-16-19 name=__codelineno-16-19 href=#__codelineno-16-19></a><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>model</span> <span class=ow>in</span> <span class=n>models</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span><span id=__span-16-20><a id=__codelineno-16-20 name=__codelineno-16-20 href=#__codelineno-16-20></a>    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>)</span>
</span><span id=__span-16-21><a id=__codelineno-16-21 name=__codelineno-16-21 href=#__codelineno-16-21></a>    <span class=n>results</span><span class=p>[</span><span class=n>name</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-16-22><a id=__codelineno-16-22 name=__codelineno-16-22 href=#__codelineno-16-22></a>        <span class=s1>&#39;mean&#39;</span><span class=p>:</span> <span class=n>scores</span><span class=o>.</span><span class=n>mean</span><span class=p>(),</span>
</span><span id=__span-16-23><a id=__codelineno-16-23 name=__codelineno-16-23 href=#__codelineno-16-23></a>        <span class=s1>&#39;std&#39;</span><span class=p>:</span> <span class=n>scores</span><span class=o>.</span><span class=n>std</span><span class=p>()</span>
</span><span id=__span-16-24><a id=__codelineno-16-24 name=__codelineno-16-24 href=#__codelineno-16-24></a>    <span class=p>}</span>
</span><span id=__span-16-25><a id=__codelineno-16-25 name=__codelineno-16-25 href=#__codelineno-16-25></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>scores</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2> (+/- </span><span class=si>{</span><span class=n>scores</span><span class=o>.</span><span class=n>std</span><span class=p>()</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>2</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
</span><span id=__span-16-26><a id=__codelineno-16-26 name=__codelineno-16-26 href=#__codelineno-16-26></a>
</span><span id=__span-16-27><a id=__codelineno-16-27 name=__codelineno-16-27 href=#__codelineno-16-27></a><span class=c1># Select best model</span>
</span><span id=__span-16-28><a id=__codelineno-16-28 name=__codelineno-16-28 href=#__codelineno-16-28></a><span class=n>best_model_name</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>results</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>results</span><span class=p>[</span><span class=n>x</span><span class=p>][</span><span class=s1>&#39;mean&#39;</span><span class=p>])</span>
</span><span id=__span-16-29><a id=__codelineno-16-29 name=__codelineno-16-29 href=#__codelineno-16-29></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Best model: </span><span class=si>{</span><span class=n>best_model_name</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <div class="admonition warning"> <p class=admonition-title>The Test Set is Sacred</p> <p>Never tune hyperparameters or select models based on test set performance. This leads to overfitting to the test set, producing optimistically biased performance estimates. Always use a separate validation set (or cross-validation on the training set) for model selection, reserving the test set only for final evaluation of the chosen model.</p> </div> <h4 id=hyperparameter-tuning-workflow>Hyperparameter Tuning Workflow<a class=headerlink href=#hyperparameter-tuning-workflow title="Permanent link">&para;</a></h4> <pre class=mermaid><code>flowchart TD
    Start(("Full Dataset"))
    Split["Split Data&lt;br/&gt;(Train 60%, Val 20%, Test 20%)"]
    Strategy{"Choose Tuning&lt;br/&gt;Strategy"}
    Grid["Grid Search&lt;br/&gt;(2-3 hyperparameters)"]
    Random["Random Search&lt;br/&gt;(4-6 hyperparameters)"]
    Bayesian["Bayesian Optimization&lt;br/&gt;(expensive models)"]
    CV["Cross-Validation&lt;br/&gt;on Training Set"]
    Track["Track Performance&lt;br/&gt;(record scores)"]
    Budget{"Budget&lt;br/&gt;Exhausted?"}
    Select["Select Best Configuration&lt;br/&gt;(highest mean CV score)"]
    Retrain["Retrain on Full Training Set&lt;br/&gt;(using best hyperparams)"]
    ValEval["Evaluate on Validation Set&lt;br/&gt;(sanity check)"]
    CheckPerf{"Performance&lt;br/&gt;Acceptable?"}
    Adjust["Adjust Strategy&lt;br/&gt;(try different model)"]
    Final["Final Evaluation on Test Set&lt;br/&gt;(TRUE performance estimate)"]

    Start --&gt; Split
    Split --&gt; Strategy
    Strategy --&gt; Grid
    Strategy --&gt; Random
    Strategy --&gt; Bayesian
    Grid --&gt; CV
    Random --&gt; CV
    Bayesian --&gt; CV
    CV --&gt; Track
    Track --&gt; Budget
    Budget --&gt;|No| Strategy
    Budget --&gt;|Yes| Select
    Select --&gt; Retrain
    Retrain --&gt; ValEval
    ValEval --&gt; CheckPerf
    CheckPerf --&gt;|No| Adjust
    Adjust --&gt; Strategy
    CheckPerf --&gt;|Yes| Final

    classDef dataNode fill:#4299e1,stroke:#2c5282,stroke-width:2px,color:#fff,font-size:14px
    classDef searchNode fill:#9f7aea,stroke:#6b46c1,stroke-width:2px,color:#fff,font-size:14px
    classDef evalNode fill:#48bb78,stroke:#2f855a,stroke-width:2px,color:#fff,font-size:14px
    classDef decisionNode fill:#ecc94b,stroke:#b7791f,stroke-width:2px,color:#333,font-size:14px
    classDef finalNode fill:#ed8936,stroke:#c05621,stroke-width:2px,color:#fff,font-size:14px

    class Start,Split dataNode
    class Grid,Random,Bayesian,CV,Track,Retrain searchNode
    class ValEval,Final evalNode
    class Strategy,Budget,CheckPerf decisionNode
    class Adjust finalNode

    linkStyle default stroke:#666,stroke-width:2px,font-size:12px</code></pre> <p><strong>Key Points</strong>: (1) Test set used ONLY once at the end, (2) Cross-validation performed on training set only, (3) Multiple tuning strategies available based on search space size</p> <ol> <li>End: "Report Test Performance" Hover text: "Test accuracy is the unbiased estimate of real-world performance"</li> </ol> <p>Color coding: - Blue: Data preparation - Green: Hyperparameter search - Purple: Cross-validation - Yellow: Decision points - Red: Final evaluation (test set) - Orange: Adjustments/iterations</p> <p>Swimlanes: - Data Management - Hyperparameter Search - Model Training - Evaluation</p> <p>Annotations: - Warning icon on test set: "Use only once for final evaluation!" - Best practice note: "Never tune hyperparameters based on test set" - Typical timeline: "Grid search: hours-days. Random search: hours. Bayesian: hours (fewer iterations needed)"</p> <p>Implementation: Mermaid.js or D3.js flowchart Canvas size: Responsive, minimum 800×1000px </details></p> <h2 id=putting-it-all-together-a-complete-evaluation-pipeline>Putting It All Together: A Complete Evaluation Pipeline<a class=headerlink href=#putting-it-all-together-a-complete-evaluation-pipeline title="Permanent link">&para;</a></h2> <p>Let's synthesize everything we've learned into a complete machine learning evaluation pipeline:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span><span class=p>,</span> <span class=n>GridSearchCV</span><span class=p>,</span> <span class=n>cross_val_score</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.svm</span><span class=w> </span><span class=kn>import</span> <span class=n>SVC</span>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>classification_report</span><span class=p>,</span> <span class=n>confusion_matrix</span><span class=p>,</span> <span class=n>roc_auc_score</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a><span class=c1># Step 1: Split data into train/validation/test</span>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a><span class=c1># First split: 80% train+val, 20% test</span>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a><span class=n>X_temp</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_temp</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a>    <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a><span class=p>)</span>
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a>
</span><span id=__span-17-13><a id=__codelineno-17-13 name=__codelineno-17-13 href=#__codelineno-17-13></a><span class=c1># Second split: 75% train, 25% validation (of the 80%)</span>
</span><span id=__span-17-14><a id=__codelineno-17-14 name=__codelineno-17-14 href=#__codelineno-17-14></a><span class=n>X_train</span><span class=p>,</span> <span class=n>X_val</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_val</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
</span><span id=__span-17-15><a id=__codelineno-17-15 name=__codelineno-17-15 href=#__codelineno-17-15></a>    <span class=n>X_temp</span><span class=p>,</span> <span class=n>y_temp</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.25</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y_temp</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>
</span><span id=__span-17-16><a id=__codelineno-17-16 name=__codelineno-17-16 href=#__codelineno-17-16></a><span class=p>)</span>
</span><span id=__span-17-17><a id=__codelineno-17-17 name=__codelineno-17-17 href=#__codelineno-17-17></a>
</span><span id=__span-17-18><a id=__codelineno-17-18 name=__codelineno-17-18 href=#__codelineno-17-18></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Training set size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-19><a id=__codelineno-17-19 name=__codelineno-17-19 href=#__codelineno-17-19></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Validation set size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>X_val</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-20><a id=__codelineno-17-20 name=__codelineno-17-20 href=#__codelineno-17-20></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test set size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-21><a id=__codelineno-17-21 name=__codelineno-17-21 href=#__codelineno-17-21></a>
</span><span id=__span-17-22><a id=__codelineno-17-22 name=__codelineno-17-22 href=#__codelineno-17-22></a><span class=c1># Step 2: Preprocessing (fit on training set only!)</span>
</span><span id=__span-17-23><a id=__codelineno-17-23 name=__codelineno-17-23 href=#__codelineno-17-23></a><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span><span id=__span-17-24><a id=__codelineno-17-24 name=__codelineno-17-24 href=#__codelineno-17-24></a><span class=n>X_train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
</span><span id=__span-17-25><a id=__codelineno-17-25 name=__codelineno-17-25 href=#__codelineno-17-25></a><span class=n>X_val_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_val</span><span class=p>)</span>
</span><span id=__span-17-26><a id=__codelineno-17-26 name=__codelineno-17-26 href=#__codelineno-17-26></a><span class=n>X_test_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span><span id=__span-17-27><a id=__codelineno-17-27 name=__codelineno-17-27 href=#__codelineno-17-27></a>
</span><span id=__span-17-28><a id=__codelineno-17-28 name=__codelineno-17-28 href=#__codelineno-17-28></a><span class=c1># Step 3: Hyperparameter tuning with grid search and cross-validation</span>
</span><span id=__span-17-29><a id=__codelineno-17-29 name=__codelineno-17-29 href=#__codelineno-17-29></a><span class=n>param_grid</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-17-30><a id=__codelineno-17-30 name=__codelineno-17-30 href=#__codelineno-17-30></a>    <span class=s1>&#39;C&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>],</span>
</span><span id=__span-17-31><a id=__codelineno-17-31 name=__codelineno-17-31 href=#__codelineno-17-31></a>    <span class=s1>&#39;gamma&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;scale&#39;</span><span class=p>,</span> <span class=s1>&#39;auto&#39;</span><span class=p>,</span> <span class=mf>0.001</span><span class=p>,</span> <span class=mf>0.01</span><span class=p>],</span>
</span><span id=__span-17-32><a id=__codelineno-17-32 name=__codelineno-17-32 href=#__codelineno-17-32></a>    <span class=s1>&#39;kernel&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=s1>&#39;poly&#39;</span><span class=p>]</span>
</span><span id=__span-17-33><a id=__codelineno-17-33 name=__codelineno-17-33 href=#__codelineno-17-33></a><span class=p>}</span>
</span><span id=__span-17-34><a id=__codelineno-17-34 name=__codelineno-17-34 href=#__codelineno-17-34></a>
</span><span id=__span-17-35><a id=__codelineno-17-35 name=__codelineno-17-35 href=#__codelineno-17-35></a><span class=n>grid_search</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span>
</span><span id=__span-17-36><a id=__codelineno-17-36 name=__codelineno-17-36 href=#__codelineno-17-36></a>    <span class=n>SVC</span><span class=p>(</span><span class=n>probability</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>  <span class=c1># Enable probability estimates for ROC curve</span>
</span><span id=__span-17-37><a id=__codelineno-17-37 name=__codelineno-17-37 href=#__codelineno-17-37></a>    <span class=n>param_grid</span><span class=p>,</span>
</span><span id=__span-17-38><a id=__codelineno-17-38 name=__codelineno-17-38 href=#__codelineno-17-38></a>    <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
</span><span id=__span-17-39><a id=__codelineno-17-39 name=__codelineno-17-39 href=#__codelineno-17-39></a>    <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>,</span>
</span><span id=__span-17-40><a id=__codelineno-17-40 name=__codelineno-17-40 href=#__codelineno-17-40></a>    <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>
</span><span id=__span-17-41><a id=__codelineno-17-41 name=__codelineno-17-41 href=#__codelineno-17-41></a>    <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span>
</span><span id=__span-17-42><a id=__codelineno-17-42 name=__codelineno-17-42 href=#__codelineno-17-42></a><span class=p>)</span>
</span><span id=__span-17-43><a id=__codelineno-17-43 name=__codelineno-17-43 href=#__codelineno-17-43></a>
</span><span id=__span-17-44><a id=__codelineno-17-44 name=__codelineno-17-44 href=#__codelineno-17-44></a><span class=n>grid_search</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
</span><span id=__span-17-45><a id=__codelineno-17-45 name=__codelineno-17-45 href=#__codelineno-17-45></a>
</span><span id=__span-17-46><a id=__codelineno-17-46 name=__codelineno-17-46 href=#__codelineno-17-46></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Best hyperparameters: </span><span class=si>{</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_params_</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-47><a id=__codelineno-17-47 name=__codelineno-17-47 href=#__codelineno-17-47></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best cross-validation accuracy: </span><span class=si>{</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_score_</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-48><a id=__codelineno-17-48 name=__codelineno-17-48 href=#__codelineno-17-48></a>
</span><span id=__span-17-49><a id=__codelineno-17-49 name=__codelineno-17-49 href=#__codelineno-17-49></a><span class=c1># Step 4: Evaluate on validation set</span>
</span><span id=__span-17-50><a id=__codelineno-17-50 name=__codelineno-17-50 href=#__codelineno-17-50></a><span class=n>best_model</span> <span class=o>=</span> <span class=n>grid_search</span><span class=o>.</span><span class=n>best_estimator_</span>
</span><span id=__span-17-51><a id=__codelineno-17-51 name=__codelineno-17-51 href=#__codelineno-17-51></a><span class=n>y_val_pred</span> <span class=o>=</span> <span class=n>best_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_val_scaled</span><span class=p>)</span>
</span><span id=__span-17-52><a id=__codelineno-17-52 name=__codelineno-17-52 href=#__codelineno-17-52></a><span class=n>val_accuracy</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_val</span><span class=p>,</span> <span class=n>y_val_pred</span><span class=p>)</span>
</span><span id=__span-17-53><a id=__codelineno-17-53 name=__codelineno-17-53 href=#__codelineno-17-53></a>
</span><span id=__span-17-54><a id=__codelineno-17-54 name=__codelineno-17-54 href=#__codelineno-17-54></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Validation set accuracy: </span><span class=si>{</span><span class=n>val_accuracy</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-55><a id=__codelineno-17-55 name=__codelineno-17-55 href=#__codelineno-17-55></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Validation Set Classification Report:&quot;</span><span class=p>)</span>
</span><span id=__span-17-56><a id=__codelineno-17-56 name=__codelineno-17-56 href=#__codelineno-17-56></a><span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_val</span><span class=p>,</span> <span class=n>y_val_pred</span><span class=p>))</span>
</span><span id=__span-17-57><a id=__codelineno-17-57 name=__codelineno-17-57 href=#__codelineno-17-57></a>
</span><span id=__span-17-58><a id=__codelineno-17-58 name=__codelineno-17-58 href=#__codelineno-17-58></a><span class=c1># Step 5: Final evaluation on test set (use only once!)</span>
</span><span id=__span-17-59><a id=__codelineno-17-59 name=__codelineno-17-59 href=#__codelineno-17-59></a><span class=n>y_test_pred</span> <span class=o>=</span> <span class=n>best_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>)</span>
</span><span id=__span-17-60><a id=__codelineno-17-60 name=__codelineno-17-60 href=#__codelineno-17-60></a><span class=n>test_accuracy</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_test_pred</span><span class=p>)</span>
</span><span id=__span-17-61><a id=__codelineno-17-61 name=__codelineno-17-61 href=#__codelineno-17-61></a>
</span><span id=__span-17-62><a id=__codelineno-17-62 name=__codelineno-17-62 href=#__codelineno-17-62></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>60</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-63><a id=__codelineno-17-63 name=__codelineno-17-63 href=#__codelineno-17-63></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;FINAL TEST SET PERFORMANCE&quot;</span><span class=p>)</span>
</span><span id=__span-17-64><a id=__codelineno-17-64 name=__codelineno-17-64 href=#__codelineno-17-64></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>60</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-65><a id=__codelineno-17-65 name=__codelineno-17-65 href=#__codelineno-17-65></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test Accuracy: </span><span class=si>{</span><span class=n>test_accuracy</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-66><a id=__codelineno-17-66 name=__codelineno-17-66 href=#__codelineno-17-66></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Confusion Matrix:&quot;</span><span class=p>)</span>
</span><span id=__span-17-67><a id=__codelineno-17-67 name=__codelineno-17-67 href=#__codelineno-17-67></a><span class=nb>print</span><span class=p>(</span><span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_test_pred</span><span class=p>))</span>
</span><span id=__span-17-68><a id=__codelineno-17-68 name=__codelineno-17-68 href=#__codelineno-17-68></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Classification Report:&quot;</span><span class=p>)</span>
</span><span id=__span-17-69><a id=__codelineno-17-69 name=__codelineno-17-69 href=#__codelineno-17-69></a><span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_test_pred</span><span class=p>))</span>
</span><span id=__span-17-70><a id=__codelineno-17-70 name=__codelineno-17-70 href=#__codelineno-17-70></a>
</span><span id=__span-17-71><a id=__codelineno-17-71 name=__codelineno-17-71 href=#__codelineno-17-71></a><span class=c1># Compute ROC AUC if binary classification</span>
</span><span id=__span-17-72><a id=__codelineno-17-72 name=__codelineno-17-72 href=#__codelineno-17-72></a><span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>y</span><span class=p>))</span> <span class=o>==</span> <span class=mi>2</span><span class=p>:</span>
</span><span id=__span-17-73><a id=__codelineno-17-73 name=__codelineno-17-73 href=#__codelineno-17-73></a>    <span class=n>y_test_proba</span> <span class=o>=</span> <span class=n>best_model</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>)[:,</span> <span class=mi>1</span><span class=p>]</span>
</span><span id=__span-17-74><a id=__codelineno-17-74 name=__codelineno-17-74 href=#__codelineno-17-74></a>    <span class=n>test_auc</span> <span class=o>=</span> <span class=n>roc_auc_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_test_proba</span><span class=p>)</span>
</span><span id=__span-17-75><a id=__codelineno-17-75 name=__codelineno-17-75 href=#__codelineno-17-75></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Test AUC-ROC: </span><span class=si>{</span><span class=n>test_auc</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p>This pipeline demonstrates best practices:</p> <ol> <li>✓ Proper train/validation/test split with stratification</li> <li>✓ Preprocessing fitted on training data only</li> <li>✓ Hyperparameter tuning via cross-validation on training set</li> <li>✓ Validation set used to catch overfitting before final evaluation</li> <li>✓ Test set used only once for final, unbiased performance estimate</li> <li>✓ Comprehensive metrics: accuracy, precision, recall, F1, confusion matrix, AUC</li> </ol> <h2 id=common-pitfalls-and-how-to-avoid-them>Common Pitfalls and How to Avoid Them<a class=headerlink href=#common-pitfalls-and-how-to-avoid-them title="Permanent link">&para;</a></h2> <p>Even experienced practitioners make evaluation mistakes. Here are the most common pitfalls:</p> <p><strong>Pitfall 1: Data leakage</strong></p> <p>Data leakage occurs when information from outside the training set influences the model, leading to overly optimistic performance estimates.</p> <p>Common sources: - Fitting preprocessors (scalers, imputers) on the entire dataset before splitting - Including future information in time-series prediction - Using the test set for feature selection or hyperparameter tuning</p> <p><strong>Prevention</strong>: Always split data first, then fit all preprocessing only on training data.</p> <p><strong>Pitfall 2: Imbalanced class evaluation</strong></p> <p>Using accuracy on imbalanced datasets (e.g., 95% class A, 5% class B) is misleading. A model that always predicts class A achieves 95% accuracy despite being useless.</p> <p><strong>Prevention</strong>: Use precision, recall, F1-score, or AUC instead of accuracy for imbalanced problems. Consider resampling techniques (oversampling minority class or undersampling majority class).</p> <p><strong>Pitfall 3: Not using stratified splits</strong></p> <p>Random train/test splits on imbalanced or small datasets can produce unrepresentative splits.</p> <p><strong>Prevention</strong>: Always use <code>stratify=y</code> in <code>train_test_split</code> for classification tasks.</p> <p><strong>Pitfall 4: Repeated use of test set</strong></p> <p>Evaluating multiple models on the test set and selecting the best one essentially turns the test set into a validation set, causing overfitting.</p> <p><strong>Prevention</strong>: Use cross-validation or a separate validation set for model selection. Touch the test set only once for final evaluation.</p> <p><strong>Pitfall 5: Ignoring confidence intervals</strong></p> <p>Reporting a single accuracy number (e.g., "95% accurate") without confidence intervals can be misleading. Different random splits may yield significantly different results.</p> <p><strong>Prevention</strong>: Report standard deviation from cross-validation: "95% ± 2% accuracy".</p> <p><strong>Pitfall 6: Wrong metrics for the problem</strong></p> <p>Using precision when you need recall (or vice versa) leads to optimizing the wrong objective.</p> <p><strong>Prevention</strong>: Understand your problem's cost function. For medical diagnosis, high recall (detect all diseases) is critical. For spam detection, high precision (don't mark legitimate emails as spam) is critical.</p> <h2 id=summary-and-key-takeaways>Summary and Key Takeaways<a class=headerlink href=#summary-and-key-takeaways title="Permanent link">&para;</a></h2> <p>This chapter has covered the essential techniques for evaluating, optimizing, and deploying machine learning models. Let's summarize the key insights:</p> <p><strong>Evaluation fundamentals:</strong></p> <ul> <li><strong>Training vs. test error</strong> reveals whether your model generalizes or overfits</li> <li><strong>Cross-validation</strong> provides more reliable performance estimates than single train/test splits</li> <li><strong>Stratified sampling</strong> ensures representative splits for imbalanced datasets</li> </ul> <p><strong>Classification metrics:</strong></p> <ul> <li><strong>Accuracy</strong> is simple but misleading for imbalanced classes</li> <li><strong>Precision</strong> measures correctness of positive predictions (important when false positives are costly)</li> <li><strong>Recall/Sensitivity</strong> measures coverage of actual positives (important when false negatives are costly)</li> <li><strong>F1 score</strong> balances precision and recall with a single metric</li> <li><strong>ROC curves and AUC</strong> provide threshold-independent evaluation</li> </ul> <p><strong>Optimization algorithms:</strong></p> <ul> <li><strong>Adam</strong> combines momentum and adaptive learning rates; the default choice for most deep learning</li> <li><strong>RMSprop</strong> adapts learning rates based on gradient history; works well for RNNs</li> <li><strong>Nesterov momentum</strong> improves standard momentum with look-ahead gradients</li> <li><strong>Gradient clipping</strong> prevents exploding gradients in recurrent networks</li> </ul> <p><strong>Hyperparameter tuning:</strong></p> <ul> <li><strong>Grid search</strong> exhaustively tries all combinations; guaranteed to find best within grid</li> <li><strong>Random search</strong> samples randomly; more efficient for high-dimensional spaces</li> <li><strong>Bayesian optimization</strong> intelligently explores promising regions; best for expensive models</li> </ul> <p><strong>Best practices:</strong></p> <ul> <li>Split data into train/validation/test sets; never tune on test set</li> <li>Use cross-validation for reliable performance estimates</li> <li>Choose metrics appropriate for your problem (precision/recall for imbalance, AUC for ranking)</li> <li>Report confidence intervals, not just point estimates</li> <li>Fit all preprocessing on training data only (avoid data leakage)</li> <li>Use stratified sampling for classification tasks</li> </ul> <h2 id=further-reading>Further Reading<a class=headerlink href=#further-reading title="Permanent link">&para;</a></h2> <p>For deeper exploration of model evaluation and optimization:</p> <ul> <li>Hastie, Tibshirani, and Friedman - "The Elements of Statistical Learning" - Comprehensive coverage of bias-variance tradeoff and model selection</li> <li>Goodfellow, Bengio, and Courville - "Deep Learning" (Chapter 8) - Optimization algorithms for deep learning</li> <li>Bergstra and Bengio (2012) - "Random Search for Hyper-Parameter Optimization" - Why random search outperforms grid search</li> <li>Snoek, Larochelle, and Adams (2012) - "Practical Bayesian Optimization of Machine Learning Algorithms" - Introduction to Bayesian hyperparameter tuning</li> <li>Powers (2011) - "Evaluation: From Precision, Recall and F-Measure to ROC, Informedness, Markedness and Correlation" - Comprehensive guide to classification metrics</li> <li><a href=https://scikit-learn.org/stable/modules/model_evaluation.html>Scikit-learn Model Evaluation Guide</a> - Practical implementation details for all metrics</li> </ul> <h2 id=exercises>Exercises<a class=headerlink href=#exercises title="Permanent link">&para;</a></h2> <p><strong>Exercise 1: Metrics for Imbalanced Classification</strong></p> <p>You're building a fraud detection system where only 0.5% of transactions are fraudulent. You train three models:</p> <ul> <li>Model A: 99.5% accuracy, 10% precision, 80% recall</li> <li>Model B: 99.0% accuracy, 30% precision, 60% recall</li> <li>Model C: 98.0% accuracy, 50% precision, 40% recall</li> </ul> <p>Which model would you choose and why? Consider the costs of false positives (flagging legitimate transactions) vs. false negatives (missing fraud).</p> <p><strong>Exercise 2: Cross-Validation Implementation</strong></p> <p>Implement 5-fold cross-validation from scratch (without using scikit-learn's <code>cross_val_score</code>). Split the iris dataset manually into 5 folds, train a k-NN classifier on 4 folds, test on the remaining fold, and repeat for all 5 combinations. Compute the mean and standard deviation of accuracy scores.</p> <p><strong>Exercise 3: ROC Curve Analysis</strong></p> <p>Train a logistic regression classifier on an imbalanced dataset. Plot the ROC curve and compute AUC. Then plot the precision-recall curve for the same classifier. Which visualization is more informative for this imbalanced problem? Explain why.</p> <p><strong>Exercise 4: Hyperparameter Tuning Comparison</strong></p> <p>Choose a dataset and model (e.g., SVM on the iris dataset). Implement: 1. Grid search over 3-4 hyperparameters 2. Random search with the same number of total evaluations 3. Compare: Which found better hyperparameters? How long did each take?</p> <p><strong>Exercise 5: Detecting Overfitting</strong></p> <p>Train decision trees with varying max_depth (1, 2, 5, 10, 20, None) on the iris dataset. For each depth: - Compute training accuracy - Compute test accuracy (using holdout) - Compute cross-validation accuracy</p> <p>Plot all three curves vs. max_depth. At what depth does overfitting begin? How can you tell?</p> <p><strong>Exercise 6: Building a Complete Pipeline</strong></p> <p>Implement the complete evaluation pipeline from the "Putting It All Together" section on a dataset of your choice. Include: - Proper train/validation/test split - Preprocessing (scaling, encoding) - Hyperparameter tuning with cross-validation - Validation set evaluation - Final test set evaluation with comprehensive metrics - Discussion of results and potential improvements</p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 | CC BY-NC-SA 4.0 DEED </div> </div> <div class=md-social> <a href=https://github.com/AnvithPothula target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://linkedin.com/in/anvith-pothula target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>